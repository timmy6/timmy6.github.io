{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"https://timmy6.github.io","root":"/"},"pages":[{"title":"分类","date":"2022-05-11T03:33:53.548Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"categories/index.html","permalink":"https://timmy6.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-05-13T09:50:04.693Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"about/index.html","permalink":"https://timmy6.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"友情链接","date":"2022-05-13T09:50:02.369Z","updated":"2022-03-21T07:18:46.000Z","comments":true,"path":"links/index.html","permalink":"https://timmy6.github.io/links/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-05-13T09:49:57.974Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"books/index.html","permalink":"https://timmy6.github.io/books/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-05-11T02:54:02.124Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"repository/index.html","permalink":"https://timmy6.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-05-13T09:49:24.041Z","updated":"2022-03-21T07:18:46.000Z","comments":false,"path":"tags/index.html","permalink":"https://timmy6.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"rabbitmq基本操作","slug":"rabbitmq基本操作","date":"2020-07-05T14:15:10.000Z","updated":"2022-05-17T07:03:05.181Z","comments":true,"path":"2020/07/05/rabbitmq基本操作/","link":"","permalink":"https://timmy6.github.io/2020/07/05/rabbitmq%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"参考 https://www.toutiao.com/i6826959307888656899/ https://www.cnblogs.com/Zhangcsc/p/11739754.html 核心概念交换机exchange接收消息，并根据路由键转发消息到所绑定的队列 交换机的4种类型 topic 对路由键进行模式匹配，将消息转发到匹配上的队列上，其中* 表示匹配任意一个单词，# 表示匹配任意一个或多个单词，使用.分割单词，例如路由键quick.orange.rabbit，可以匹配上绑定键quick.#,*.orange.rabbit direct 要求路由键必须与绑定key完全匹配，这样才会被转发对应的队列 fanout 不处理路由键。你只需要简单的将队列绑定到交换机上，一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上 headers 不处理路由键，而是根据消息内容中的headers属性进行匹配 常用命令 basic.consume持续订阅,自动接收下一条消息 basic.get获取单条消息 basic.ack确认收到消息,或者消费者在订阅到队列的时候就将auto ack设置为true basic.reject丢弃消息,如果将reject命令的requeue参数设置为true的话,rabbitmq会将消息投递给下个消费者,否则会立即从队列删除消息并且存放到死信队列 queue.declare创建队列,如果不指定名称则随机分配一个名称,作为匿名队列 exclusive限制只有由一个消费者够消费 auto-delete当最后一个消费者取消订阅时候,队列会自动移除 当重复声明一个已存在的队列,若声明参数完全匹配现存队列,rabbit什么都不会做并返回成功 设置queue.declare的passive为true时,如果队列已存在,queue.declare返回成功,如果队列不存在,queue.declare命令不会创建队列而会返回一个错误 应该由生成者还是消费者创建队列呢?假设由消费者创建队列,若生成者先投递消息,此时还没有消费者,这个时候消息会怎么样?当有消费者了并且创建队列了会怎么样?答: 消息会提示发送成功,但是事实上它已经丢失了,即时消费者创建队列了也不能消费之前的发布的消息,最好的做法是消费者和生成者都要尝试创建队列,并且绑定队列和交换器 生产消息 AMQP_NOPARAM 无 AMQP_DURABLE 持久化exchange AMQP_PASSIVE 声明一个已存在的交换器的，如果不存在将抛出异常，这个一般用在consume端。因为一般produce端创建,在consume端建议设置成AMQP_PASSIVE,防止consume创建exchange AMQP_AUTODELETE 该交换器将在没有消息队列绑定时自动删除 为什么要用信道channel为了减少tcp连接开销,多个通道可以共享tcp连接??? 什么是消息幂等性？无论一条消息被消费多少次，消费的结果都是一样的。 什么是confirm消息确认机制？生成者生成消息，Broker收到消息就会给生产者一个应答，生产者接受应答来确认broker是否收到消息。 如何实现confirm确认消息？ 在Channel上开启确认模式：channel.confirmSelect() 在channel上添加监听：addConfirmListener，监听成功和失败的结果，具体结果对消息进行重新发送或者记录日志。 如何生成的消息匹配不到队列会怎么样？如果Mandatory设置为true，如果找不到队列，则broker会调用basic.return方法将消息返还给生产者;当mandatory设置为false时，出现上述情况broker会直接将消息丢弃;通俗的讲，mandatory标志告诉broker代理服务器至少将消息route到一个队列中，否则就将消息return给发送者;Mandatory设置为true只有在confirm模式有效 如何获得被return回来的消息？通过为channel信道设置ReturnListener监听器来实现 1234567891011121314151617181920212223242526272829&lt;?phprequire_once __DIR__ . &#x27;/vendor/autoload.php&#x27;;use PhpAmqpLib\\Connection\\AMQPStreamConnection;use PhpAmqpLib\\Message\\AMQPMessage;$connection = new AMQPStreamConnection(&#x27;localhost&#x27;, 5672, &#x27;guest&#x27;, &#x27;guest&#x27;, &#x27;/&#x27;);$channel = $connection-&gt;channel();$channel-&gt;set_return_listener(function ($i,$msg,$exchange,$routeKey,AMQPMessage $message) &#123; print_r($message-&gt;body);&#125;);$channel-&gt;confirm_select();$channel-&gt;set_ack_handler(function (AMQPMessage $message) &#123; print_r($message-&gt;body);&#125;);$channel-&gt;exchange_declare(&#x27;hyperf&#x27;, &#x27;topic&#x27;, true, true, false);$channel-&gt;queue_declare(&#x27;kt-test&#x27;, false, true, false, false);$channel-&gt;queue_bind(&#x27;kt-test&#x27;, &#x27;kt-test&#x27;, &#x27;kt-test&#x27;);for ($i = 0; $i &lt; 2; $i++) &#123; $msg = new AMQPMessage(&#x27;Hello World!&#x27;); //设置一个匹配不到队列的路由键，mandatory设置为true $channel-&gt;basic_publish($msg, &#x27;hyperf&#x27;, &#x27;kjfwelf&#x27;,true); echo &quot; [x] Sent &#x27;Hello World!&#x27;\\n&quot;;&#125;$channel-&gt;wait_for_pending_acks_returns(10); //等待$channel-&gt;close();$connection-&gt;close(); 什么是消费端的限流？rabbitMQ提供了一种qos的功能，即非自动确认消息的前提下，如果有一定数目的消息（通过consumer或者Channel设置qos）未被确认，不进行新的消费。 1$channel-&gt;basic_qos($prefetch_size, $prefetch_count, $a_global); prefetchSize:0 单条消息的大小限制。0就是不限制，一般都是不限制。 prefetchCount: 设置一个固定的值，一旦有N个消息还没有ack，则consumer将block掉，直到有消息ack global：是否将上面的设置用于channel，也是就是说上面设置的限制是用于channel级别的还是consumer的级别的。 什么是TTL队列&#x2F;消息？ 支持消息的过期时间，在消息发送时可以指定。 支持队列过期时间，在消息入队列开始计算时间，只要超过了队列的超时时间配置，那么消息就会自动的清除。 什么是死信队列？死信队列：DLX，Dead-Letter-Exchange 消息变为死信的几种情况： 消息被拒绝（basic.reject&#x2F;basic.nack）同时requeue&#x3D;false（不重回队列） TTL过期 队列达到最大长度https://www.cnblogs.com/Zhangcsc/p/11739754.html12345678910111213141516171819202122232425262728293031323334&lt;?phprequire_once __DIR__ . &#x27;/vendor/autoload.php&#x27;;use PhpAmqpLib\\Connection\\AMQPStreamConnection;use PhpAmqpLib\\Message\\AMQPMessage;use PhpAmqpLib\\Wire\\AMQPTable;$connection = new AMQPStreamConnection(&#x27;localhost&#x27;, 5672, &#x27;guest&#x27;, &#x27;guest&#x27;, &#x27;/&#x27;);$channel = $connection-&gt;channel();$args = new AMQPTable();// 消息过期方式：设置 queue.normal 队列中的消息10s之后过期$args-&gt;set(&#x27;x-message-ttl&#x27;, 3000);// 设置队列最大长度方式： x-max-length//$args-&gt;set(&#x27;x-max-length&#x27;, 1);$args-&gt;set(&#x27;x-dead-letter-exchange&#x27;, &#x27;exchange.dlx&#x27;);$args-&gt;set(&#x27;x-dead-letter-routing-key&#x27;, &#x27;routingkey&#x27;);$channel-&gt;exchange_declare(&#x27;exchange.dlx&#x27;, &#x27;direct&#x27;, false, true);$channel-&gt;queue_declare(&#x27;queue.dlx&#x27;, false, true, false, false);$channel-&gt;queue_bind(&#x27;queue.dlx&#x27;, &#x27;exchange.dlx&#x27;, &#x27;routingkey&#x27;);$channel-&gt;exchange_declare(&#x27;hyperf&#x27;, &#x27;topic&#x27;, true, true, false);$channel-&gt;queue_declare(&#x27;test-ttl&#x27;, false, true, false, false,false,$args);$channel-&gt;queue_bind(&#x27;test-ttl&#x27;, &#x27;hyperf&#x27;, &#x27;kt-test&#x27;);for ($i = 0; $i &lt; 2; $i++) &#123; $msg = new AMQPMessage(&#x27;Hello World!&#x27;); //设置一个匹配不到队列的路由键，mandatory设置为true $channel-&gt;basic_publish($msg, &#x27;hyperf&#x27;, &#x27;kt-test&#x27;,false); echo &quot; [x] Sent &#x27;Hello World!&#x27;\\n&quot;;&#125;$channel-&gt;close();$connection-&gt;close();","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://timmy6.github.io/categories/rabbitmq/"}],"tags":[]},{"title":"微服务","slug":"微服务","date":"2020-06-02T14:15:10.000Z","updated":"2022-05-17T06:52:16.315Z","comments":true,"path":"2020/06/02/微服务/","link":"","permalink":"https://timmy6.github.io/2020/06/02/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"优点 每个子业务独立部署，不会互相影响 每个子业务可以使用不同的开发语言 grpc和protobuf gRPC 是谷歌开源的轻量级 RPC 通信框架，其中的通信协议基于二进制数据流，支持 HTTP 2.0 协议，还可以为通信双方建立持续的双向数据流 protobuf 两个微服务之间通过基于 HTTP 2.0 二进制数据帧通信，那么如何约定二进制数据的格式呢？答案是使用 gRPC 内置的 protobuf 协议，其 DSL 语法 可清晰定义服务间通信的数据结构 docker容器多个容器共享宿主主机的 kernel，多个容器之间相互隔离 服务发现它作为一个注册中心会记录每个微服务的 IP 和端口，各微服务上线时会在它那注册，下线时会注销 12go get -u github.com/micro/protobuf/protogo get -u github.com/micro/protobuf/protoc-gen-go 微服务的优点 各个子模块互相独立，可以选用不同的技术栈，独立开发和维护。 故障隔离，一个服务挂掉不会影响其他服务。 微服务的缺点 数据一致性 事务问题 session一致性问题 锁问题 单个服务不可用导致整个系统崩溃（熔断器） 不同开发团队需要紧密协作。 定位问题难，问题日志可能分布在多台nginx上 系统变得更加复杂，运维也是个问题。 如何保障微服务架构下的数据一致性？https://www.cnblogs.com/mahatmasmile/p/8530077.htmlCAP理论，c一致性，a可用性，p分区容错性具体表现为在一定时间内，可能模块之间数据是不一致的，但是通过自动或手动补偿后能够达到最终的一致。二阶段提交协议可靠消息最终一致性 上游应用将本地业务执行和消息发送绑定在同一个本地事务中，保证要么本地操作成功并发送 MQ 消息","categories":[{"name":"微服务","slug":"微服务","permalink":"https://timmy6.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[]},{"title":"程序常用算法","slug":"程序常用算法","date":"2020-05-20T15:15:10.000Z","updated":"2022-05-17T06:50:09.882Z","comments":true,"path":"2020/05/20/程序常用算法/","link":"","permalink":"https://timmy6.github.io/2020/05/20/%E7%A8%8B%E5%BA%8F%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95/","excerpt":"","text":"给定一个数组,找最大元素值123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)func main() &#123; var arr = []int&#123;0, 1, 2, 45, 3, 4, 5, 6, 7, 8, 9, 10&#125; var beginPtr = 0 var endPtr = len(arr) - 1 for beginPtr &lt; endPtr &#123; // 知道两个位置重叠,这个数即为最大值(最小值) if arr[beginPtr] &gt; arr[endPtr] &#123; endPtr-- &#125; else &#123; beginPtr++ &#125; &#125; fmt.Println(&quot;max value:&quot;, arr[beginPtr])&#125; 给定一个数组,随机找其中几个不重复的元素12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;math/rand&quot; &quot;time&quot;)func main() &#123; rand.Seed(time.Now().Unix()) var arr = []int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; var total = len(arr) for i := 0; i &lt; 4; i++ &#123; j := rand.Int()%total + i // 从剩余元素中随机抽取一个元素 arr[i], arr[j] = arr[j], arr[i] // 将随机抽取的元素替换掉开头的元素 total-- &#125; fmt.Println(arr)&#125; 任何数字和某个数字a求余时,其结果不会超过a rand.Int()%total,随着total递减,所以改表达式求值结果最大值不会超过剩余元素个数 rand.Int()%total + i,加i的目的是让元素位置往后移动 arr[i], arr[j] = arr[j], arr[i],后面的随机数会替换掉前面的数字","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://timmy6.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"链表","slug":"链表","date":"2020-05-10T15:15:10.000Z","updated":"2022-05-17T06:48:22.905Z","comments":true,"path":"2020/05/10/链表/","link":"","permalink":"https://timmy6.github.io/2020/05/10/%E9%93%BE%E8%A1%A8/","excerpt":"","text":"链表 相对于数组,链表不需要连续的存储地址 每一个节点会记录下一个节点的地址 参考 https://blog.csdn.net/weixin_41582192/article/details/81181077 单链表节点内部结构1234type node struct &#123; Data int Next *node&#125; 头节点没有data,有next 尾节点有data,没有next 删除节点例如a-&gt;b-&gt;c,删除b,流程如下: 根据b.next获取c的地址 要怎么找到a,并将a.next赋值为c的地址插入节点例如a-&gt;c之间插入b,流程如下: 创建b节点 根据a.next获取c的地址,然后赋值为b.next 将b的地址赋值给a.next 双链表节点内部结构12345type node struct &#123; Data int Next *node Prev *node&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://timmy6.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"redis架构模式","slug":"redis架构模式","date":"2020-04-12T14:15:10.000Z","updated":"2022-05-17T06:41:01.553Z","comments":true,"path":"2020/04/12/redis架构模式/","link":"","permalink":"https://timmy6.github.io/2020/04/12/redis%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"Redis 有哪些架构模式？讲讲各自的特点 单机版 主从复制 哨兵模式（监控主从服务器，主服务器下线能够自动进行故障转移） 集群 主从复制大概两个过程： 从节点发送sync给主节点，主节点发送rdb快照文件给从节点，从节点从快照文件同步数据 主节点每写一个命令就会同步到从节点，从节点接收并执行收到的命令 哨兵模式一般使用3个哨兵，1主2从 作用 监控主节点和从节点的状态 当主节点发送故障，会自动将从节点转换为主节点，整个过程不需要人工参与原理 哨兵节点会向所有主从节点和其他哨兵节点发送ping消息，如果主节点在一定时间内（down-after-milliseconds）没有得到回复，则会被哨兵节点标记为主观下线（SDOWN）。 当有足够数据量的哨兵节点标记主节点为主观下线，则主节点会标记为客观下线。 主节点会进行故障转移，选取一个从节点来替换主节点。操作准备节点：3个哨兵，1主，2从； 主从节点主要配置如下：12345678# 使得Redis服务器可以跨网络访问bind 0.0.0.0# 设置密码requirepass &quot;123456&quot;# 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置slaveof 192.168.11.128 6379# 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置masterauth 123456 哨兵节点配置如下：1234567# 禁止保护模式protected-mode no# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。sentinel monitor mymaster 192.168.11.128 6379 2# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster 123456 启动哨兵节点和主从节点1234567891011121314cd /data/wwwroot/redis/redis_sentinel#启动redisredis-server redis_6480/redis.conf #这个是主节点redis-server redis_6481/redis.confredis-server redis_6482/redis.conf#查看主从是否启动成功redis-cli -h 127.0.0.1 -p 6480 pingredis-cli -h 127.0.0.1 -p 6480 info replication#启动哨兵redis-sentinel sentinel_26379/sentinel.confredis-sentinel sentinel_26380/sentinel.confredis-sentinel sentinel_26381/sentinel.conf#确认哨兵是否启用成功redis-cli -p 26379 info sentinel 集群redis的集群采用无中心结构，所有redis节点彼此互联（PING—PONG机制），当某个节点失败时需要集群中超过半数节点检测失效才会生效。客户端与redis节点直连，不需要借助中间代理层，客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。 集群数据分布每一个节点负责维护一部分槽和槽存放的数据，槽的范围是0到16383key -&gt; 槽 -&gt; 节点 集群请求路由 先计算key对应的槽，可以通过cluster keyslot &#123;key&#125;查看对应哪个槽 找槽对应的节点 若不是本节点，则回复move重定向错误，通知客户端请求正确的节点cli模式下重定向，加上-c参数，例如redis-cli -p 6481 -c如何解决集群mget问题？ 集群带来的一个问题是，无法批处理，例如当我们提交了一批命令，往Redis中存储一批键，那么这些键一般会被映射到不同的slot，而不同的slot又可能在Redis Cluster中不同的节点上，这样就和的预期有点不同，有没有办法将这批键映射到同一个slot呢？ 可以使用hash_tag，哈希标签是确保两个键都在同一个哈希槽里的一种方式。 比如这两个键 {user1000}.following 和 {user1000}.followers 会被哈希到同一个哈希槽里，因为只有 user1000 这个子串会被用来计算哈希值。 对于 foo{}{bar} 这个键，整个键都会被用来计算哈希值，因为第一个出现的 { 和它右边第一个出现的 } 之间没有任何字符。 对于 foo{bar}{zap} 这个键，用来计算哈希值的是 bar 这个子串，因为算法会在第一次有效或无效（比如中间没有任何字节）地匹配到 { 和 } 的时候停止。 集群是如何扩容? 添加新节点，redis-trib.rb add-node new_host:new_port exitsing_host:existing_port ，新加入节点刚开始都是主节点状态，没有负责槽，不能接收任何读写操作，需要导入槽和数据，或者是设置为从节点 迁移过程redis-trib.rb reshard &#123;existing_ip:existing_port&#125; 目标节点准备导入槽 源节点准备导出槽 获取槽下n个key 批量迁移相关key的数据 循环迁移key 通知槽分配给目标节点 新节点设置成从节点，具体进入从节点命令行，执行cluster replicate master_id 集群是如何缩容？ 下线节点是否有负责的槽 ，如果有的话需要先迁移到其他节点上，命令使用redis-trib.rb reshared &#123;existing_ip:existing_port&#125; 当下线节点不再负责槽或者本身是从节点就可以通知集群其他节点忘记下线节点，命令使用redis-trib.rb del-node &#123;host:port&#125; &#123;downNodeId&#125; 忘记节点 下线节点正常关闭 集群是如何故障转移的？ 首先，如果一个节点在规定时间内没有回复，会被其他节点标记为主观下线 如果被超过半数的节点标记为主观下线，则故障节点会被标为客观下线 资格检查；当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，则会触发选举，触发条件：断线时间不超过cluster-node-time*cluster-slave-validity-fator，目的是剔除太久没有同步主节点数据的从节点 准备选举时间；一个故障主节点可能会有多个从节点，这就需要有发起选举的优先级，主要根据复制偏移量来设置延迟选举时间，复制偏移量越大，排名越靠前，延迟时间越低，越有机会才会主节点 选举投票； 只有持有槽的主节点才能参与选举投票 只有一个从节点获得n&#x2F;2+1的选票才能选举成功 在clsuter-node-timeout*2内从节点没有获取足够数量的投票，选举作废 替换主节点，接管故障节点的槽和通知集群 迁移槽命令参数redis-trib.rb reshard &#123;existing_ip:existing_port&#125; –slots 需要确定迁移槽的总数量，总槽数&#x2F;总节点 –from 多个源节点，迁出槽 –to 一个目标节点，迁入槽 –timeout 控制每次migrate操作的超时时间，默认为60000毫秒 –pipeline 控制每次批量迁移键的数量，默认为10 host:port 集群中任意一个节点的地址 docker安装redis1docker run --name redis -p 6379:6379 redis 配置文件修改12345678port 6481cluster-enabled yes#集群内部配置文件cluster-config-file nodes-6481.conf#节点超时时间，单位毫秒cluster-node-timeout 15000logfile &quot;/data/wwwroot/redis/redis_cluster/6481/log/redis-6481.log&quot;pidfile /data/wwwroot/redis/redis_cluster/redis-6481.pid 开始123456789101112131415161718192021222324252627282930313233343536373839404142#启动节点redis-server /data/wwwroot/redis/redis_cluster/6481/redis-6481.confredis-server /data/wwwroot/redis/redis_cluster/6482/redis-6482.confredis-server /data/wwwroot/redis/redis_cluster/6483/redis-6483.confredis-server /data/wwwroot/redis/redis_cluster/6484/redis-6484.confredis-server /data/wwwroot/redis/redis_cluster/6485/redis-6485.confredis-server /data/wwwroot/redis/redis_cluster/6486/redis-6486.confredis-server /data/wwwroot/redis/redis_cluster/6487/redis-6487.confredis-server /data/wwwroot/redis/redis_cluster/6488/redis-6488.conf#创建集群#--replicas 1表示每个主节点配备几个从节点redis-trib.rb create --replicas 1 127.0.0.1:6481 127.0.0.1:6482 127.0.0.1:6483 127.0.0.1:6484 127.0.0.1:6485 127.0.0.1:6486#检测集群完整性#只要16384个槽中有一个没有分配给节点则表示集群不完整#可以对集群中任意一个节点发起检测redis-trib.rb check 127.0.0.1:6481#查看集群所有节点cluster nodes#集群扩容#6487是新节点，6481是已存在节点#如果新节点已存在数据，则会添加失败#redis-trib.rb add-node &#123;new_ip:new_port&#125; &#123;existing_ip:existing_port&#125;redis-trib.rb add-node 127.0.0.1:6487 127.0.0.1:6481#迁移槽和数据，127.0.0.1:6481为集群中任意一个节点redis-trib.rb reshard 127.0.0.1:6481#集群缩容#迁移槽redis-trib.rb reshard 127.0.0.1:6481#忘记节点redis-trib.rb del-node 127.0.0.1:6487 d4aafc5465d0f85a55ccd648e045cedcb46478cd#请求路由#查看key对应的槽cluster keyslot &#123;key&#125;#cli模式下加上-c可以重定向到正确节点redis-cli -p 6481 -c 新节点迁移槽和数据日志输出12345678910111213141516171819202122M: b079123bb42e1de36e9bc21d0473f8ceda6f7265 127.0.0.1:6481 slots:0-5460 (5461 slots) master 1 additional replica(s)M: bcbb401d25543cfc6384546ad24b46eb264b426e 127.0.0.1:6483 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: 8f2f21cb11d1986da9137f099e938bdb4e0f230e 127.0.0.1:6484 slots: (0 slots) slave replicates fa0015a21a575b170f5e39f463cc62fdb3a6e667S: af886e91bf0f42e36627d16d35bc270c0b6fb35e 127.0.0.1:6486 slots: (0 slots) slave replicates b079123bb42e1de36e9bc21d0473f8ceda6f7265M: fa0015a21a575b170f5e39f463cc62fdb3a6e667 127.0.0.1:6482 slots:5461-10922 (5462 slots) master 1 additional replica(s)S: 41e8cc7350b94185fca11ce243183f414307b037 127.0.0.1:6485 slots: (0 slots) slave replicates bcbb401d25543cfc6384546ad24b46eb264b426e[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.","categories":[{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/categories/redis/"}],"tags":[]},{"title":"redis持久化","slug":"redis持久化","date":"2020-03-03T14:15:10.000Z","updated":"2022-05-17T06:33:50.875Z","comments":true,"path":"2020/03/03/redis持久化/","link":"","permalink":"https://timmy6.github.io/2020/03/03/redis%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"参考 https://www.jianshu.com/p/bab8f4b26445 https://www.cnblogs.com/lizhimin123/p/10192217.html 相对于memcache,redis的是数据可以做持久化处理,主要有两种方式,快照rdb和追加文件aof,redis是持久化处理是比较耗时,一般在主从模式中,master不做持久化处理,由slave处理 什么是Redis持久化？持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。 快照rdb redis使用操作系统的多进程COW机制(Copy On Write)复制写机制来实现快照的持久化 由子进程进行持久操作，子进程刚刚产生时，和父进程共享内存里面的代码段和数据段 子进程会 配置持久化有两个命令，save和bgsave，save会阻塞服务进程，直到持久化完成，bgsave会fork子进程，由子进程去完成持久化，bgsave对应配置如下： 1234// 满足以上三个条件中的任意一个，则自动触发 BGSAVE 操作 save 900 1 // 服务器在900秒之内，对数据库执行了至少1次修改 save 300 10 // 服务器在300秒之内，对数据库执行了至少10修改 save 60 1000 // 服务器在60秒之内，对数据库执行了至少1000修改 rdb文件结构https://www.cnblogs.com/lizhimin123/p/10192217.html REDIS：5字节，保存着 “REDIS” 五个字符 db_version：4字节，RDB文件的版本号 database 0：数据库中的键值对 SELECTDB：1字节常量 db_number：数据库号码 key_value_pairs：键值对 type: 记录类对象的编码类型，程序会根据 TYPE 属性来决定如何读入和解释value数据 key value EOF：RDB文件的结束标志 check_sum：校验和（CRC64），用来检查RDB文件是否出错 rdb问题 持久化过程中数据发生改变？rdb文件被成为快照文件，子进程所看到的数据在它被创建的一瞬间就固定下来了，父进程修改的某个数据只是该数据的复制品。（父子进程共享内存，数据发生写时会另外复制一份数据进行修改） 优点: 性能好 缺点: 实时性差 追加日志aofredis将指令追加到日志，通过回放指令来恢复数据，随着时间的增大会有日志文件变大的问题，这就需要重写日志 aof重写日志的过程是怎么样的？ fork子进程 子进程遍历内存数据写到新的aof文件 在生成新的aof文件的过程中，如果收到新指令，则继续保存在系统内存缓存中 完成新的aof文件之后，将系统内存缓存数据追加到新的aof文件 新的aof文件代替旧的aof文件 优点: 实时性小 缺点: 需要重写日志文件","categories":[{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/categories/redis/"}],"tags":[]},{"title":"redis常见问题","slug":"redis常见问题","date":"2020-02-03T14:15:10.000Z","updated":"2022-05-17T06:30:07.515Z","comments":true,"path":"2020/02/03/redis常见问题/","link":"","permalink":"https://timmy6.github.io/2020/02/03/redis%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"参考 https://www.cnblogs.com/jasontec/p/9699242.html https://zhuanlan.zhihu.com/p/79778696 使用过Redis分布式锁么，它是怎么实现的？redis的分布式锁主要使用set命令的nx选项抢占锁，以及ex设置过期时间，先nx获得锁并且设置过期时间，这两个过程是原子性的，中间不会被其他命令打断；另外防止锁超时过期误删锁，一般使用set获得锁时会设置一个唯一值，释放锁的时候需要匹配一下两个值是否一致 什么是一致性哈希算法？什么是哈希槽？https://www.jianshu.com/p/6ad87a1f070e redis 的 custer 提供了两个功能： 自动对数据分片，落到各个节点上 即使集群部分节点失效或者连接不上，依然可以继续处理命令 普通哈希算法是hash(key)%number对数量进行取余获得key所在节点位置，如果改变数量会导致原有节点上的数据发生变化； 在一致性哈希算法中，整个哈希空间是一个虚拟圆环。 对节点取哈希值，然后分配到哈希环上。对某个值进行搜索的时候按顺时针搜索找到key第一个存在的节点，即使发生节点数据变化，也只是影响一小部分区间的数据； 一致性哈希算法对于容错性和扩展性有非常好的支持。但一致性哈希算法也有一个严重的问题，就是数据倾斜。 解决方案 对每个真实节点增加多个虚拟节点，然后维护一个虚拟节点和真实节点的映射关系表；（即环上都是）https://geektutu.com/post/geecache-day4.html rredis 集群（cluster）并没有选用上面一致性哈希，而是采用了哈希槽（slot）的这种概念。每个redis节点会维护一部分槽以及槽上的数据，总的槽大概一万六千多，槽可以均匀分布在多个节点 123456docker run --rm --net=host --name redis-manager \\-e DATASOURCE_DATABASE=&#x27;redis_manager&#x27; \\-e DATASOURCE_URL=&#x27;jdbc:mysql://127.0.0.1:3306/redis_manager?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=GMT%2b8&#x27; \\-e DATASOURCE_USERNAME=&#x27;root&#x27; \\-e DATASOURCE_PASSWORD=&#x27;123456&#x27; \\reasonduan/redis-manager https://www.fengpt.cn/archives/redis%E9%9B%86%E7%BE%A4%E5%9C%A8%E6%9F%A5%E6%89%BEkey%E7%9A%84%E6%97%B6%E5%80%99%E6%98%AF%E5%A6%82%E4%BD%95%E8%B7%AF%E7%94%B1%E7%9A%84 redis集群哈希槽redis cluster 包含了16384个哈希槽，每个 key 通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。例如机器硬盘小的，可以分配少一点槽位，硬盘大的可以分配多一点。如果节点硬盘都差不多则可以平均分配。所以哈希槽这种概念很好地解决了一致性哈希的弊端。 在容错性和扩展性上，redis对槽位的转移，把故障节点负责的槽位转移到其他正常的节点上。 但一定要注意的是，对于槽位的转移和分派，redis 集群是不会自动进行的，而是需要人工配置的。所以 redis 集群的高可用是依赖于节点的主从复制与主从间的自动故障转移。 使用过Redis做异步队列么，你是怎么用的？有什么缺点？可以是使用blpop和rpush，blpop会移除列表头部元素，如果列表没有元素会阻塞直到等待超时或发现元素为止，rpush从尾部写入数据；缺点如下： 消息容易丢失 消息分发策略没有专业的mq丰富，例如kafka的分区，rabbitmq的路由键等等 什么是缓存穿透？如何避免？什么是缓存雪崩？何如避免？缓存穿透一般缓存系统会先查缓存，值不存在的时候再查数据库；一些恶意的请求会故意查询不存在的key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。如何避免？ 对查询结果为空的情况也进行缓存，缓存时间设置短一点 对一定不存在的key进行过滤，可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤（布尔过滤器）缓存雪崩当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。如何避免？ 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 Redis的字典是如何实现的？简述渐进式rehash的过程？https://www.jianshu.com/p/e2697fecac0dhttps://www.cnblogs.com/neooelric/p/9621736.html Redis事务是怎么样的？redis的事务是通过mutil实现的，mutil开始一个事务，然后将多个命令入队到事务中，最后执行exec命令触发事务。redis的事务有一些不足： 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做 同的key是有可能分配在不同的Redis节点上的，在这种情况下Redis的事务机制是不生效的 集群可以使用lua脚本吗？不可以，除非key在同一个redis节点上，可以使用&#123;hash_tag&#125;来是不同的key落到同一个节点上 123456&gt; CLUSTER KEYSLOT somekey11058&gt; CLUSTER KEYSLOT foo&#123;hash_tag&#125;(integer) 2515&gt; CLUSTER KEYSLOT bar&#123;hash_tag&#125;(integer) 2515 keySlot算法中，如果key包含{}，就会使用第一个{}内部的字符串作为hash key，这样就可以保证拥有同样{}内部字符串的key就会拥有相同slot Redis的多数据库机制，了解多少？单机版有16个数据库，每个数据库的数据相互隔离，集群版只有一个数据库 谈谈你对分布式和集群，微服务的理解？两则之间有什么关系？ 分布式是将一个业务拆分多个子业务，多个子业务可以部署不同机器上面，子业务之间通过rpc或消息中间件或其他方式进行通信，如果有一个子业务不可用，那么整个业务就不可用 微服务是将一个业务拆分多个子业务，多个子业务可以部署在不同机器或统一机器上面（和分布式的区别）。 集群是同一个业务部署到多个机器上面，比如用nginx做负载均衡。 分布式下每个子业务都可以做集群，分布式和微服务类似，只是部署方式不一样 redis集群有什么限制 不能批量处理key 不支持事务，多数据库 一些大的键值对象不能映射到不同的节点上 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使用keys 指定模式可以获得key列表 因为redis是单线程模式，使用keys命令会导致线程阻塞一段时间，线上服务会停顿，直到命令执行完毕才能恢复 可以用scan命令，无阻塞的，但是会有一定的重复概率 bgsave的原理是什么？fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 Pipeline有什么好处，为什么要用pipeline？可以将多次IO往返的时间缩减为一次 Redis的同步机制了解么？ 第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。 加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 是否使用过Redis集群，集群的原理是什么？Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。","categories":[{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/categories/redis/"}],"tags":[]},{"title":"Redis的常用淘汰策略以及算法","slug":"Redis的常用淘汰策略以及算法","date":"2020-01-05T14:15:10.000Z","updated":"2022-05-17T06:24:53.442Z","comments":true,"path":"2020/01/05/Redis的常用淘汰策略以及算法/","link":"","permalink":"https://timmy6.github.io/2020/01/05/Redis%E7%9A%84%E5%B8%B8%E7%94%A8%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5%E4%BB%A5%E5%8F%8A%E7%AE%97%E6%B3%95/","excerpt":"","text":"Redis配置内存为多少合适？默认：如果不设置最大内存大小或者设置最大内存大小为0，在64为操作系统下不限制内存大小，在32位操作系统下最多使用3GB内存。 一般推荐Redis设置内存为最大物理内存的75%都是安全的 如何修改内存redis.conf中 12maxmemory 104857600config set maxmemory 104857600 Redis的内存淘汰策略过期策略 定期删除 惰性删除 内存淘汰机制 lru - 最近最少使用的 key，也就是首先淘汰最长时间未被使用的缓存，强调的是时间 random - 随机删除 lfu - 最近最不经常使用，,也就是淘汰一定时期内被访问次数最少的缓存，强调的是频率 LRU算法原理其原理是维护一个双向链表，key -&gt; node，其中node保存链表前后节点关系及数据data。新插入的key时，放在头部，并检查是否超出总容量，如果超出则删除最后的key；访问key时，无论是查找还是更新，将该Key被调整到头部。 Redis并没有使用严格的LRU算法，因为维护一个那么大的双向链表需要的内存空间较大。redis通过随机采样法淘汰数据，每次随机出5（默认）个key，从里面淘汰掉最近最少使用的key。 显然LRU的缺陷是明显的，最新访问的数据被当做热数据显然是不合理的，热数据顾名思义就是被访问频次叫高的数据，显然是不同的概念 LFU算法原理假如你使用的是LRU算法，一个key很久没有被访问到，只刚刚是偶尔被访问了一次，那么它就被认为是热点数据，不会被淘汰，而有些key将来是很有可能被访问到的则被淘汰了。如果使用LFU算法则不会出现这种情况，因为使用一次并不会使一个key成为热点数据。LFU原理使用计数器来对key进行排序，每次key被访问的时候，计数器增大。计数器越大，可以约等于访问越频繁。具有相同引用计数的数据块则按照时间排序。 LFC算法存在两个问题： 在LRU算法中可以维护一个双向链表，然后简单的把被访问的节点移至链表开头，但在LFU中是不可行的，节点要严格按照计数器进行排序，新增节点或者更新节点位置时，时间复杂度可能达到O(N)。 只是简单的增加计数器的方法并不完美。访问模式是会频繁变化的，一段时间内频繁访问的key一段时间之后可能会很少被访问到，只增加计数器并不能体现这种趋势 参考 https://blog.csdn.net/raoxiaoya/article/details/103141022","categories":[{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/categories/redis/"}],"tags":[]},{"title":"mysql索引知识","slug":"mysql索引知识","date":"2019-12-15T14:15:10.000Z","updated":"2022-05-17T06:16:11.976Z","comments":true,"path":"2019/12/15/mysql索引知识/","link":"","permalink":"https://timmy6.github.io/2019/12/15/mysql%E7%B4%A2%E5%BC%95%E7%9F%A5%E8%AF%86/","excerpt":"","text":"参考 https://www.toutiao.com/i6732776474308248072/ https://www.cnblogs.com/jie-y/p/11153480.html https://www.cnblogs.com/kkbill/p/11381783.html 为什么要用索引？索引用于加速查询速度 索引的缺点 需要维护索引文件,占物理空间 影响增删改性能 数据存储文件对于MyISAM存储引擎来说 .frm后缀的文件存储的是表结构。 .myd后缀的文件存储的是表数据。 .myi后缀的文件存储的就是索引文件。对于InnoDB 存储引擎来说: .frm后缀的文件存储的是表结构。 .ibd后缀的文件存放索引文件和数据(需要开启innodb_file_per_table 参数) myisam和innodb从索引方面上来说有什么区别？https://www.cnblogs.com/jie-y/p/11153480.html myisam主索引和数据是分开的，innodb数据文件本身就是主索引文件 myisam的主索引文件和辅助索引文件结构一样，叶子节点保存行数据的物理地址 innodb的主索引文件是按主键构造的b+树（也叫聚簇索引），叶子节点保存行数据；辅助索引的叶子节点保存主键值 聚簇索引聚簇索引并不是一种索引类型，也是一种数据存储方式，它按照主键的顺序构建b+树，行数据存放在叶子节点上 聚簇索引的缺点 页分裂会导致表占用更多的磁盘空间；假如磁盘中的某一个已经存满了，但是新增的行要插入到这一页当中，存储引擎就会把该也分裂成两个页面来容纳该行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间 什么是二级索引？对于非主键列其他列建立的索引就是二级索引 聚簇索引和二级索引有什么区别？ 聚簇索引的叶子节点存放行数据，二级索引的叶子节点存放索引列的值和主键 二级索引需要回表查询，也就是二次查询，而聚簇索引不需要 为什么选择B+树作为数据库索引结构？https://www.cnblogs.com/kkbill/p/11381783.html首先需要理解的是b树和b+树的区别； b树b树就是平衡的多路搜索树，b树通常意味着所有的值都是按顺序存储的，并且每一个叶子也到根的距离相同，所谓的m阶B树，即m路平衡搜索树；一颗m阶b树满足以下条件： 每个结点至多含有m个分支节点（m&gt;&#x3D;2）。 除根结点之外的每个非叶结点，至少含有m&#x2F;2个分支。 若根结点不是叶子结点，则至少有2个孩子。 一个含有k个孩子的非叶结点包含k-1个关键字。 （每个结点内的关键字按升序排列）所有的叶子结点都出现在同一层。实际上这些结点并不存在，可以看作是外部结点。 所有的叶子结点都出现在同一层。b+树相对于b树的区别 叶子结点包含全部关键字以及行记录数据（或指针） 叶子结点连接在一起，组成一个链表，利于范围搜索 非叶子结点不存放真正的数据，只存放关键字，利于同样大小的磁盘页可以容纳更多的关键字（节点元素），相对应的树的高度就越小，发生io的次数就越少 索引优化(原则) 应该选择基数大的字段作为索引 数据类型要和索引字段类型一致,如果varchar字段,用数字查询不能使用索引 多列索引需要遵循左侧前缀匹配原则,多列索引组成一个索引,比较的时候是从左到右匹配 不在索引列做计算 字符串做索引需要避免索引长度过长问题（mysql的索引底层是一个b+树，每个节点对应一个磁盘页，能够容纳的大小是有限，如果索引越小，就能容纳更多key，树的高度就越低，发出io次数就越少，性能就越高） 常用索引命令12345678910111213# 查看表所有索引show index from users;# 创建索引,如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 lengthcreate index index-name on users(name(10));# 创建唯一索引create unique index index-name on users(name(10))# 创建索引alter table users add index index-name(name(10));alter table users add primary key(id);alter table users add unique index-name(name(10));# 删除索引alter table users drop index index-name;drop index index-name on users; 其他https://blog.csdn.net/qq_35495339/article/details/89304012 in,or可以命中索引,in比union all消耗更多cpu,但是一般推荐用in 负向条件不可以应用索引,包括!=、&lt;&gt;、not in、not exists、not like,可以优化为in查询 最左侧查询需求，并不是指 SQL 语句的 where 顺序要和联合索引一致 范围查询可以使用索引,但是范围列后面的列无法用到索引,例如联合索引 (empno、title、fromdate,其中sql语句为select * fromemployees.titles where emp_no &lt; 10010&#39; and title=&#39;Senior Engineer&#39;and from_date between &#39;1986-01-01&#39; and &#39;1986-12-31&#39;,那么只有 emp_no 可以用到索引，而 title 和 from_date 则使用不到索引","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"mysql主从复制和读写分离","slug":"mysql主从复制和读写分离","date":"2019-11-25T14:15:10.000Z","updated":"2022-05-17T06:10:33.751Z","comments":true,"path":"2019/11/25/mysql主从复制和读写分离/","link":"","permalink":"https://timmy6.github.io/2019/11/25/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%92%8C%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/","excerpt":"","text":"一致性是指多副本中的数据一致性问题,可以分为强一致性,顺序一致性,弱一致性 强一致性在任意时刻，所有节点中的数据是一样的,例如，例如主从数据库,主库更新一个数据后,可以从从库读取到 可以指定复制所有库,指定库,或者指定表 主从复制的优点 主库负责写,从库负责读,可以分配负载以提高性能 数据备份,从库可以作为备份数据库 主从复制原理 主库开启二进制日志 主库将sql语句通过io线程保存在二进制日志binary log 从库启动io线程,读取主库的binary log到自己的中继日志realy log 从库开启sql线程,定时检查realy log,然后执行realy log语句 从库会记录主库二级制日志的坐标,所以从库可以暂停恢复继续处理 docker启动mysql容器https://www.cnblogs.com/sablier/p/11605606.html 1234567# 镜像为mysql:5.7docker run -p 13306:3306 --name mysql_1 --network mysql-network -e MYSQL_ROOT_PASSWORD=123456 -d mysql:v57# 进入容器 docker exec -it mysql_1 /bin/bash# 允许root远程登录mysqlgrant all privileges on *.* to root@&#x27;%&#x27; identified by &quot;password&quot;;flush privileges; 主库配置创建用户 12345# 创建用于复制数据的用户,并只赋予replication权限create user &#x27;repl&#x27;@&#x27;%&#x27;;grant replication slave on *.* to repl@&#x27;%&#x27; identified by &quot;123456&quot;;# 导出主库已经存在的数据mysqldump -u用户名 -p密码 --all-databases --master-data=1 &gt; dbdump.db 配置my.cnf 123456789# docker默认路径`/etc/mysql/my.cnf`vi /etc/mysql/my.cnf[mysqld]log-bin=mysql-binserver-id=1# 重启/etc/init.d/mysqld restart server-id 为0时,表示主库拒绝任何来自从库的连接 主从库server-id不能冲突，主要Master要依靠server_id来决定是否执行event。从库会把主库的event发送回主库??? 多个从库的server-id不能冲突，server-id用来表示从库连接 从库配置配置my.cnf 1234567891011[mysqld]server-id=2# 重启/etc/init.d/mysqld restart# 设置主库信息change master to master_host=&#x27;mysql_1&#x27;,master_user=&#x27;repl&#x27;,master_password=&#x27;123456&#x27;;# 启动start slave;# 查看是否成功show slave status\\G 测试sql1234# 创建users表create table users( id int(11) auto_increment, name varchar(100) not null, age int(1) default 0, primary key(id) )engine=InnoDB default charset=utf8;# 插入一条数据insert into users(name,age) values(&#x27;wuzhc&#x27;,20),(&#x27;mayun&#x27;,65); 复制过程当master上写操作繁忙时，当前POS点例如是10，而slave上IO_THREAD线程接收过来的是3，此时master宕机，会造成相差7个点未传送到slave上而数据丢失 异步复制 半同步复制 常见的错误sql_slave_skip_counter表示跳过复制错误 master上删除一条记录，而slave上找不到 set global sql_slave_skip_counter=1; 主键重复。在slave已经有该记录，又在master上插入了同一条记录 删除从库重复的记录 在master上更新一条记录，而slave上找不到，丢失了数据 从库补充数据,跳过set global sql_slave_skip_counter=1; 恢复relay-log日志从库有两个线程,一个是Slave_IO_Running,一个是Slave_SQL_Running Slave_IO_Running ：接收master的binlog信息 Master_Log_File Read_Master_Log_PosSlave_SQL_Running：执行写操作 Relay_Master_Log_File Exec_Master_Log_Pos12345stop slave;# MASTER_LOG_FILE对应Relay_Master_Log_File,MASTER_LOG_POS对应Exec_Master_Log_PosCHANGE MASTER TO MASTER_LOG_FILE=&#x27;mysql-bin.000001&#x27;,MASTER_LOG_POS=1609;start slave;show slave status\\G; mysql自定义dock镜像123456789FROM mysql:5.7RUN sed -i &quot;s@http://deb.debian.org@http://mirrors.aliyun.com@g&quot; /etc/apt/sources.list \\ &amp;&amp; sed -i &quot;s@http://security.debian.org@http://mirrors.aliyun.com@g&quot; /etc/apt/sources.list \\ &amp;&amp; rm -Rf /var/lib/apt/lists/* \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install vim -y \\ &amp;&amp; apt-get install iputils-ping -y \\ &amp;&amp; apt-get install net-tools -y \\ &amp;&amp; apt-get install ssh -y 主从复制需要考虑哪些问题？主从复制延迟 升级从库配置 升级mysql到5.6之后，采用并行复制 分库 写一份数据到redis，读从库没有数据时从redis读 更改读库的方式 使用事务事务同一个事务的sql发到同个从库 主从复制有哪些方式？ 半同步复制；防止主库挂掉后数据丢失（半同步复制确保事务提交后binlog至少传输到一个从库，只是传输到从库，不保证从库应用完这个事务的binlog ） 并行复制；主要解决主从复制延迟问题 如何查看主从延迟的时间？通过在从库执行命令show status，其中Seconds_Behind_Master可以反映延迟时间","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"一些常用的命令","slug":"一些常用的命令","date":"2019-11-16T14:15:10.000Z","updated":"2022-05-17T05:44:51.384Z","comments":true,"path":"2019/11/16/一些常用的命令/","link":"","permalink":"https://timmy6.github.io/2019/11/16/%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4/","excerpt":"","text":"一些常用的命令查看端口占用情况1lsof -i tcp:8989 eg: 1234lsof -i tcp:80COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEGoogle 328 mengyueping 181u IPv4 0x393cc3d704a30853 0t0 TCP bogon:65200-&gt;202.108.249.246:http (ESTABLISHED) 杀死正在运行的服务12kill -9 应用的pidkill -9 $(pgrep 应用名字) 查看某个应用进程的 pid1234echo $(pgrep bee)# $(pgrep 进程的名字)ps -ef | grep 应用名（支持通配符） eg: 123[root@VM_0_3_centos ~]# ps -ef | grep beeroot 16864 16828 0 15:47 pts/0 00:00:00 grep --color=auto beeroot 18955 1 0 6月08 ? 00:00:44 bee run 查看内存1234free total used free shared buff/cache availableMem: 3881904 861012 469244 480 2551648 2712060Swap: 0 0 0 12# 单位为 megabytesfree -m total : 总计物理内存大小 used : 已使用多大 free : 可用有多少 shared : 多个进程共享的内存总额 buff/cache :磁盘缓存的大小 查看磁盘空间12345678df -h文件系统 容量 已用 可用 已用% 挂载点/dev/vda1 50G 6.6G 41G 15% /devtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 24K 1.9G 1% /dev/shmtmpfs 1.9G 444K 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgrouptmpfs 380M 0 380M 0% /run/user/0 查看某个目录的大小： 123# du -sh [目录名] 返回该目录的大小du -sh ./src272M ./src 查看指定文件夹下的所有文件大小（包含子文件夹）： 1du -h ../src/ 查看内核&#x2F;操作系统&#x2F;CPU信息的linux系统信息命令12uname -aLinux VM_0_3_centos 3.10.0-514.26.2.el7.x86_64 #1 SMP Tue Jul 4 15:04:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 查看环境变量1env","categories":[{"name":"Linux","slug":"Linux","permalink":"https://timmy6.github.io/categories/Linux/"}],"tags":[{"name":"常用命令","slug":"常用命令","permalink":"https://timmy6.github.io/tags/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"}]},{"title":"数据库结构设计","slug":"数据库结构设计","date":"2019-11-05T14:15:10.000Z","updated":"2022-05-17T02:16:36.607Z","comments":true,"path":"2019/11/05/数据库结构设计/","link":"","permalink":"https://timmy6.github.io/2019/11/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"数据库结构设计 减少数据冗余 尽量避免数据维护中出现更新，插入和删除异常 插入异常：如果表中的某个实体随着另一个实体而存在 更新异常：如果更改表中的某个实体的单独属性时，需要对多行进行更新 删除异常：如果删除表中的某一实体则会导致其他实体的消失 节约数据存储空间 提高查询效率 数据库结构设计的步骤 需求分析：全面了解产品设计的存储需求 存储需求 数据处理需求 数据的安全性和完整性 逻辑设计：设计数据的逻辑存储结构 数据实体之间的逻辑关系，解决数据冗余和数据维护异常 物理设计：根据所使用的数据库特点进行表结构设计 关系型数据库：Oralce，SQLServer，Mysql，postgresSQL 非关系型数据库：mongo，Redis，Hadoop 存储引擎： Innodb 维护优化：根据实际情况对索引，存储结构等进行优化 数据库设计范式设计出没有数据冗余和数据维护异常的数据库结构。 数据库设计的第一范式： 数据库表中的所有字段都只具有单一属性 单一属性的列是由基本的数据类型所构成的 设计出来的表都是简单的二维表 数据库设计的第二范式： 要求一个表中只具有一个业务主键，也就是说符合第二范式的表中不能存在非主键列对只对部分主键的依赖关系。 数据库设计的第三范式： 指每一个非主属性既不部分依赖于也不传递依赖于业务主键，也就是在第二范式的基础上消除了非主属性对主键的传递依赖。 物理设计根据所选择的关系型数据库的特点，对逻辑模型进行存储结构设计。包括： 定义数据库、表及字段的命名规范 选择合适的存储引擎 为表中的字段选择合适的数据类型 建立数据库表具体结构 定义数据库、表及字段的命名规范数据库、表及字段的命名要遵守： 可读性原则 表意性原则 长名原则 选择合适的存储引擎 存储引擎 事务 锁粒度 主要应用 忌用 MyISAM 不支持 支持并发插入的表级锁 select，insert 读写操作频繁 MRG_MYISAM 不支持 支持并发插入的表级锁 分段归档，数据仓库 全局查找过多的场景 Innodb 支持 支持MVCC的行级锁 事务处理 无 Archive 不支持 行级锁 日志记录，只支持insert，select 需要随机读取，更新，删除 Ndb cluster 支持 行级锁 高可用性 大部分应用 数据类型的选择为表中的字段选择合适的数据类型： 当一个列可以选择多种数据类型时，应该优先考虑数字类型。 其次是日期或二进制类型 最后是字符类型。 对于相同级别的数据类型，应该优先选择占用空间小的数据类型。 在对数据进行比较（查询条件、Join条件有关联排序时）：字符类型是与排序规则有关系；而数字类型和二进制类型不需要参照这种这种规则，是按照二进制大小进行排序的，同样的数据字符类型处理就比较慢。 数据库中数据存储是以页为单位的，每一页存储的数据量是一定的，Innodb中是16k，数据的长度越小，在每页中能容纳的数据行数就越多，这样在加载同样的数据时，使用的宽度较小的类型就比宽度较大的类型加载的数据页较少，也就减少了磁盘IO，有利于性能的提升。 如何选择正确的整数类型 列类型 存储空间 取值范围（SIGNED） 取值范围（UNSIGNED） tinyint 1个字节 -128~127 (2^7 ~ 2^7-1) 0~255 smallint 2个字节 -32768 ~ 32767 0~65535 mediumint 3个字节 -8388608 ~ 8388607 0~16777215 int 4个字节 -2147483648 ~ 2147483647 0~4294967295 bigint 8个字节 -9223372036854775808 ~ 9223372036854775807 0 ~ 18446744073709551615 如果只存储两位数，就使用 tinyint 类型，不要使用 int 类型，可以节约空间。 如何选择正确的实数类型 列类型 存储空间 是否精确类型 FLOAT 4个字节 否 DOUBLE 8个字节 否 DECIMAL 每4个字节存9个数字，小数点占一个字节 是 DECIMAL(18,9) 需要 9 个字节来存储。 如何选择 VARCHAR 和 CHAR 类型 VARCHAR 类型的存储特点： varchar 用于存储变长字符串，只占用必要的存储空间 列的最大长度小于255则只占用一个额外字节用于记录字符串长度 列的最大长度大于255则要占用两个额外字节用于记录字符串长度 VARCHAR 长度的选择问题 使用最小的符合需求的长度 varchar(5)和varchar(200)存储’Mysql’字符串性能不同 mysql 为了更有效的优化查询，在内存中对字符串的使用是固定的宽度，列太长就会消耗更多的内存。 VARCHAR 的适用场景： 字符串列的最大长度比平均长度大很多（发挥变长存储的特点） 字符串列很少被更新（更新，字符串长度会产生变化，可能引起存储页的分裂；还会产生很多存储碎片） 使用了多字节字符集存储字符串（例如utf8，不同字符存储字节数不同，中文和英文就不同） CHAR 类型的存储特点： CHAR 类型是定长的 字符串存储在 CHAR 类型的列中会删除末尾的空格 CHAR 类型的最大宽度为 255 CHAR 的适用场景： CHAR 类型适合存储所有长度近似的值 （eg： md5值，身份证号，手机号） CHAR 类型适合存储短字符串 CHAR 类型适合存储经常更新的字符串列 如何存储日期类型 DATATIME 类型 以 YYYY-MM-DD HH:MM:SS[.fraction] 格式存储日期时间 datetime &#x3D; YYYY-MM-DD HH:MM:SS datetime(6) &#x3D; YYYY-MM-DD HH:MM:SS.fraction DATATIME类型与时区无关，占用8个字节的存储空间 时间范围：1000-01-01 00:00:00 到 9999-12-31 23:59:59 TIMESTAMP 类型 时间戳，存储了由格林尼治时间1970年1月1日到当前时间的秒数 以 YYYY-MM-DD HH:MM:SS.[.fraction] 的格式显示，占用4个字节。 时间范围： 1970-01-01 到 2038-01-19 timestamp 类型显示依赖于所指定的时区 在行的数据修改时，可以自动修改 timestamp 列的值。 date类型 存储用户生日时，只需要存储日期部分 一是把日期部分存储为字符串（至少要8个字节） 二是使用int类型来存储（4个字节） 三是使用datetime类型来存储（8个字节） date 类型的优点： 占用的字节数比使用字符串、datetime、int存储要少，使用date类型只需要3个字节。 使用Date类型还可以利用日期时间函数进行日期之间的计算 date类型用于保存 1000-01-01 到 9999-12-31 之间的日期 time类型 time类型用于存储时间数据，格式为：HH:MM:SS 存储日期时间数据的注意事项 不要使用字符串类型来存储日期时间数据 日期时间类型通常比字符串占用的存储空间小 日期时间类型在进行查找过滤时可以利用日期来进行对比 日期时间类型还有着丰富的处理函数，可以方便的对时期类型进行日期计算 使用Int存储日期时间不如使用 Timestamp 类型 如何为 Innodb 选择主键 主键应该尽可能的小 主键应该是顺序增长的 （Innodb 内部的逻辑顺序是和主键顺序相同的，主键的顺序是顺序增长的，那么插入数据就能顺序插入，避免了随机IO的产生，所以这样可以增加数据的插入效率） Innodb 的主键和业务主键可以不同 （业务主键可以添加唯一索引） 数据库结构：（查询性能要求、范式化要求） 从数据库架构方面优化数据库；维护和优化：索引&amp;sql优化。","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"mysql基准测试","slug":"mysql基准测试","date":"2019-10-15T15:15:10.000Z","updated":"2022-05-17T02:14:22.503Z","comments":true,"path":"2019/10/15/mysql基准测试/","link":"","permalink":"https://timmy6.github.io/2019/10/15/mysql%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95/","excerpt":"","text":"MySQL基准测试 基准测试 是一种测量和评估软件性能指标的活动，用于建立某个时刻的性能基准，以便当系统发生软硬件变化时，重新进行基准测试以评估变化对性能影响。 直接、简单、易于比较，用于评估服务器的处理能力 可能不关心业务逻辑，所使用的查询和业务的真实性可以和业务环境没关系 压力测试： 对真实的业务数据进行测试，获得真实系统所能承受的压力 针对不同主题，所使用的数据和查询也是真实用到的（比如购物车流程，报名流程） 基准测试目的： 建立 mysql 服务器的性能基准线 确定当前 mysql 服务器运行情况 模拟比当系统更高的负载，以找出系统的扩展瓶颈 增加数据库并发，观察 QPS，TPS变化，确定并发量与性能最优的关系 测试不同的硬件、软件和操作系统配置 证明新的硬件设备是否配置正确 如何进行基准测试 对整个系统进行基准测试 从系统入口进行测试（如网站Web前端，手机APP前端） 优点： 能够测试整个系统的性能，包括web服务器缓存、数据库等 能反映出系统中各个组件接口间的性能问题体现真实性能状况 缺点：测试设计复杂，消耗时间长 单独对 mysql 进行基准测试 优点： 测试设计简单，消耗时间短 缺点：无法全面了解整个系统的性能基线 mysql 基准测试的常见指标 单位时间内所处理的事务数 （TPS） 单位时间内所处理的查询数 （QPS） 响应时间 平均响应时间、最小响应时间、最大响应时间、各时间所占百分比 并发量：同时处理的查询请求的数量 （并发量不等于连接数） 正在工作中的并发的操作数 或 同时工作的数量 设计基准测试 对整个系统还是某一组件 使用什么样的数据 准备基准测试及数据收集脚本 CPU使用率、IO、网络流量、状态与计数器信息等 运行基准测试 保存及分析基准测试 基准测试中容易忽略的问题 使用功能生产环境数据时，只使用了部分数据 推荐：使用生产环境数据库完全备份来测试 在多用户场景中，只做单用户的测试 推荐：使用多线程并发测试 在单服务器上测试分布式应用 推荐：使用相同架构进行测试 返回执行同一个查询 容易缓存命中，无法反应真实查询性能。 基准测试工具mysqlslapmysqlslap ： mysql自带的基准测试工具，随 mysql 一起安装。 可以模拟服务器负载，并输出相关统计信息 可以指定也可以自动生成查询语句 常用参数说明： --auto-generate-sql 由系统自动生成 SQL 脚本进行测试 --auto-generate-sql-add-autoincrement 在生成的表中增加自增ID --auto-generate-sql-load-type 指定测试中使用的查询类型 (混合、读写、删除) --auto-generate-sql-write-number 指定初始化数据时生成的数据量 --concurrency 指定并发线程的数量 --engine 指定要测试表的存储引擎，可以用逗号分割多个存储引擎 --no-drop 指定不清理测试数据 --iterations 指定测试运行的次数 --number-of-queries 指定每一个线程执行的查询数量 --debug-info 指定输出额外的内存及CPU统计信息 --number-int-cols 指定测试表中包含的 INT 类型列的数量 --number-char-cols 指定测试表中包含的 varchar 类型的数量 --create-schema 指定了用于执行测试的数据库的名字 --query 用户指定自定义 SQL 的脚本 --only-print 并不运行测试脚本，而是把生成的脚本打印出来 mysql 表中列不要太多，可以使用 --number-int-cols 和 --number-char-cols 对列的数量进行控制，得出列的数量和性能之间的关系。 sysbenchhttps://github.com/akopytov/sysbench 多线程基准测试工具 常用参数： --test 用于指定所要执行的测试类型，支持以下参数 Fileio 文件系统 I&#x2F;O 性能测试 cpu cpu 性能测试 memory 内存性能测试 Oltp 测试要指定具体的 lua 脚本（Lua脚本位于：sysbench-0.5&#x2F;sysbench&#x2F;tests&#x2F;db） --mysql-db 用于指定执行基准测试的数据库名 --mysql-table-engine 用于指定所使用的存储引擎 --oltp-tables-count 执行测试的表的数量 --oltp-table-size 指定每个表中的数据行数 --num-threads 指定测试的并发线程数量 --max-time 指定最大的测试时间 --report-interval 指定间隔多长时间输出一次统计信息 --mysql-user 指定执行测试的 mysql 用户 --mysql-password 指定执行测试的 mysql 用户的密码 prepare 用于准备测试数据 run 用于实际进行测试 cleanup 用于清理测试数据","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"mysql服务器参数介绍","slug":"mysql服务器参数介绍","date":"2019-09-15T15:15:10.000Z","updated":"2022-05-17T02:12:16.630Z","comments":true,"path":"2019/09/15/mysql服务器参数介绍/","link":"","permalink":"https://timmy6.github.io/2019/09/15/mysql%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"mysql 获取配置信息路径 命令行 1mysqld_safe --datadir=/data/sql_data 配置文件 1mysqld --help --verbose | grep -A 1 &#x27;Default options&#x27; 12Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf /usr/local/mysql/my.cnf ~/.my.cnf mysql 配置参数的作用域 全局参数 12mysql&gt; set global 参数名=参数值;mysql&gt; set @@global.参数名:=参数值; 全局参数配置完，需要重新退出才会生效。 会话参数 12mysql&gt; set [session] 参数名=参数值;mysql&gt; set @@session.参数名:=参数值; 内存配置相关的参数 确定可以使用的内存上限 32位操作系统只能使用3g以内的内存 设置的不能超过物理内存大小 确定mysql的每个连接使用的内存 sort_buffer_size join_buffer_size read_buffer_size read_rnd_buffer_size 确定需要为操作系统保留多少内存 如何为缓存池分配内存 Innodb_buffer_pool_size 总内存 -（每个线程所需要的内存 * 连接数） - 系统保留内存 key_buffer_size select sum(index_length) from information_schema.tables where engine&#x3D;’myisam’ IO配置相关的参数安全相关配置参数数据库结构优化良好的数据库逻辑设计 和 物理设计使查询语句尽量简单 尽量减少数据冗余 尽量避免数据维护中出现更新，插入和删除异常 插入异常：如果表中的某个实体随着另一个实体而存在。 更新异常：如果更改表中的某个实体的单独属性时，需要对多行进行更新。 删除异常：如果删除表中的某一实体则会导致其他实体的消失 节约数据存储空间 提高查询效率 设计步骤： 需求分析：全面了解产品设计的存储需求 存储需求 数据处理需求 数据的安全性和完整性 逻辑设计：设计数据的逻辑存储结构 数据实体之间的逻辑关系，解决数据冗余和数据维护异常","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"sql存储引擎对性能影响","slug":"mysql存储引擎对性能影响","date":"2019-09-10T15:15:10.000Z","updated":"2022-05-17T02:04:54.709Z","comments":true,"path":"2019/09/10/mysql存储引擎对性能影响/","link":"","permalink":"https://timmy6.github.io/2019/09/10/mysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%AF%B9%E6%80%A7%E8%83%BD%E5%BD%B1%E5%93%8D/","excerpt":"","text":"mysql 体系架构插件式存储引擎 存储引擎：MyISAMMySQL5.5之前版本默认存储引擎 会把索引缓存到内存中，数据缓存到系统中。 使用 MyISAM 存储引擎的表： 系统表 临时表：在排序、分组等操作中，当数量超过一定的大小之后，由查询优化器所建立的临时表。 创建一个 MyISAM 表MyISAM 存储引擎表由 MYD 和 MYI 组成。创建一张 MyISAM 表： 1create table good (id int(11) default NULL, name varchar(10) default NULL) engine=MyISAM default charset=utf8; 12345#进入到mysql 数据存储目录，/usr/local/mysql/data，对应的数据库目录下： 执行 ls -1ls -1good.MYD good.MYIgood_5008.sdi .MYD : 存储数据信息 .MYI : 存储索引信息 MyISAM 特性 并发性与锁级别 表级锁（不是行级锁） 对表中的数据修改时，需要对整个表加锁；对表中的数据进行读取的时候，也需要对整个表进行加共享锁（共享锁之间不会阻塞）。（读写和写入是互斥的，在一些情况在对表中数据进行读取的时候，可以在表末尾插入数据。对读写并发不是很好。） 表损坏修复（可能会导致数据丢失，不支持事务） 1234#对表进行检查check table tablename#对表恢复repair table tablename 或者使用命令行 myisamchk 对表进行修复，需要mysql停止服务，否则表可能造成更大损坏。 MyISAM 表支持的索引类型（支持全文索引） MyISAM 表支持数据压缩 （压缩后的表只能进行读操作，不能写）命令行： myisampack 限制： 版本 &lt; MySQL5.0时，默认表大小为4G；如果存储大表则要修改 MAX_Rows 和 AVG_ROW_LENGTH 版本 &gt; MySQL5.0时，默认支持为256TB； 适用场景： 非事务型应用（在线分析、报表，不涉及财务的应用） 只读类应用（只读报表等） 空间类应用（存储GPS类数据，支持空间函数） 存储引擎：InnoDBMySQL5.5及以后默认存储引擎。MySQL5.7以后 Innodb 支持全文索引和空间函数。Innodb 适合大多数 OLTP 应用。 InnoDB 是事务级存储引擎，完美支持行级锁，事务ACID特性。会同时在内存中缓存索引和数据。 具有在线热备份方案。 InnoDB 使用表空间进行数据存储。 123innodb_file_per_tableON : 数据会存储在独立表空间（ tablename.ibd ）OFF : 数据会存储在系统表空间（ ibdataX ） 1234#查看show variables like &#x27;innodb_file_per_table&#x27;#设置set global innodb_file_per_table=off 系统表空间和独立表空间要如何选择： 系统表空间无法简单的收缩文件大小（删除数据不会缩小；只能把整个数据库innodb表导出后，删除innodb相关的表空间文件后，重启mysql，表空间重建，重新导入数据） 独立表空间可以通过 optimize table 命令收缩系统文件 系统表空间会产生IO瓶颈 独立表空间可以同时向多个文件刷新数据 建议：对InnoDB使用独立表空间（mysql5.6之后默认是独立表空间） 把系统表空间中的表转移到独立表空间步骤： 1、使用 mysqldump 导出所有数据库表数据（如果数据存储过程有事件触发器一起导出） 2、停止mysql服务，修改参数，并删除innodb相关文件 3、重启mysql服务，重建innodb系统表空间 4、重新导入数据 Innodb状态检查 1mysql&gt; show engine innodb status","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"CentOS参数配置对mysql性能优化","slug":"CentOS参数配置对mysql性能优化","date":"2019-08-15T13:15:10.000Z","updated":"2022-05-16T09:59:32.770Z","comments":true,"path":"2019/08/15/CentOS参数配置对mysql性能优化/","link":"","permalink":"https://timmy6.github.io/2019/08/15/CentOS%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E5%AF%B9mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"CentOS系统参数优化推荐书籍：《Linux性能优化大师》 内核相关参数( /etc/sysctl.conf ) 查看内核(kernel)参数配置 1sysctl -a 网络性能参数123net.core.somaxconn=65535net.core.netdev_max_backlog=65535net.ipv4.tcp_max_syn_backlog=65535 http 请求经过三次握手建立网络连接，处于监听状态的端口，都会有自己的监听队列，参数 net.core.somaxconn 就决定了监听队列大小的长度，负载很大的服务器，就需要把这个参数修改大一些。 net.core.netdev_max_backlog 在每个网络接口接收数据包的速率 比 内核处理数据包的速率快的时候，允许被发送到队列中的数据包的最大数量。 net.ipv4.tcp_max_syn_backlog 还未获得对方连接的请求，可以保存到队列中的最大数目，超过这个数据大小的连接可能就会被抛弃。 12345678#查看有多少个请求由监听变成了链接#列出所有的端口，包括监听的和未监听的。netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 0.0.0.0:etlservicemgr 0.0.0.0:* LISTEN 1234567891011121314151617181920#列出所有的tcp协议的端口netstat -t#列出所有的UDP协议的端口netstat -ua#找出程序运行的端口netstat -ap | grep &#x27;程序名&#x27;#找出端口的程序名netstat -ap | grep &#x27;端口号&#x27;#显示路由表的信息netstat -r#显示接口信息netstat -i#分类统计各个协议的相关信息netstat -sa net.ipv4.tcp_fin_timeout 用于处理 tcp 连接等待状态的时间 1234#用于加快 tcp 连接的回收，tcp连接占满就会出现无法连接的状态net.ipv4.tcp_fin_timeout=10net.ipv4.tcp_tw_reuse=1net.ipv4.tcp_tw_recycle=1 tcp 连接接收和发送缓冲区大小的默认值和最大值（调整的大一些） 1234net.core.wmem_default = 87380net.core.wmem_max = 16777216net.core.rmem_default=87380net.core.rmem_max=16777216 减少失效连接所占用的 tcp 资源的数量，加快资源回收的效率（调整小一些） 12345678#tcp 发送 keepalive 的时间间隔，用户确认tcp连接是否有效，单位秒net.ipv4.tcp_keepalive_time=120#当发送探测点消息没有响应时，重发该消息的时间间隔，单位秒net.ipv4.tcp_keepalive_intvl=30#认定 tcp 连接失效之前，最多发送多少个 keepalive 消息net.ipv4.tcp_keepalive_probes=3 内存性能参数1kernel.shmmax = 4294967295 这个参数应该设置的足够大，以便能在一个共享内存段下容纳下整个的 Innodb 缓冲池的大小。（如果太低，就需要创建多个共享内存段，可能导致系统性能下降，原因是当实例启动的时候，多个共享内存段可能会导致当时系统性能轻微的性能下降，其他时候不会有影响） 这个值的大小对 64 位 linux 系统，可取的最大值为物理内存值-1byte，建议值为大于物理内存的一半，一般取值大于Innodb缓冲池的大小即可，可以取物理内存-1byte。 1vm.swappiness = 0 这个参数当内存不足时，会对性能产生比较明显的影响 Linux 系统内存交换区：在Linux系统安装时，都会有一个特殊的磁盘分区，称之为系统交换分区。使用 free -m 在系统中查看，可以看到类似下面的内容，其中 swap 就是交换分区。 1234[root@VM_0_3_centos ~]# free -m total used free shared buff/cache availableMem: 3790 1763 235 0 1791 1732Swap: 0 0 0 当操作系统因为没有足够的内存时，就会将一些虚拟内存写到磁盘的交换区中，这样就会发生内存交换。 在MySQL 服务器上是或否要使用交换分区有一些争议：在MySQL服务所在的Linux系统上完全禁用交换分区。带来的风险：降低操作系统的性能；容易造成内存溢出，崩溃，或都被操作系统kill掉。 在MySQL服务器上保留交换分区还是很有必要的，但是要控制何时使用交换分区。 1vm.swappiness = 0 参数告诉Linux内核除非虚拟内存完全满了，否则不要使用交换分区。 增加资源限制 /etc/security/limit.conf这个文件实际上市 Linux PAM 也就是插入式认证模块的配置文件。打开文件数的限制。 12* soft nofile 65535* hard nofile 65535 用于控制打开文件的数量，加到 limit.conf 文件的末尾即可。 增加到 65535 以保证可以打开足够多的文件句柄。 表示对所有用户有效 soft 指的是当前系统生效的设置 hard 表明系统中所有设定的最大值 nofile 表示所限制的资源是打开文件的最大数目 65536 就是限制的数量 这个文件修改需要重启系统才能生效。 磁盘调度策略/sys/block/devname/queue/scheduler 1234cat /sys/block/vda/queue/schedulercat /sys/block/sda/queue/schedulernoop anticipatory deadline [cfq] noop（电梯式调度策略） ：NOOP 实现了一个 FIFO 队列，它像电梯的工作方法一样对 I&#x2F;O 请求进行组织，当有一个新的请求到来时，它将请求合并到最近的请求之后，以此来保证请求同一介质。 NOOP 倾向饿死读而立于写，因此 NOOP 对于闪存设备、RAM及嵌入式系统是最好的选择。 deadline（截止时间调度策略）： deadline 确保了一个截止时间内服务请求，这个截止时间是可调整的，而默认读期限短于写期限。 这样就防止了写操作因为不能被读取而饿死的现象， deadline 对数据库类应用是最好的选择。 anticipatory （预料I&#x2F;O调度策略）： 本质上与deadline 一样，但在最后一次读操作后，要等待6ms，才能继续进行对其他I&#x2F;O请求进行调度。 它会在每个6ms中插入新的I&#x2F;O操作，而会将一些小写入流合并成一个大写入流，用写入延时换取最大的写入吞吐量。 AS适合于写入较多的环境，比如文件服务器，AS对数据库环境表现很差。","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"影响数据库性能的因素","slug":"影响数据库性能的因素","date":"2019-08-10T15:15:10.000Z","updated":"2022-05-16T09:56:55.733Z","comments":true,"path":"2019/08/10/影响数据库性能的因素/","link":"","permalink":"https://timmy6.github.io/2019/08/10/%E5%BD%B1%E5%93%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E6%80%A7%E8%83%BD%E7%9A%84%E5%9B%A0%E7%B4%A0/","excerpt":"","text":"影响数据库性能的因素 影响数据库性能的因素 sql查询速度 服务器硬件 网卡流量 磁盘IO 网卡流量 大表 大事务 QPS &amp; TPSQPS：每秒钟处理的查询量 eg： 一个cpu 10ms 处理 1个sql， 1s 处理 100个sql，那么QPS&lt;&#x3D;100 一个cpu 100ms处理 1个sql，QPS&lt;&#x3D;10 TPS： 超高的QPS和TPS带来的风险：效率低下的SQL 数据库的性能问题大部分都是由于sql的慢查询造成的，大部分问题可以通过对sql的优化得到解决。 并发量 &amp; CPU使用率并发量：同一时间处理的请求的数量；与同时连接数不同。 空闲的百分比值越高空闲率越高。 大量的并发和超高的CPU使用率 大量的并发：数据库连接数被占满。（max_connections默认100） 超高的CPU使用率：因cpu资源耗尽而出现宕机。 磁盘IO数据库备份远程同步计划任务会导致IO达到峰值。 最好不要在主库上数据库备份 大型活动前取消这类计划 风险： 磁盘IO性能突然下降（使用更快的磁盘设备） 其他大量消耗磁盘性能的计划任务（调整计划任务，做好磁盘维护） 数据库扩展需要完整性和一致性 网卡流量网卡IO被占满（1000Mb&#x2F;8 约等于 100MB） 如何避免无法连接数据库的情况： 减少从服务器的数量 进行分级缓存 避免使用 select * 进行查询 分离业务网络和服务器网络 大表 记录行数巨大，单标超过千万行 表数据文件巨大，表数据文件超过10G 第一、 大表对查询的影响： 慢查询：很难再一定的时间内过滤出所需要的数据。 查询的维度区分度比较低（只有几个维度，例如三方登录字段：只有微信、qq几个有限的维度，查询的数据量就比较大），会产生大量磁盘IO，降低磁盘效率。 第二、大表对DDL操作的影响： 建立索引需要很长的时间 Mysql 版本 &lt; 5.5 建立索引会锁表 Mysql 版本 &gt;&#x3D; 5.5 虽然不会锁表，但会引起主从延迟 大表对DDL操作的影响：修改表结构需要长时间锁表。 风险：会造成长时间的主从延迟。影响正常的数据操作。 如何处理数据库中的大表： 分库分表把一张大表分成多个小表。 难点： 分表主键的选择；分表后跨分区数据的查询和统计。 大表的历史数据归档： 减少对前后端业务的影响 难点：归档时间点的选择。如何进行归档操作。 大事务 什么是事务？ 事务是数据库系统区别于其他一切文件系统的重要特征之一 事务是一组具有原子性的sql语句，或是一个独立的工作单元 特点：原子性、一致性、隔离性、持久性 事务原子性 atomicity： 一个事务被视为一个不可分割的最小工作单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中的一部分操作 银行例子：1. 取钱 2.存钱 事务的一致性 consistency： 一致性是指事务将数据库从一种一致性状态转换到另外一种一致性状态，在事务开始之前和事务结束后数据库中数据的完整性没有被破坏 事务的隔离性 isolation： 隔离性要求一个事务对数据库中数据的修改，在未提交完成前对于其它事务是不可见的 SQL标准中定义的四种隔离级别： 未提交读（READ uncommited） 已提交读（READ commited）（不可重复读） 可重复读（repeatable READ） 可串行化（serializable） 隔离性由低-&gt;高，并发性由高-&gt;低 事务的持久性 durability： 一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，已经提交的修改数据也不会丢失 大事务： 运行时间比较长，操作的数据比较多的事务 风险： 锁定太多的数据，造成大量的阻塞和锁超时 回滚时所需时间比较长 执行时间长，容易造成主从延迟 如何处理大事务： 避免一次处理太多的数据 移除不必要在事务中的select操作","categories":[{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"}]},{"title":"go interface","slug":"go-interface","date":"2019-07-25T15:15:10.000Z","updated":"2022-05-16T09:51:17.074Z","comments":true,"path":"2019/07/25/go-interface/","link":"","permalink":"https://timmy6.github.io/2019/07/25/go-interface/","excerpt":"","text":"interface 接口（interface）无法被实例化. 接口类型也算是引用类型。 接口是根据方法集合区分的（定义的所有方法）。 代表某一类特征（Duck Typing） 接口的使用1234type Animal interface &#123; Eat(foot string) Run()&#125; 123456789type Person struct &#123; &#125;func (p *Person)Eat(foot string) &#123; &#125;func (p *Person)Run() &#123; &#125; Person 实现了 Eat(foot string) 方法和 Run() 方法, 也就是说 Person 实现了接口 Animal ，并且这种实现接口的方式是无侵入的. 判断一个类型是否实现了某个接口： 两个方法的签名需要完全一致 两个方法的名称要一模一样 接口的另一种使用 可以把实现接口的类型，赋值给对应的接口类型变量 12var p Person = &amp;Person&#123;&#125;var a Animal = p 变量 p 是接口变量 a 的实际值，也叫动态值. 变量 p 的类型 Person 叫做接口变量 a 的实际类型，也叫 动态类型. 类型 Animal 是接口变量 a 的 静态类型，是永远不会变化的。（相对于动态类型是变化的跟我们的赋值有关） 接口类型变量的零值是nil。 当给一个接口变量赋值的时候，该变量的动态类型和动态值会一起被存储在一个专用的数据结构中。 其实，这个接口变量的值是这个专用数据结构的一个实例，而不是我们赋给改变量的那个实际值。 这个专用的数据结构在 Go 语言的 runtime 包中叫 iface 。iface的实例会包含两个指针，一个是指向类型信息的指针，另一个是指向动态值的指针。这里的类型信息是由另一个专用数据结构的实例承载的，其中包含了动态值的类型，以及使它实现了接口的方法和调用他们的途径。 使用 == 判断接口变量是否为 nil： 12345678var p Personvar a Animal = p// p == nil , a != nilif a == nil &#123; fmt.Println(&quot;a == nil&quot;)&#125;else&#123; fmt.Println(&quot;a != nil&quot;)&#125; 对一个接口变量只声明不初始化，或者直接给接口变量赋值 nil，这时接口变量值为 nil。 接口的组合接口的组合：接口类型之间的嵌入。 建议声明小接口，更容易组合接口，扩展性强、比较灵活。 组合的接口之间有同名的方法（方法签名不同也不行）就会编译报错。 看Go标准库 io 包： 123456789101112type Reader interface &#123; Read(p []byte) (n int, err error)&#125;type Writer interface &#123; Write(p []byte) (n int, err error)&#125;type ReadWriter interface &#123; Reader Writer&#125; 同时实现了 Reader 接口和 Writer 接口，就相当于实现了组合接口 ReadWriter。 1234567891011type Closer interface &#123; Close() error&#125;type ReadCloser interface &#123; Reader Closer&#125;type WriteCloser interface &#123; Writer Closer&#125; nil 接口变量123var p Person = nilvar a Animal = p// p == nil , a != nil Person 实现了接口，p 是一个nil变量，赋值给接口类型变量 a，a 依然可以调用接口实现的方法。方法接收者必须是指针类型才能调用接口实现的方法。 Duck TypingDuck Typing ，看起来像鸭子，它就是鸭子。 Go语言对象没有继承和多态，只有封装性。 协议注重关注方法的实现，而很少关注类型。 只要实现了B协议方法的实体，是B协议类型的入参， 都可以作为的传入。 变相实现了继承和多态，实现多个协议，就可以是类似多继承。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"go mod","slug":"go-mod","date":"2019-07-16T14:15:10.000Z","updated":"2022-05-16T09:48:42.679Z","comments":true,"path":"2019/07/16/go-mod/","link":"","permalink":"https://timmy6.github.io/2019/07/16/go-mod/","excerpt":"","text":"go modgo mod 命令管理包 在当前目录初始化生成 go.mod 文件 1go mod init 下载包依赖到本地缓存 本地缓存目录：$GOPATH/pkg/mod 1go mod download 编辑go.mod 格式化go.mod文件 1go mod edit -fmt 以json的形式查看依赖 12go list -m -json allgo mod edit -json 打印模块依赖图 1go mod graph 拉取缺少的模块，移除不用的模块 1go mod tidy 将依赖复制到vendor下 1go mod vendor 验证依赖是否正确 1go mod verify 需要依赖的原因 1go mod why go.mod 编写四个命令: module : 指定包的名字（路径） require: 指定的依赖项模块 replace: 可以替换依赖项模块 exclude: 可以忽略依赖项模块 eg: 12345678910111213141516171819module cocktailgo 1.12require github.com/gin-gonic/gin v1.4.0replace ( golang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2 =&gt; github.com/golang/crypto v0.0.0-20190513172903-22d7a77e9e5f golang.org/x/net =&gt; github.com/golang/net v0.0.0-20190514140710-3ec191127204 golang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3 =&gt; github.com/golang/net v0.0.0-20190514140710-3ec191127204 golang.org/x/net v0.0.0-20190503192946-f4e77d36d62c =&gt; github.com/golang/net v0.0.0-20190514140710-3ec191127204 golang.org/x/sync =&gt; github.com/golang/sync v0.0.0-20190423024810-112230192c58 golang.org/x/sys v0.0.0-20190222072716-a9d3bda3a223 =&gt; github.com/golang/sys v0.0.0-20190516110030-61b9204099cb golang.org/x/sys v0.0.0-20190412213103-97732733099d =&gt; github.com/golang/sys v0.0.0-20190516110030-61b9204099cb golang.org/x/text v0.3.0 =&gt; github.com/golang/text v0.3.2 golang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e =&gt; github.com/golang/tools v0.0.0-20190517183331-d88f79806bbd) 使用 replace 可以把 golang.rog/ 替换成 github/ 。 一些其他使用 执行 go run server.go 运行代码会发现 go mod 会自动查找依赖自动下载。 go module 安装 package 的原則是先拉最新的 release tag，若无tag则拉最新的commit。 go 会自动生成一个 go.sum 文件来记录 dependency tree。 来检查可以升级的 package 1go list -m -u all 升级依赖版本1go get -u need-upgrade-package 或者 1go get -u Modules官方介绍：https://github.com/golang/go/wiki/Modules 一些遇到的问题 go 1.10.3 版本Bug。需要升级版本,删除 /usr/local/Cellar/go/ 目录下文件，重新安装。 原因参考：https://github.com/golang/go/issues?q=milestone%3AGo1.10.4 1234go get github.com/beego/bee# github.com/beego/bee/usr/local/Cellar/go/1.10.3/libexec/pkg/tool/darwin_amd64/link: /usr/local/Cellar/go/1.10.3/libexec/pkg/tool/darwin_amd64/link: combining dwarf failed: Unknown load command 0x32 (50) go mod init 报错 123456go mod go: modules disabled inside GOPATH/src by GO111MODULE=auto; see &#x27;go help modules&#x27;# 设置环境变量解决 GO111MODULE 默认值为auto 其他：on 、offexport GO111MODULE=on","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"Golang不同类型比较","slug":"不同类型比较","date":"2019-06-16T14:15:10.000Z","updated":"2022-05-16T09:39:13.858Z","comments":true,"path":"2019/06/16/不同类型比较/","link":"","permalink":"https://timmy6.github.io/2019/06/16/%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E6%AF%94%E8%BE%83/","excerpt":"","text":"9.13 Golang不同类型比较在日常开发过程中难免会遇到各个类型的变量的比较以及运算操作，这里做了一些简单的汇总，希望能给各位同学在开发中带来帮助。 这里先上一波关系运算符&#x3D;&#x3D;，!&#x3D;，&lt;，&lt;&#x3D;，&gt; 和 &gt;&#x3D;。 float浮点数比较golang 支持两种浮点float32和float64，众所众知，涉及浮点数比较或运算是会遇到精度问题，具体要根据golang实现IEEE 754的情况定。 默认情况下，float32精度是小数后7位，float64精度是小数点后15位。 如例1： 123456789var a float32 = 1.00000001var b float32 = 1.000000000001var c float32 = 1.0000001var d float32 = 1.000000000001fmt.Println(a == b) //truefmt.Println(a &gt; b) //falsefmt.Println(c == d) //falsefmt.Println(c &gt; d) //true float64 123456789var a float64 = 1.0000000000000001var b float64 = 1.000000000000000001var c float64 = 1.000000000000001var d float64 = 1.0000000000000000001fmt.Println(a == b) //truefmt.Println(a &gt; b) //falsefmt.Println(c == d) //falsefmt.Println(c &gt; d) //true 这里写了一个根据精度进行float比较的简单的类，注意最大精度为小数点后15位，超出会丢失精度。 示例： 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;fmt&quot; &quot;math&quot;)type Floater struct &#123; Accuracy float64 //精度,最大为小数点后15位&#125;//是否相等func (f Floater) IsEqual(a, b float64) bool &#123; return math.Abs(a-b) &lt; f.Accuracy&#125;//0为相等 1为a大于b -1为a小于bfunc (f Floater) Bccomp(a, b float64) int8 &#123; if math.Abs(a-b) &lt; f.Accuracy &#123; return 0 &#125; if math.Max(a, b) == a &#123; return 1 &#125; else &#123; return -1 &#125;&#125;func main() &#123; f := Floater&#123;Accuracy: 0.000000000001&#125; var a float64 = 1.0000000002 var b float64 = 1.0000000001 fmt.Println(f.Bccomp(a, b)) //1 fmt.Println(f.Bccomp(b, a)) //-1 fmt.Println(f.Bccomp(a, a)) //0&#125; 顺便讲一下如何实现保留小数点后2位如何实现 123456789101112 //方法1a := 2.556v, _ := strconv.ParseFloat(fmt.Sprintf(&quot;%.2f&quot;, a), 64)fmt.Println(v) //2.56 //方法2 v = math.Trunc(a*1e2+0.5) * 1e-2fmt.Println(v) //2.56//方法3n10 := math.Pow10(2)v = math.Trunc((a+0.5/n10)*n10) / n10fmt.Println(v) 指针类型比较1234a := &quot;hello&quot;b := &amp;ac := &amp;afmt.Println(b == c) 当变量是相同或者都为nil时，指针值相等。 interface类型比较123456789101112131415161718192021222324252627282930313233type I1 interface &#123; f()&#125;type I2 interface &#123; f()&#125;type S1 struct &#123; name string&#125;func (s S1) f() &#123;&#125;type S2 struct &#123; name string&#125;func (s S2) f() &#123; &#125;func main() &#123; var a, b, c, d I1 var e I2 a = S1&#123;&quot;hello&quot;&#125; b = S1&#123;&quot;hello&quot;&#125; c = S1&#123;&quot;world&quot;&#125; d = S2&#123;&quot;hello&quot;&#125; fmt.Println(a == b) //true fmt.Println(a == c) //false fmt.Println(a == d) //false fmt.Println(a == e) //false&#125; 比较 slice&#x2F;struct&#x2F;map这三个都可以用reflect.DeepEqual来判断是否相等 123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type S struct &#123; s string&#125;func main() &#123; s1 := S&#123;s: &quot;hello&quot;&#125; s2 := S&#123;s: &quot;hello&quot;&#125; if reflect.DeepEqual(s1, s2) &#123; fmt.Println(s1, &quot;==&quot;, s2) &#125; a1 := []int&#123;1, 2&#125; a2 := []int&#123;1, 2&#125; if reflect.DeepEqual(a1, a2) &#123; fmt.Println(a1, &quot;==&quot;, a2) &#125; m1 := map[int]string&#123;1: &quot;a&quot;, 2: &quot;b&quot;&#125; m2 := map[int]string&#123;1: &quot;a&quot;, 2: &quot;b&quot;&#125; if reflect.DeepEqual(m1, m2) &#123; fmt.Println(m1, &quot;==&quot;, m2) &#125;&#125;","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"channel 实现原理分析","slug":"channel","date":"2019-06-08T13:05:10.000Z","updated":"2022-05-16T09:34:29.826Z","comments":true,"path":"2019/06/08/channel/","link":"","permalink":"https://timmy6.github.io/2019/06/08/channel/","excerpt":"","text":"#channel 实现原理分析 channel一个类型管道，通过它可以在goroutine之间发送和接收消息。它是Golang在语言层面提供的goroutine间的通信方式。 众所周知，Go依赖于称为CSP（Communicating Sequential Processes）的并发模型，通过Channel实现这种同步模式。Go并发的核心哲学是不要通过共享内存进行通信; 相反，通过沟通分享记忆。 下面以简单的示例来演示Go如何通过channel来实现通信。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;time&quot;)func goRoutineA(a &lt;-chan int) &#123; val := &lt;-a fmt.Println(&quot;goRoutineA received the data&quot;, val)&#125;func goRoutineB(b chan int) &#123; val := &lt;-b fmt.Println(&quot;goRoutineB received the data&quot;, val)&#125;func main() &#123; ch := make(chan int, 3) go goRoutineA(ch) go goRoutineB(ch) ch &lt;- 3 time.Sleep(time.Second * 1)&#125; 结果为： goRoutineA received the data 3 上面只是个简单的例子，只输出goRoutineA ，没有执行goRoutineB，说明channel仅允许被一个goroutine读写。 说道channel这里不得不提通道的结构hchan。 hchan源代码在src&#x2F;runtime&#x2F;chan.go 123456789101112131415161718192021222324type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125; 说明： qcount uint &#x2F;&#x2F; 当前队列中剩余元素个数dataqsiz uint &#x2F;&#x2F; 环形队列长度，即缓冲区的大小，即make（chan T，N），N.buf unsafe.Pointer &#x2F;&#x2F; 环形队列指针elemsize uint16 &#x2F;&#x2F; 每个元素的大小closed uint32 &#x2F;&#x2F; 表示当前通道是否处于关闭状态。创建通道后，该字段设置为0，即通道打开; 通过调用close将其设置为1，通道关闭。elemtype *_type &#x2F;&#x2F; 元素类型，用于数据传递过程中的赋值；sendx uint和recvx uint是环形缓冲区的状态字段，它指示缓冲区的当前索引 - 支持数组，它可以从中发送数据和接收数据。recvq waitq &#x2F;&#x2F; 等待读消息的goroutine队列sendq waitq &#x2F;&#x2F; 等待写消息的goroutine队列lock mutex &#x2F;&#x2F; 互斥锁，为每个读写操作锁定通道，因为发送和接收必须是互斥操作。 这里sudog代表goroutine。 创建channel 有两种，一种是带缓冲的channel，一种是不带缓冲的channel 12345// 带缓冲ch := make(chan Task, 3)// 不带缓冲ch := make(chan int) 这里我们先讨论带缓冲 1ch := make(chan int, 3) 创建通道后的缓冲通道结构 12345678910111213141516171819202122232425262728hchan struct &#123; qcount uint : 0 dataqsiz uint : 3 buf unsafe.Pointer : 0xc00007e0e0 elemsize uint16 : 8 closed uint32 : 0 elemtype *runtime._type : &amp;&#123; size:8 ptrdata:0 hash:4149441018 tflag:7 align:8 fieldalign:8 kind:130 alg:0x55cdf0 gcdata:0x4d61b4 str:1055 ptrToThis:45152 &#125; sendx uint : 0 recvx uint : 0 recvq runtime.waitq : &#123;first:&lt;nil&gt; last:&lt;nil&gt;&#125; sendq runtime.waitq : &#123;first:&lt;nil&gt; last:&lt;nil&gt;&#125; lock runtime.mutex : &#123;key:0&#125;&#125; 源代码 12345func makechan(t *chantype, size int) *hchan &#123; elem := t.elem ...&#125; 如果我们创建一个带buffer的channel，底层的数据模型如下图： 向channel写入数据1ch &lt;- 3 底层hchan数据流程如图 发送操作概要 1、锁定整个通道结构。 2、确定写入。尝试recvq从等待队列中等待goroutine，然后将元素直接写入goroutine。 3、如果recvq为Empty，则确定缓冲区是否可用。如果可用，从当前goroutine复制数据到缓冲区。 4、如果缓冲区已满，则要写入的元素将保存在当前正在执行的goroutine的结构中，并且当前goroutine将在sendq中排队并从运行时挂起。 5、写入完成释放锁。 这里我们要注意几个属性buf、sendx、lock的变化。 流程图 从channel读取操作几乎和写入操作相同 代码 1234func goRoutineA(a &lt;-chan int) &#123; val := &lt;-a fmt.Println(&quot;goRoutineA received the data&quot;, val)&#125; 底层hchan数据流程如图 这里我们要注意几个属性buf、sendx、recvx、lock的变化。 读取操作概要 1、先获取channel全局锁 2、尝试sendq从等待队列中获取等待的goroutine， 3、 如有等待的goroutine，没有缓冲区，取出goroutine并读取数据，然后唤醒这个goroutine，结束读取释放锁。 4、如有等待的goroutine，且有缓冲区（此时缓冲区已满），从缓冲区队首取出数据，再从sendq取出一个goroutine，将goroutine中的数据存入buf队尾，结束读取释放锁。 5、如没有等待的goroutine，且缓冲区有数据，直接读取缓冲区数据，结束读取释放锁。 6、如没有等待的goroutine，且没有缓冲区或缓冲区为空，将当前的goroutine加入recvq排队，进入睡眠，等待被写goroutine唤醒。结束读取释放锁。 流程图 recvq和sendq 结构recvq和sendq基本上是链表，看起来基本如下 selectselect就是用来监听和channel有关的IO操作，当 IO 操作发生时，触发相应的动作。 一个简单的示例如下 123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;fmt&quot; &quot;time&quot;)func goRoutineD(ch chan int, i int) &#123; time.Sleep(time.Second * 3) ch &lt;- i&#125;func goRoutineE(chs chan string, i string) &#123; time.Sleep(time.Second * 3) chs &lt;- i&#125;func main() &#123; ch := make(chan int, 5) chs := make(chan string, 5) go goRoutineD(ch, 5) go goRoutineE(chs, &quot;ok&quot;) select &#123; case msg := &lt;-ch: fmt.Println(&quot; received the data &quot;, msg) case msgs := &lt;-chs: fmt.Println(&quot; received the data &quot;, msgs) default: fmt.Println(&quot;no data received &quot;) time.Sleep(time.Second * 1) &#125;&#125; 运行程序，因为当前时间没有到3s，所以select 选择defult no data received 修改程序，我们注释掉default，并多执行几次结果为 received the data 5 received the data ok received the data ok received the data ok select语句会阻塞，直到监测到一个可以执行的IO操作为止，而这里goRoutineD和goRoutineE睡眠时间是相同的，都是3s，从输出可看出，从channel中读出数据的顺序是随机的。 再修改代码，goRoutineD睡眠时间改成4s 1234func goRoutineD(ch chan int, i int) &#123; time.Sleep(time.Second * 4) ch &lt;- i&#125; 此时会先执行goRoutineE，select 选择case msgs :&#x3D; &lt;-chs。 range可以持续从channel读取数据，一直到channel被关闭，当channel中没有数据时会阻塞当前goroutine，与读channel时阻塞处理机制一样。 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;time&quot;)func goRoutineD(ch chan int, i int) &#123; for i := 1; i &lt;= 5; i++&#123; ch &lt;- i &#125;&#125;func chanRange(chanName chan int) &#123; for e := range chanName &#123; fmt.Printf(&quot;Get element from chan: %d\\n&quot;, e) if len(chanName) &lt;= 0 &#123; // 如果现有数据量为0，跳出循环 break &#125; &#125;&#125;func main() &#123; ch := make(chan int, 5) go goRoutineD(ch, 5) chanRange(ch)&#125; 结果：Get element from chan: 1Get element from chan: 2Get element from chan: 3Get element from chan: 4Get element from chan: 5 死锁（deadlock）指两个或两个以上的协程的执行过程中，由于竞争资源或由于彼此通信而造成的一种阻塞的现象。 在非缓冲信道若发生只流入不流出，或只流出不流入，就会发生死锁。 下面是一些死锁的例子 1、 123456package mainfunc main() &#123; ch := make(chan int) ch &lt;- 3&#125; 上面情况，向非缓冲通道写数据会发生阻塞，导致死锁。解决办法创建缓冲区 ch :&#x3D; make(chan int，3) 2、 12345678910package mainimport ( &quot;fmt&quot;)func main() &#123; ch := make(chan int) fmt.Println(&lt;-ch)&#125; 向非缓冲通道读取数据会发生阻塞，导致死锁。 解决办法开启缓冲区，先向channel写入数据。 3、 123456789package mainfunc main() &#123; ch := make(chan int, 3) ch &lt;- 3 ch &lt;- 4 ch &lt;- 5 ch &lt;- 6&#125; 写入数据超过缓冲区数量也会发生死锁。解决办法将写入数据取走。 死锁的情况有很多这里不再赘述。 还有一种情况，向关闭的channel写入数据，不会产生死锁，产生panic。 123456789package mainfunc main() &#123; ch := make(chan int, 3) ch &lt;- 1 close(ch) ch &lt;- 2&#125; 解决办法别向关闭的channel写入数据。 参考： https://codeburst.io/diving-deep-into-the-golang-channels-549fd4ed21a8 https://speakerdeck.com/kavya719/understanding-channels?slide=14 https://my.oschina.net/renhc/blog/2246871","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"匿名函数和闭包","slug":"匿名函数和闭包","date":"2019-06-02T13:05:10.000Z","updated":"2022-05-16T07:06:13.501Z","comments":true,"path":"2019/06/02/匿名函数和闭包/","link":"","permalink":"https://timmy6.github.io/2019/06/02/%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%E5%92%8C%E9%97%AD%E5%8C%85/","excerpt":"","text":"匿名函数：顾名思义就是没有名字的函数。很多语言都有如：java，js,php等，其中js最钟情。匿名函数最大的用途是来模拟块级作用域,避免数据污染的。 今天主要讲一下Golang语言的匿名函数和闭包。 匿名函数示例： 1、 123456789101112package mainimport ( &quot;fmt&quot;)func main() &#123; f:=func()&#123; fmt.Println(&quot;hello world&quot;) &#125; f()//hello world fmt.Printf(&quot;%T\\n&quot;, f) //打印 func()&#125; 2、带参数 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)func main() &#123; f:=func(args string)&#123; fmt.Println(args) &#125; f(&quot;hello world&quot;)//hello world //或 (func(args string)&#123; fmt.Println(args) &#125;)(&quot;hello world&quot;)//hello world //或 func(args string) &#123; fmt.Println(args) &#125;(&quot;hello world&quot;) //hello world&#125; 3、带返回值 1234567891011package mainimport &quot;fmt&quot;func main() &#123; f:=func()string&#123; return &quot;hello world&quot; &#125; a:=f() fmt.Println(a)//hello world&#125; 4、多个匿名函数 12345678910111213141516171819package mainimport &quot;fmt&quot;func main() &#123; f1,f2:=F(1,2) fmt.Println(f1(4))//6 fmt.Println(f2())//6&#125;func F(x, y int)(func(int)int,func()int) &#123; f1 := func(z int) int &#123; return (x + y) * z / 2 &#125; f2 := func() int &#123; return 2 * (x + y) &#125; return f1,f2&#125; 闭包（closure）闭包：说白了就是函数的嵌套，内层的函数可以使用外层函数的所有变量，即使外层函数已经执行完毕。 示例： 1、 12345678910111213141516171819package mainimport &quot;fmt&quot;func main() &#123; a := Fun() b:=a(&quot;hello &quot;) c:=a(&quot;hello &quot;) fmt.Println(b)//worldhello fmt.Println(c)//worldhello hello &#125;func Fun() func(string) string &#123; a := &quot;world&quot; return func(args string) string &#123; a += args return a &#125;&#125; 2、 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;func main() &#123; a := Fun() d := Fun() b:=a(&quot;hello &quot;) c:=a(&quot;hello &quot;) e:=d(&quot;hello &quot;) f:=d(&quot;hello &quot;) fmt.Println(b)//worldhello fmt.Println(c)//worldhello hello fmt.Println(e)//worldhello fmt.Println(f)//worldhello hello&#125;func Fun() func(string) string &#123; a := &quot;world&quot; return func(args string) string &#123; a += args return a &#125;&#125; 注意两次调用F()，维护的不是同一个a变量。 3、 12345678910111213141516171819package mainimport &quot;fmt&quot;func main() &#123; a := F() a[0]()//0xc00004c080 3 a[1]()//0xc00004c080 3 a[2]()//0xc00004c080 3&#125;func F() []func() &#123; b := make([]func(), 3, 3) for i := 0; i &lt; 3; i++ &#123; b[i] = func() &#123; fmt.Println(&amp;i,i) &#125; &#125; return b&#125; 闭包通过引用的方式使用外部函数的变量。例中只调用了一次函数F,构成一个闭包，i 在外部函数B中定义，所以闭包维护该变量 i ，a[0]、a[1]、a[2]中的 i 都是闭包中 i 的引用。因此执行,i 的值已经变为3，故再调用a0时的输出是3而不是0。 4、如何避免上面的BUG ，用下面的方法，注意和上面示例对比。 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport &quot;fmt&quot;func main() &#123; a := F() a[0]() //0xc00000a0a8 0 a[1]() //0xc00000a0c0 1 a[2]() //0xc00000a0c8 2&#125;func F() []func() &#123; b := make([]func(), 3, 3) for i := 0; i &lt; 3; i++ &#123; b[i] = (func(j int) func() &#123; return func() &#123; fmt.Println(&amp;j, j) &#125; &#125;)(i) &#125; return b&#125;或者package mainimport &quot;fmt&quot;func main() &#123; a := F() a[0]() //0xc00004c080 0 a[1]() //0xc00004c088 1 a[2]() //0xc00004c090 2&#125;func F() []func() &#123; b := make([]func(), 3, 3) for i := 0; i &lt; 3; i++ &#123; j := i b[i] = func() &#123; fmt.Println(&amp;j, j) &#125; &#125; return b&#125; 每次 操作仅将匿名函数放入到数组中，但并未执行，并且引用的变量都是 i，随着 i 的改变匿名函数中的 i 也在改变，所以当执行这些函数时，他们读取的都是环境变量 i 最后一次的值。解决的方法就是每次复制变量 i 然后传到匿名函数中，让闭包的环境变量不相同。 5、 12345678910111213package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(F())//2&#125;func F() (r int) &#123; defer func() &#123; r++ &#125;() return 1&#125; 输出结果为2，即先执行r&#x3D;1 ,再执行r++。 6、递归函数 还有一种情况就是必须用都闭包，就是递归函数。 123456789101112131415package mainimport &quot;fmt&quot;func F(i int) int &#123; if i &lt;= 1 &#123; return 1 &#125; return i * F(i-1)&#125;func main() &#123; var i int = 3 fmt.Println(i, F(i))// 3 6&#125; 7、斐波那契数列(Fibonacci) 这个数列从第3项开始，每一项都等于前两项之和。 1234567891011121314151617181920package mainimport &quot;fmt&quot;func fibonaci(i int) int &#123; if i == 0 &#123; return 0 &#125; if i == 1 &#123; return 1 &#125; return fibonaci(i-1) + fibonaci(i-2)&#125;func main() &#123; var i int for i = 0; i &lt; 10; i++ &#123; fmt.Printf(&quot;%d\\n&quot;, fibonaci(i)) &#125;&#125; 小结：匿名函数和闭包其实是一回事儿，匿名函数就是闭包。匿名函数给编程带来灵活性的同时也容易产生bug，在使用过程当中要多注意函数的参数，及可接受的参数的问题。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"单例模式","slug":"single","date":"2019-05-22T13:05:10.000Z","updated":"2022-05-16T06:49:47.526Z","comments":true,"path":"2019/05/22/single/","link":"","permalink":"https://timmy6.github.io/2019/05/22/single/","excerpt":"","text":"单例模式是常用的模式之一，一般介绍的单例模式有 饿汉式 和 懒汉式 等，不管那种模式最终目的只有一个，就是只实例化一次，仅允许一个实例存在。 GO语言实现单例模式相对简单，这里考虑到并发，用到了sync.Mutex 和结构体sync.Once。 示例： 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;sync&quot;)var ( lock *sync.Mutex = &amp;sync.Mutex&#123;&#125; instance *Singleton)type Singleton struct &#123;&#125;func GetInstance() *Singleton &#123; if instance == nil &#123; lock.Lock() defer lock.Unlock() if instance == nil &#123; instance = &amp;Singleton&#123;&#125; fmt.Println(&quot;instance...&quot;) &#125; &#125; return instance&#125;func main() &#123; var s *Singleton s = GetInstance() s = GetInstance() fmt.Println(s)&#125; 执行结果： instance…&amp;{} 通过结果可以看到只输出了一个instance…。 上面的实现方式还可以通过结构体sync.Once更优雅的实现。 示例： 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot; &quot;sync&quot;)var ( once sync.Once instance *Singleton)type Singleton struct &#123;&#125;func GetInstance() *Singleton &#123; once.Do(func() &#123; instance = &amp;Singleton&#123;&#125; fmt.Println(&quot;instance...&quot;) &#125;) return instance&#125;func main() &#123; var s *Singleton s = GetInstance() s = GetInstance() fmt.Println(s)&#125; 输出结果： instance…&amp;{} 通过sync.Once的源代码查看它是如何运行的 123456789101112func (o *Once) Do(f func()) &#123; if atomic.LoadUint32(&amp;o.done) == 1 &#123; return &#125; // Slow-path. o.m.Lock() defer o.m.Unlock() if o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) f() &#125;&#125; sync.Once.Do(f func())使用加锁原子操作（代码包sync&#x2F;atomic）来保证函数 f 只执行一次。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"GC垃圾回收机制","slug":"gc","date":"2019-05-15T15:05:10.000Z","updated":"2022-05-16T06:49:11.270Z","comments":true,"path":"2019/05/15/gc/","link":"","permalink":"https://timmy6.github.io/2019/05/15/gc/","excerpt":"","text":"垃圾回收(Garbage Collection，简称GC)是编程语言中提供的内存管理功能。 在传统的系统级编程语言（主要指C&#x2F;C++）中，程序员定义了一个变量，就是在内存中开辟了一段相应的空间来存值。由于内存是有限的，所以当程序不再需要使用某个变量的时候，就需要销毁该对象并释放其所占用的内存资源，好重新利用这段空间。在C&#x2F;C++中，释放无用变量内存空间的事情需要由程序员自己来处理。就是说当程序员认为变量没用了，就手动地释放其占用的内存。但是这样显然非常繁琐，如果有所遗漏，就可能造成资源浪费甚至内存泄露。当软件系统比较复杂，变量多的时候程序员往往就忘记释放内存或者在不该释放的时候释放内存了。这对于程序开发人员是一个比较头痛的问题。 为了解决这个问题，后来开发出来的几乎所有新语言（java，python，php等等）都引入了语言层面的自动内存管理 – 也就是语言的使用者只用关注内存的申请而不必关心内存的释放，内存释放由虚拟机（virtual machine）或运行时（runtime）来自动进行管理。而这种对不再使用的内存资源进行自动回收的功能就被称为垃圾回收。 垃圾回收常见的方法引用计数（reference counting） 引用计数通过在对象上增加自己被引用的次数，被其他对象引用时加1，引用自己的对象被回收时减1，引用数为0的对象即为可以被回收的对象。这种算法在内存比较紧张和实时性比较高的系统中使用的比较广泛，如ios cocoa框架，php，python等。 优点： 1、方式简单，回收速度快。 缺点： 1、需要额外的空间存放计数。 2、无法处理循环引用（如a.b&#x3D;b;b.a&#x3D;a这种情况）。 3、频繁更新引用计数降低了性能。 标记-清除（mark and sweep） 该方法分为两步，标记从根变量开始迭代得遍历所有被引用的对象，对能够通过应用遍历访问到的对象都进行标记为“被引用”；标记完成后进行清除操作，对没有标记过的内存进行回收（回收同时可能伴有碎片整理操作）。这种方法解决了引用计数的不足，但是也有比较明显的问题：每次启动垃圾回收都会暂停当前所有的正常代码执行，回收是系统响应能力大大降低！当然后续也出现了很多mark&amp;sweep算法的变种（如三色标记法）优化了这个问题。 复制收集 复制收集的方式只需要对对象进行一次扫描。准备一个「新的空间」，从根开始，对对象进行扫，如果存在对这个对象的引用，就把它复制到「新空间中」。一次扫描结束之后，所有存在于「新空间」的对象就是所有的非垃圾对象。 这两种方式各有千秋，标记清除的方式节省内存但是两次扫描需要更多的时间，对于垃圾比例较小的情况占优势。复制收集更快速但是需要额外开辟一块用来复制的内存，对垃圾比例较大的情况占优势。特别的，复制收集有「局部性」的优点。 在复制收集的过程中，会按照对象被引用的顺序将对象复制到新空间中。于是，关系较近的对象被放在距离较近的内存空间的可能性会提高，这叫做局部性。局部性高的情况下，内存缓存会更有效地运作，程序的性能会提高。 对于标记清除，有一种标记-压缩算法的衍生算法： 对于压缩阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到减少内存碎片的目的。 分代收集（generation） 这种收集方式用了程序的一种特性：大部分对象会从产生开始在很短的时间内变成垃圾，而存在的很长时间的对象往往都有较长的生命周期。 根据对象的存活周期不同将内存划分为新生代和老年代，存活周期短的为新生代，存活周期长的为老年代。这样就可以根据每块内存的特点采用最适当的收集算法。 新创建的对象存放在称为 新生代（young generation）中（一般来说，新生代的大小会比 老年代小很多）。高频对新生成的对象进行回收，称为「小回收」，低频对所有对象回收，称为「大回收」。每一次「小回收」过后，就把存活下来的对象归为老年代，「小回收」的时候，遇到老年代直接跳过。大多数分代回收算法都采用的「复制收集」方法，因为小回收中垃圾的比例较大。 这种方式存在一个问题：如果在某个新生代的对象中，存在「老生代」的对象对它的引用，它就不是垃圾了，那么怎么制止「小回收」对其回收呢？这里用到了一中叫做写屏障的方式。 程序对所有涉及修改对象内容的地方进行保护，被称为「写屏障」（Write Barrier）。写屏障不仅用于分代收集，也用于其他GC算法中。 在此算法的表现是，用一个记录集来记录从新生代到老生代的引用。如果有两个对象A和B，当对A的对象内容进行修改并加入B的引用时，如果①A是「老生代」②B是「新生代」。则将这个引用加入到记录集中。「小回收」的时候，因为记录集中有对B的引用，所以B不再是垃圾。 三色标记算法三色标记算法是对标记阶段的改进，原理如下： 起初所有对象都是白色。 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 重复 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。 可视化如下。 三色标记的一个明显好处是能够让用户程序和 mark 并发的进行，具体可以参考论文：《On-the-fly garbage collection: an exercise in cooperation.》。Golang 的 GC 实现也是基于这篇论文，后面再具体说明。 GO的垃圾回收器go语言垃圾回收总体采用的是经典的mark and sweep算法。 v1.3以前版本 STW（Stop The World） golang的垃圾回收算法都非常简陋，然后其性能也广被诟病:go runtime在一定条件下（内存超过阈值或定期如2min），暂停所有任务的执行，进行mark&amp;sweep操作，操作完成后启动所有任务的执行。在内存使用较多的场景下，go程序在进行垃圾回收时会发生非常明显的卡顿现象（Stop The World）。在对响应速度要求较高的后台服务进程中，这种延迟简直是不能忍受的！这个时期国内外很多在生产环境实践go语言的团队都或多或少踩过gc的坑。当时解决这个问题比较常用的方法是尽快控制自动分配内存的内存数量以减少gc负荷，同时采用手动管理内存的方法处理需要大量及高频分配内存的场景。 v1.3 Mark STW, Sweep 并行 1.3版本中，go runtime分离了mark和sweep操作，和以前一样，也是先暂停所有任务执行并启动mark，mark完成后马上就重新启动被暂停的任务了，而是让sweep任务和普通协程任务一样并行的和其他任务一起执行。如果运行在多核处理器上，go会试图将gc任务放到单独的核心上运行而尽量不影响业务代码的执行。go team自己的说法是减少了50%-70%的暂停时间。 v1.5 三色标记法 go 1.5正在实现的垃圾回收器是“非分代的、非移动的、并发的、三色的标记清除垃圾收集器”。引入了上文介绍的三色标记法，这种方法的mark操作是可以渐进执行的而不需每次都扫描整个内存空间，可以减少stop the world的时间。 由此可以看到，一路走来直到1.5版本，go的垃圾回收性能也是一直在提升，但是相对成熟的垃圾回收系统（如java jvm和javascript v8），go需要优化的路径还很长（但是相信未来一定是美好的~）。 v1.8 混合写屏障（hybrid write barrier） 这个版本的 GC 代码相比之前改动还是挺大的，采用一种混合的 write barrier 方式 （Yuasa-style deletion write barrier [Yuasa ‘90] 和 Dijkstra-style insertion write barrier [Dijkstra ‘78]）来避免 堆栈重新扫描。 混合屏障的优势在于它允许堆栈扫描永久地使堆栈变黑（没有STW并且没有写入堆栈的障碍），这完全消除了堆栈重新扫描的需要，从而消除了对堆栈屏障的需求。重新扫描列表。特别是堆栈障碍在整个运行时引入了显着的复杂性，并且干扰了来自外部工具（如GDB和基于内核的分析器）的堆栈遍历。 此外，与Dijkstra风格的写屏障一样，混合屏障不需要读屏障，因此指针读取是常规的内存读取; 它确保了进步，因为物体单调地从白色到灰色再到黑色。 混合屏障的缺点很小。它可能会导致更多的浮动垃圾，因为它会在标记阶段的任何时刻保留从根（堆栈除外）可到达的所有内容。然而，在实践中，当前的Dijkstra障碍可能几乎保留不变。混合屏障还禁止某些优化：特别是，如果Go编译器可以静态地显示指针是nil，则Go编译器当前省略写屏障，但是在这种情况下混合屏障需要写屏障。这可能会略微增加二进制大小。 小结： 通过go team多年对gc的不断改进和忧化，GC的卡顿问题在1.8 版本基本上可以做到 1 毫秒以下的 GC 级别。 实际上，gc低延迟是有代价的，其中最大的是吞吐量的下降。由于需要实现并行处理，线程间同步和多余的数据生成复制都会占用实际逻辑业务代码运行的时间。GHC的全局停止GC对于实现高吞吐量来说是十分合适的，而Go则更擅长与低延迟。并行GC的第二个代价是不可预测的堆空间扩大。程序在GC的运行期间仍能不断分配任意大小的堆空间，因此我们需要在到达最大的堆空间之前实行一次GC，但是过早实行GC会造成不必要的GC扫描，这也是需要衡量利弊的。因此在使用Go时，需要自行保证程序有足够的内存空间。 垃圾收集是一个难题，没有所谓十全十美的方案，通常是为了适应应用场景做出的一种取舍。 相信GO未来会更好。 参考： https://github.com/golang/proposal/blob/master/design/17503-eliminate-rescan.md http://legendtkl.com/2017/04/28/golang-gc/ https://blog.twitch.tv/gos-march-to-low-latency-gc-a6fa96f06eb7 https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"redis连接池","slug":"redis","date":"2019-05-09T15:05:10.000Z","updated":"2022-05-16T06:12:38.969Z","comments":true,"path":"2019/05/09/redis/","link":"","permalink":"https://timmy6.github.io/2019/05/09/redis/","excerpt":"","text":"Go Redis连接池官方包 https://github.com/gomodule/redigo 1、创建配置文件 存放在conf配置文件夹，可以跟你的需要存在相应。 redis.go 12345678package confvar RedisConf = map[string]string&#123; &quot;name&quot;: &quot;redis&quot;, &quot;type&quot;: &quot;tcp&quot;, &quot;address&quot;: &quot;127.0.0.1:6379&quot;, &quot;auth&quot;: &quot;123456&quot;,&#125; 2、redis连接池redispool.go 连接池实现 12345678910111213141516171819202122232425262728293031package redisimport ( . &quot;example/example/conf&quot; //改成你自己配置目录 &quot;github.com/garyburd/redigo/redis&quot; &quot;time&quot;)var RedisClient *redis.Poolfunc init() &#123; // 建立连接池 RedisClient = &amp;redis.Pool&#123; // 从配置文件获取maxidle以及maxactive，取不到则用后面的默认值 MaxIdle: 16, //最初的连接数量 // MaxActive:1000000, //最大连接数量 MaxActive: 0, //连接池最大连接数量,不确定可以用0（0表示自动定义），按需分配 IdleTimeout: 300 * time.Second, //连接关闭时间 300秒 （300秒不使用自动关闭） Dial: func() (redis.Conn, error) &#123; //要连接的redis数据库 c, err := redis.Dial(RedisConf[&quot;type&quot;], RedisConf[&quot;address&quot;]) if err != nil &#123; return nil, err &#125; if _, err := c.Do(&quot;AUTH&quot;, RedisConf[&quot;auth&quot;]); err != nil &#123; _=c.Close() return nil, err &#125; return c, nil &#125;, &#125;&#125; 使用示例：123456789101112131415161718192021222324252627282930package mainimport ( &quot;example/example/public/redispool&quot; //改成你自己的redispool.go(redis连接池实现文件)的目录 &quot;fmt&quot; &quot;github.com/gomodule/redigo/redis&quot;)var RedisExpire = 3600 //缓存有效期func main() &#123; // 从池里获取连接 rc := redispool.RedisClient.Get() // 用完后将连接放回连接池 defer rc.Close() key := &quot;redis.cache&quot; _, err := rc.Do(&quot;Set&quot;, key, &quot;1&quot;, &quot;EX&quot;, RedisExpire) if err != nil &#123; fmt.Println(err) return &#125; val, err := redis.String(rc.Do(&quot;Get&quot;, key)) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(val) //删除 rc.Do(&quot;Del&quot;, key)&#125;","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/tags/redis/"}]},{"title":"路由中间件 - 签名验证","slug":"sign","date":"2019-04-25T15:05:10.000Z","updated":"2022-05-16T02:56:50.147Z","comments":true,"path":"2019/04/25/sign/","link":"","permalink":"https://timmy6.github.io/2019/04/25/sign/","excerpt":"","text":"概览首先同步下项目概况： 上篇文章分享了，路由中间件 - Jaeger 链路追踪（实战篇），文章反响真是出乎意料， 「Go中国」 公众号也转发了，有很多朋友加我好友交流，直呼我大神，其实我哪是什么大神，只不过在本地实践了而已，对于 Go 语言的使用，我还是个新人，在这里感谢大家的厚爱！ 这篇文章咱们分享：路由中间件 - 签名验证。 为什么使用签名验证？ 这个就不用多说了吧，主要是为了保证接口安全和识别调用方身份，基于这两点，咱们一起设计下签名。 调用方需要申请 App Key 和 App Secret，App Key 用来识别调用方身份，App Secret 用来加密生成签名使用。 当然生成的签名还需要满足以下几点： 可变性：每次的签名必须是不一样的。 时效性：每次请求的时效性，过期作废。 唯一性：每次的签名是唯一的。 完整性：能够对传入数据进行验证，防止篡改。 举个例子： /api?param_1=xxx&amp;param_2=xxx，其中 param_1 和 param_2 是两个参数。 如果增加了签名验证，需要再传递几个参数： ak 表示App Key，用来识别调用方身份。 ts 表示时间戳，用来验证接口的时效性。 sn 表示签名加密串，用来验证数据的完整性，防止数据篡改。 sn 是通过 App Secret 和 传递的参数 进行加密的。 最终传递的参数如下： /api?param_1=xxx&amp;param_2=xxx&amp;ak=xxx&amp;ts=xxx&amp;sn=xxx 在这要说一个调试技巧，ts 和 sn 参数每次都手动生成太麻烦了，当传递 debug=1 的时候，会返回 ts 和 sn , 具体看下代码就清楚了。 这篇文章分享三种实现签名的方式，分别是：MD5 组合加密、AES 对称加密、RSA 非对称加密。 废话不多说，进入主题。 MD5 组合生成签名首先，封装一个 Go 的 MD5 方法： 12345func MD5(str string) string &#123; s := md5.New() s.Write([]byte(str)) return hex.EncodeToString(s.Sum(nil))&#125; 进行加密： 123456appKey = &quot;demo&quot;appSecret = &quot;xxx&quot;encryptStr = &quot;param_1=xxx&amp;param_2=xxx&amp;ak=&quot;+appKey+&quot;&amp;ts=xxx&quot;// 自定义验证规则sn = MD5(appSecret + encryptStr + appSecret) 验证签名通过传递参数，再次生成签名，如果将传递的签名与生成的签名进行对比。 相同，表示签名验证成功。 不同，表示签名验证失败。 中间件 - 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293var AppSecret string// MD5 组合加密func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; utilGin := util.Gin&#123;Ctx: c&#125; sign, err := verifySign(c) if sign != nil &#123; utilGin.Response(-1, &quot;Debug Sign&quot;, sign) c.Abort() return &#125; if err != nil &#123; utilGin.Response(-1, err.Error(), sign) c.Abort() return &#125; c.Next() &#125;&#125;// 验证签名func verifySign(c *gin.Context) (map[string]string, error) &#123; _ = c.Request.ParseForm() req := c.Request.Form debug := strings.Join(c.Request.Form[&quot;debug&quot;], &quot;&quot;) ak := strings.Join(c.Request.Form[&quot;ak&quot;], &quot;&quot;) sn := strings.Join(c.Request.Form[&quot;sn&quot;], &quot;&quot;) ts := strings.Join(c.Request.Form[&quot;ts&quot;], &quot;&quot;) // 验证来源 value, ok := config.ApiAuthConfig[ak] if ok &#123; AppSecret = value[&quot;md5&quot;] &#125; else &#123; return nil, errors.New(&quot;ak Error&quot;) &#125; if debug == &quot;1&quot; &#123; currentUnix := util.GetCurrentUnix() req.Set(&quot;ts&quot;, strconv.FormatInt(currentUnix, 10)) res := map[string]string&#123; &quot;ts&quot;: strconv.FormatInt(currentUnix, 10), &quot;sn&quot;: createSign(req), &#125; return res, nil &#125; // 验证过期时间 timestamp := time.Now().Unix() exp, _ := strconv.ParseInt(config.AppSignExpiry, 10, 64) tsInt, _ := strconv.ParseInt(ts, 10, 64) if tsInt &gt; timestamp || timestamp - tsInt &gt;= exp &#123; return nil, errors.New(&quot;ts Error&quot;) &#125; // 验证签名 if sn == &quot;&quot; || sn != createSign(req) &#123; return nil, errors.New(&quot;sn Error&quot;) &#125; return nil, nil&#125;// 创建签名func createSign(params url.Values) string &#123; // 自定义 MD5 组合 return util.MD5(AppSecret + createEncryptStr(params) + AppSecret)&#125;func createEncryptStr(params url.Values) string &#123; var key []string var str = &quot;&quot; for k := range params &#123; if k != &quot;sn&quot; &amp;&amp; k != &quot;debug&quot; &#123; key = append(key, k) &#125; &#125; sort.Strings(key) for i := 0; i &lt; len(key); i++ &#123; if i == 0 &#123; str = fmt.Sprintf(&quot;%v=%v&quot;, key[i], params.Get(key[i])) &#125; else &#123; str = str + fmt.Sprintf(&quot;&amp;%v=%v&quot;, key[i], params.Get(key[i])) &#125; &#125; return str&#125; AES 对称加密在使用前，咱们先了解下什么是对称加密？ 对称加密就是使用同一个密钥即可以加密也可以解密，这种方法称为对称加密。 常用算法：DES、AES。 其中 AES 是 DES 的升级版，密钥长度更长，选择更多，也更灵活，安全性更高，速度更快，咱们直接上手 AES 加密。 优点 算法公开、计算量小、加密速度快、加密效率高。 缺点 发送方和接收方必须商定好密钥，然后使双方都能保存好密钥，密钥管理成为双方的负担。 应用场景 相对大一点的数据量或关键数据的加密。 生成签名首先，封装 Go 的 AesEncrypt 加密方法 和 AesDecrypt 解密方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 加密 aes_128_cbcfunc AesEncrypt (encryptStr string, key []byte, iv string) (string, error) &#123; encryptBytes := []byte(encryptStr) block, err := aes.NewCipher(key) if err != nil &#123; return &quot;&quot;, err &#125; blockSize := block.BlockSize() encryptBytes = pkcs5Padding(encryptBytes, blockSize) blockMode := cipher.NewCBCEncrypter(block, []byte(iv)) encrypted := make([]byte, len(encryptBytes)) blockMode.CryptBlocks(encrypted, encryptBytes) return base64.URLEncoding.EncodeToString(encrypted), nil&#125;// 解密func AesDecrypt (decryptStr string, key []byte, iv string) (string, error) &#123; decryptBytes, err := base64.URLEncoding.DecodeString(decryptStr) if err != nil &#123; return &quot;&quot;, err &#125; block, err := aes.NewCipher(key) if err != nil &#123; return &quot;&quot;, err &#125; blockMode := cipher.NewCBCDecrypter(block, []byte(iv)) decrypted := make([]byte, len(decryptBytes)) blockMode.CryptBlocks(decrypted, decryptBytes) decrypted = pkcs5UnPadding(decrypted) return string(decrypted), nil&#125;func pkcs5Padding (cipherText []byte, blockSize int) []byte &#123; padding := blockSize - len(cipherText)%blockSize padText := bytes.Repeat([]byte&#123;byte(padding)&#125;, padding) return append(cipherText, padText...)&#125;func pkcs5UnPadding (decrypted []byte) []byte &#123; length := len(decrypted) unPadding := int(decrypted[length-1]) return decrypted[:(length - unPadding)]&#125; 进行加密： 12345appKey = &quot;demo&quot;appSecret = &quot;xxx&quot;encryptStr = &quot;param_1=xxx&amp;param_2=xxx&amp;ak=&quot;+appKey+&quot;&amp;ts=xxx&quot;sn = AesEncrypt(encryptStr, appSecret) 验证签名1decryptStr = AesDecrypt(sn, app_secret) 将加密前的字符串与解密后的字符串做个对比。 相同，表示签名验证成功。 不同，表示签名验证失败。 中间件 - 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105var AppSecret string// AES 对称加密func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; utilGin := util.Gin&#123;Ctx: c&#125; sign, err := verifySign(c) if sign != nil &#123; utilGin.Response(-1, &quot;Debug Sign&quot;, sign) c.Abort() return &#125; if err != nil &#123; utilGin.Response(-1, err.Error(), sign) c.Abort() return &#125; c.Next() &#125;&#125;// 验证签名func verifySign(c *gin.Context) (map[string]string, error) &#123; _ = c.Request.ParseForm() req := c.Request.Form debug := strings.Join(c.Request.Form[&quot;debug&quot;], &quot;&quot;) ak := strings.Join(c.Request.Form[&quot;ak&quot;], &quot;&quot;) sn := strings.Join(c.Request.Form[&quot;sn&quot;], &quot;&quot;) ts := strings.Join(c.Request.Form[&quot;ts&quot;], &quot;&quot;) // 验证来源 value, ok := config.ApiAuthConfig[ak] if ok &#123; AppSecret = value[&quot;aes&quot;] &#125; else &#123; return nil, errors.New(&quot;ak Error&quot;) &#125; if debug == &quot;1&quot; &#123; currentUnix := util.GetCurrentUnix() req.Set(&quot;ts&quot;, strconv.FormatInt(currentUnix, 10)) sn, err := createSign(req) if err != nil &#123; return nil, errors.New(&quot;sn Exception&quot;) &#125; res := map[string]string&#123; &quot;ts&quot;: strconv.FormatInt(currentUnix, 10), &quot;sn&quot;: sn, &#125; return res, nil &#125; // 验证过期时间 timestamp := time.Now().Unix() exp, _ := strconv.ParseInt(config.AppSignExpiry, 10, 64) tsInt, _ := strconv.ParseInt(ts, 10, 64) if tsInt &gt; timestamp || timestamp - tsInt &gt;= exp &#123; return nil, errors.New(&quot;ts Error&quot;) &#125; // 验证签名 if sn == &quot;&quot; &#123; return nil, errors.New(&quot;sn Error&quot;) &#125; decryptStr, decryptErr := util.AesDecrypt(sn, []byte(AppSecret), AppSecret) if decryptErr != nil &#123; return nil, errors.New(decryptErr.Error()) &#125; if decryptStr != createEncryptStr(req) &#123; return nil, errors.New(&quot;sn Error&quot;) &#125; return nil, nil&#125;// 创建签名func createSign(params url.Values) (string, error) &#123; return util.AesEncrypt(createEncryptStr(params), []byte(AppSecret), AppSecret)&#125;func createEncryptStr(params url.Values) string &#123; var key []string var str = &quot;&quot; for k := range params &#123; if k != &quot;sn&quot; &amp;&amp; k != &quot;debug&quot; &#123; key = append(key, k) &#125; &#125; sort.Strings(key) for i := 0; i &lt; len(key); i++ &#123; if i == 0 &#123; str = fmt.Sprintf(&quot;%v=%v&quot;, key[i], params.Get(key[i])) &#125; else &#123; str = str + fmt.Sprintf(&quot;&amp;%v=%v&quot;, key[i], params.Get(key[i])) &#125; &#125; return str&#125; RSA 非对称加密和上面一样，在使用前，咱们先了解下什么是非对称加密？ 非对称加密就是需要两个密钥来进行加密和解密，这两个秘钥分别是公钥（public key）和私钥（private key），这种方法称为非对称加密。 常用算法：RSA。 优点 与对称加密相比，安全性更好，加解密需要不同的密钥，公钥和私钥都可进行相互的加解密。 缺点 加密和解密花费时间长、速度慢，只适合对少量数据进行加密。 应用场景 适合于对安全性要求很高的场景，适合加密少量数据，比如支付数据、登录数据等。 创建签名首先，封装 Go 的 RsaPublicEncrypt 公钥加密方法 和 RsaPrivateDecrypt 解密方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// 公钥加密func RsaPublicEncrypt(encryptStr string, path string) (string, error) &#123; // 打开文件 file, err := os.Open(path) if err != nil &#123; return &quot;&quot;, err &#125; defer file.Close() // 读取文件内容 info, _ := file.Stat() buf := make([]byte,info.Size()) file.Read(buf) // pem 解码 block, _ := pem.Decode(buf) // x509 解码 publicKeyInterface, err := x509.ParsePKIXPublicKey(block.Bytes) if err != nil &#123; return &quot;&quot;, err &#125; // 类型断言 publicKey := publicKeyInterface.(*rsa.PublicKey) //对明文进行加密 encryptedStr, err := rsa.EncryptPKCS1v15(rand.Reader, publicKey, []byte(encryptStr)) if err != nil &#123; return &quot;&quot;, err &#125; //返回密文 return base64.URLEncoding.EncodeToString(encryptedStr), nil&#125;// 私钥解密func RsaPrivateDecrypt(decryptStr string, path string) (string, error) &#123; // 打开文件 file, err := os.Open(path) if err != nil &#123; return &quot;&quot;, err &#125; defer file.Close() // 获取文件内容 info, _ := file.Stat() buf := make([]byte,info.Size()) file.Read(buf) // pem 解码 block, _ := pem.Decode(buf) // X509 解码 privateKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil &#123; return &quot;&quot;, err &#125; decryptBytes, err := base64.URLEncoding.DecodeString(decryptStr) //对密文进行解密 decrypted, _ := rsa.DecryptPKCS1v15(rand.Reader,privateKey,decryptBytes) //返回明文 return string(decrypted), nil&#125; 调用方 申请 公钥（public key），然后进行加密： 12345appKey = &quot;demo&quot;appSecret = &quot;公钥&quot;encryptStr = &quot;param_1=xxx&amp;param_2=xxx&amp;ak=&quot;+appKey+&quot;&amp;ts=xxx&quot;sn = RsaPublicEncrypt(encryptStr, appSecret) 验证签名1decryptStr = RsaPrivateDecrypt(sn, app_secret) 将加密前的字符串与解密后的字符串做个对比。 相同，表示签名验证成功。 不同，表示签名验证失败。 中间件 - 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105var AppSecret string// RSA 非对称加密func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; utilGin := util.Gin&#123;Ctx: c&#125; sign, err := verifySign(c) if sign != nil &#123; utilGin.Response(-1, &quot;Debug Sign&quot;, sign) c.Abort() return &#125; if err != nil &#123; utilGin.Response(-1, err.Error(), sign) c.Abort() return &#125; c.Next() &#125;&#125;// 验证签名func verifySign(c *gin.Context) (map[string]string, error) &#123; _ = c.Request.ParseForm() req := c.Request.Form debug := strings.Join(c.Request.Form[&quot;debug&quot;], &quot;&quot;) ak := strings.Join(c.Request.Form[&quot;ak&quot;], &quot;&quot;) sn := strings.Join(c.Request.Form[&quot;sn&quot;], &quot;&quot;) ts := strings.Join(c.Request.Form[&quot;ts&quot;], &quot;&quot;) // 验证来源 value, ok := config.ApiAuthConfig[ak] if ok &#123; AppSecret = value[&quot;rsa&quot;] &#125; else &#123; return nil, errors.New(&quot;ak Error&quot;) &#125; if debug == &quot;1&quot; &#123; currentUnix := util.GetCurrentUnix() req.Set(&quot;ts&quot;, strconv.FormatInt(currentUnix, 10)) sn, err := createSign(req) if err != nil &#123; return nil, errors.New(&quot;sn Exception&quot;) &#125; res := map[string]string&#123; &quot;ts&quot;: strconv.FormatInt(currentUnix, 10), &quot;sn&quot;: sn, &#125; return res, nil &#125; // 验证过期时间 timestamp := time.Now().Unix() exp, _ := strconv.ParseInt(config.AppSignExpiry, 10, 64) tsInt, _ := strconv.ParseInt(ts, 10, 64) if tsInt &gt; timestamp || timestamp - tsInt &gt;= exp &#123; return nil, errors.New(&quot;ts Error&quot;) &#125; // 验证签名 if sn == &quot;&quot; &#123; return nil, errors.New(&quot;sn Error&quot;) &#125; decryptStr, decryptErr := util.RsaPrivateDecrypt(sn, config.AppRsaPrivateFile) if decryptErr != nil &#123; return nil, errors.New(decryptErr.Error()) &#125; if decryptStr != createEncryptStr(req) &#123; return nil, errors.New(&quot;sn Error&quot;) &#125; return nil, nil&#125;// 创建签名func createSign(params url.Values) (string, error) &#123; return util.RsaPublicEncrypt(createEncryptStr(params), AppSecret)&#125;func createEncryptStr(params url.Values) string &#123; var key []string var str = &quot;&quot; for k := range params &#123; if k != &quot;sn&quot; &amp;&amp; k != &quot;debug&quot; &#123; key = append(key, k) &#125; &#125; sort.Strings(key) for i := 0; i &lt; len(key); i++ &#123; if i == 0 &#123; str = fmt.Sprintf(&quot;%v=%v&quot;, key[i], params.Get(key[i])) &#125; else &#123; str = str + fmt.Sprintf(&quot;&amp;%v=%v&quot;, key[i], params.Get(key[i])) &#125; &#125; return str&#125; 如何调用？与其他中间件调用方式一样，根据自己的需求自由选择。 比如，使用 MD5 组合： 1.Use(sign_md5.SetUp()) 使用 AES 对称加密： 1.Use(sign_aes.SetUp()) 使用 RSA 非对称加密： 1.Use(sign_rsa.SetUp()) 性能测试既然 RSA 非对称加密，最安全，那么统一都使用它吧。 NO！NO！NO！绝对不行！ 为什么我要激动，因为我以前遇到过这个坑呀，都是血泪的教训呀… 咱们挨个测试下性能： MD5123456789101112131415func Md5Test(c *gin.Context) &#123; startTime := time.Now() appSecret := &quot;IgkibX71IEf382PT&quot; encryptStr := &quot;param_1=xxx&amp;param_2=xxx&amp;ak=xxx&amp;ts=1111111111&quot; count := 1000000 for i := 0; i &lt; count; i++ &#123; // 生成签名 util.MD5(appSecret + encryptStr + appSecret) // 验证签名 util.MD5(appSecret + encryptStr + appSecret) &#125; utilGin := util.Gin&#123;Ctx: c&#125; utilGin.Response(1, fmt.Sprintf(&quot;%v次 - %v&quot;, count, time.Since(startTime)), nil)&#125; 模拟 一百万 次请求，大概执行时长在 1.1s ~ 1.2s 左右。 AES123456789101112131415func AesTest(c *gin.Context) &#123; startTime := time.Now() appSecret := &quot;IgkibX71IEf382PT&quot; encryptStr := &quot;param_1=xxx&amp;param_2=xxx&amp;ak=xxx&amp;ts=1111111111&quot; count := 1000000 for i := 0; i &lt; count; i++ &#123; // 生成签名 sn, _ := util.AesEncrypt(encryptStr, []byte(appSecret), appSecret) // 验证签名 util.AesDecrypt(sn, []byte(appSecret), appSecret) &#125; utilGin := util.Gin&#123;Ctx: c&#125; utilGin.Response(1, fmt.Sprintf(&quot;%v次 - %v&quot;, count, time.Since(startTime)), nil)&#125; 模拟 一百万 次请求，大概执行时长在 1.8s ~ 1.9s 左右。 RSA1234567891011121314func RsaTest(c *gin.Context) &#123; startTime := time.Now() encryptStr := &quot;param_1=xxx&amp;param_2=xxx&amp;ak=xxx&amp;ts=1111111111&quot; count := 500 for i := 0; i &lt; count; i++ &#123; // 生成签名 sn, _ := util.RsaPublicEncrypt(encryptStr, &quot;rsa/public.pem&quot;) // 验证签名 util.RsaPrivateDecrypt(sn, &quot;rsa/private.pem&quot;) &#125; utilGin := util.Gin&#123;Ctx: c&#125; utilGin.Response(1, fmt.Sprintf(&quot;%v次 - %v&quot;, count, time.Since(startTime)), nil)&#125; 我不敢模拟 一百万 次请求，还不知道啥时候能搞定呢，咱们模拟 500 次试试。 模拟 500 次请求，大概执行时长在 1s 左右。 上面就是我本地的执行效果，大家可以质疑我的电脑性能差，封装的方法有问题… 你们也可以试试，看看性能差距是不是这么大。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"路由中间件 - Jaeger实战","slug":"gin-jaeger-demo","date":"2019-04-19T14:25:10.000Z","updated":"2022-05-16T02:49:35.743Z","comments":true,"path":"2019/04/19/gin-jaeger-demo/","link":"","permalink":"https://timmy6.github.io/2019/04/19/gin-jaeger-demo/","excerpt":"","text":"概述首先同步下项目概况： 上篇文章分享了，路由中间件 - Jaeger 链路追踪（理论篇），这篇文章咱们接着分享：路由中间件 - Jaeger 链路追踪（实战篇）。 这篇文章，确实让大家久等了，主要是里面有一些技术点都是刚刚研究的，没有存货。 先看下咱们要实现的东西： API 调用了 5 个服务，其中 4 个 gRPC 服务，1 个 HTTP 服务，服务与服务之间又相互调用： Speak 服务，又调用了 Listen 服务 和 Sing 服务。 Read 服务，又调用了 Listen 服务 和 Sing 服务。 Write 服务，又调用了 Listen 服务 和 Sing 服务。 咱们要实现的就是查看 API 调用的链路。 关于一些理论的东西，大家可以去看看上篇文章或查阅一些资料，这篇文章就是实现怎么用。 OK，开整。 Jaeger 部署咱们使用 All in one 的方式，进行本地部署。 下载地址：https://www.jaegertracing.io/download/ 我的电脑是 macOS 选择 -&gt; Binaries -&gt; macOS 下载后并解压，会发现以下文件： example-hotrod jaeger-agent jaeger-all-in-one jaeger-collector jaeger-ingester jaeger-query 进入到解压后的目录执行： 1./jaeger-all-in-one 目测启动后，访问地址： http://127.0.0.1:16686/ 到这，Jaeger 已经部署成功了。 准备测试服务准备的五个测试服务如下： 听（listen） 端口：9901 通讯：gRPC 说（speak） 端口：9902 通讯：gRPC 读（read） 端口：9903 通讯：gRPC 写（write） 端口：9904 通讯：gRPC 唱（sing） 端口：9905 通讯：HTTP 听、说、读、写、唱，想这几个服务的名称就花了好久 ~ 我默认大家都会写 grpc 服务，如果不会写的，可以查看下我原来的文章《Go gRPC Hello World》。 应用示例实例化 Tracer1234567891011121314151617181920212223func NewJaegerTracer(serviceName string, jaegerHostPort string) (opentracing.Tracer, io.Closer, error) &#123; cfg := &amp;jaegerConfig.Configuration &#123; Sampler: &amp;jaegerConfig.SamplerConfig&#123; Type : &quot;const&quot;, //固定采样 Param : 1, //1=全采样、0=不采样 &#125;, Reporter: &amp;jaegerConfig.ReporterConfig&#123; LogSpans : true, LocalAgentHostPort : jaegerHostPort, &#125;, ServiceName: serviceName, &#125; tracer, closer, err := cfg.NewTracer(jaegerConfig.Logger(jaeger.StdLogger)) if err != nil &#123; panic(fmt.Sprintf(&quot;ERROR: cannot init Jaeger: %v\\n&quot;, err)) &#125; opentracing.SetGlobalTracer(tracer) return tracer, closer, err&#125; HTTP 注入1234injectErr := jaeger.Tracer.Inject(span.Context(), opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(req.Header))if injectErr != nil &#123; log.Fatalf(&quot;%s: Couldn&#x27;t inject headers&quot;, err)&#125; HTTP 拦截12345678910111213spCtx, err := opentracing.GlobalTracer().Extract(opentracing.HTTPHeaders, opentracing.HTTPHeadersCarrier(c.Request.Header))if err != nil &#123; ParentSpan = Tracer.StartSpan(c.Request.URL.Path) defer ParentSpan.Finish()&#125; else &#123; ParentSpan = opentracing.StartSpan( c.Request.URL.Path, opentracing.ChildOf(spCtx), opentracing.Tag&#123;Key: string(ext.Component), Value: &quot;HTTP&quot;&#125;, ext.SpanKindRPCServer, ) defer ParentSpan.Finish()&#125; gRPC 注入12345678910111213141516171819202122232425262728293031323334func ClientInterceptor(tracer opentracing.Tracer, spanContext opentracing.SpanContext) grpc.UnaryClientInterceptor &#123; return func(ctx context.Context, method string, req, reply interface&#123;&#125;, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption) error &#123; span := opentracing.StartSpan( &quot;call gRPC&quot;, opentracing.ChildOf(spanContext), opentracing.Tag&#123;Key: string(ext.Component), Value: &quot;gRPC&quot;&#125;, ext.SpanKindRPCClient, ) defer span.Finish() md, ok := metadata.FromOutgoingContext(ctx) if !ok &#123; md = metadata.New(nil) &#125; else &#123; md = md.Copy() &#125; err := tracer.Inject(span.Context(), opentracing.TextMap, MDReaderWriter&#123;md&#125;) if err != nil &#123; span.LogFields(log.String(&quot;inject-error&quot;, err.Error())) &#125; newCtx := metadata.NewOutgoingContext(ctx, md) err = invoker(newCtx, method, req, reply, cc, opts...) if err != nil &#123; span.LogFields(log.String(&quot;call-error&quot;, err.Error())) &#125; return err &#125;&#125; gRPC 拦截1234567891011121314151617181920212223242526272829func serverInterceptor(tracer opentracing.Tracer) grpc.UnaryServerInterceptor &#123; return func(ctx context.Context, req interface&#123;&#125;, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface&#123;&#125;, err error) &#123; md, ok := metadata.FromIncomingContext(ctx) if !ok &#123; md = metadata.New(nil) &#125; spanContext, err := tracer.Extract(opentracing.TextMap, MDReaderWriter&#123;md&#125;) if err != nil &amp;&amp; err != opentracing.ErrSpanContextNotFound &#123; grpclog.Errorf(&quot;extract from metadata err: %v&quot;, err) &#125; else &#123; span := tracer.StartSpan( info.FullMethod, ext.RPCServerOption(spanContext), opentracing.Tag&#123;Key: string(ext.Component), Value: &quot;gRPC&quot;&#125;, ext.SpanKindRPCServer, ) defer span.Finish() ParentContext = opentracing.ContextWithSpan(ctx, span) &#125; return handler(ParentContext, req) &#125;&#125; 上面是一些核心的代码，涉及到的全部代码我都会上传到 github，供下载。 运行启动服务1234567891011121314151617// 启动 Listen 服务cd listen &amp;&amp; go run main.go// 启动 Speak 服务cd speak &amp;&amp; go run main.go// 启动 Read 服务cd read &amp;&amp; go run main.go// 启动 Write 服务cd write &amp;&amp; go run main.go// 启动 Sing 服务cd sing &amp;&amp; go run main.go// 启动 go-gin-api 服务cd go-gin-api &amp;&amp; go run main.go 访问路由http://127.0.0.1:9999/jaeger_test 效果 就到这吧。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"路由中间件 - 链路追踪","slug":"gin-jaeger","date":"2019-04-09T14:15:20.000Z","updated":"2022-05-16T02:44:05.503Z","comments":true,"path":"2019/04/09/gin-jaeger/","link":"","permalink":"https://timmy6.github.io/2019/04/09/gin-jaeger/","excerpt":"","text":"概述首先同步下项目概况： 上篇文章分享了，路由中间件 - 捕获异常，这篇文章咱们分享：路由中间件 - Jaeger 链路追踪。 啥是链路追踪？ 我理解链路追踪其实是为微服务架构提供服务的，当一个请求中，请求了多个服务单元，如果请求出现了错误或异常，很难去定位是哪个服务出了问题，这时就需要链路追踪。 咱们先看一张图： 这张图的调用链还比较清晰，咱们想象一下，随着服务的越来越多，服务与服务之间调用关系也越来越多，可能就会发展成下图的情况。 这调用关系真的是… 看到这，我的内心是崩溃的。 那么问题来了，这种情况下怎么快速定位问题？ 如何设计日志记录？我们自己也可以设计一个链路追踪，比如当发生一个请求，咱们记录它的： 请求的唯一标识 请求了哪些服务？ 请求的服务依次顺序？ 请求的 Request 和 Response 日志？ 对日志进行收集、整理，并友好展示 怎么去实现请求的唯一标识？ 以 Go 为例 写一个中间件，在每次请求的 Header 中包含：X-Request-Id，代码如下： 1234567891011func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; requestId := c.Request.Header.Get(&quot;X-Request-Id&quot;) if requestId == &quot;&quot; &#123; requestId = util.GenUUID() &#125; c.Set(&quot;X-Request-Id&quot;, requestId) c.Writer.Header().Set(&quot;X-Request-Id&quot;, requestId) c.Next() &#125;&#125; 每个 Request 和 Response 日志中都要包含 X-Request-Id。 问题又来了，每次调用都记录日志，当调用的服务过多时，频繁的记录日志，就会有性能问题呀，肿么办？ 哎，这么麻烦，看看市面上有没有一些开源工具呢？ 开源工具 Jaeger：https://www.jaegertracing.io Zipkin：https://zipkin.io/ Appdash：https://about.sourcegraph.com/ 这个就不多做介绍了，基本上都能满足需求，至于优缺点，大家可以挨个去瞅瞅，喜欢哪个就用哪个？ 我为什么选择 Jaeger ？ 因为我目前只会用这个，其他还不会 … 咱们一起看下 Jaeger 是怎么回事吧。 Jaeger 架构图 图片来源于官网。 简单介绍下上图三个关键组件： Agent Agent是一个网络守护进程，监听通过UDP发送过来的Span，它会将其批量发送给collector。按照设计，Agent要被部署到所有主机上，作为基础设施。Agent将collector和客户端之间的路由与发现机制抽象了出来。 Collector Collector从Jaeger Agent接收Trace，并通过一个处理管道对其进行处理。目前的管道会校验Trace、建立索引、执行转换并最终进行存储。存储是一个可插入的组件，现在支持Cassandra和elasticsearch。 Query Query服务会从存储中检索Trace并通过UI界面进行展现，该UI界面通过React技术实现，其页面UI如下图所示，展现了一条Trace的详细信息。 其他组件，大家可以了解下并选择性使用。 Jaeger Span 图片来源于官网。 怎么操作 Span 呢？Span 有哪些可以调用的 API ？ Jaeger 部署All in one 为了方便大家快速使用，Jaeger 直接提供一个 All in one 包，我们可以直接执行，启动一套完整的 Jaeger tracing 系统。 启动成功后，访问 http://localhost:16686 就可以看到 Jaeger UI。 独立部署 jaeger-agent jaeger-collector jaeger-query jaeger-ingester jaeger-operator jaeger-cassandra-schema jaeger-es-index-cleaner spark-dependencies 可以自由搭配，组合使用。 Jaeger 端口 端口：6831 协议：UDP 所属模块：Agent 功能：通过兼容性 Thrift 协议，接收 Jaeger thrift 类型数据 端口：14267 协议：HTTP 所属模块：Collector 功能：接收客户端 Jaeger thrift 类型数据 端口：16686 协议：HTTP 所属模块：Query 功能：客户端前端界面展示端口 Jaeger 采样率分布式追踪系统本身也会造成一定的性能低损耗，如果完整记录每次请求，对于生产环境可能会有极大的性能损耗，一般需要进行采样设置。 固定采样 （sampler.type&#x3D;const） sampler.param&#x3D;1 全采样， sampler.param&#x3D;0 不采样； 按百分比采样 （sampler.type&#x3D;probabilistic） sampler.param&#x3D;0.1 则随机采十分之一的样本； 采样速度限制 （sampler.type&#x3D;ratelimiting） sampler.param&#x3D;2.0 每秒采样两个traces； 动态获取采样率 （sampler.type&#x3D;remote） 这个是默认配置，可以通过配置从 Agent 中获取采样率的动态设置。 Jaeger 缺点 接入过程有一定的侵入性； 本身缺少监控和报警机制，需要结合第三方工具来实现，比如配合Grafana 和 Prometheus实现； 看到这，说的都是理论，大家的心里话可能是： 实战 Jaeger 部署 Jaeger 在 Gin 中使用 Jaeger 在 gRPC 中使用 关于实战的分享，我准备整理出 4 个服务，然后实现服务与服务之间进行相互调用，目前 Demo 还没写完… 下篇文章再给大家分享。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"路由中间件 - 捕获异常","slug":"catch-error","date":"2019-03-25T13:25:20.000Z","updated":"2022-05-13T09:46:42.880Z","comments":true,"path":"2019/03/25/catch-error/","link":"","permalink":"https://timmy6.github.io/2019/03/25/catch-error/","excerpt":"","text":"概述首先同步下项目概况： 上篇文章分享了，路由中间件 - 日志记录，这篇文章咱们分享：路由中间件 - 捕获异常。当系统发生异常时，提示 “系统异常，请联系管理员！”，同时并发送 panic 告警邮件。 什么是异常？在 Go 中异常就是 panic，它是在程序运行的时候抛出的，当 panic 抛出之后，如果在程序里没有添加任何保护措施的话，控制台就会在打印出 panic 的详细情况，然后终止运行。 我们可以将 panic 分为两种： 一种是有意抛出的，比如， 1panic(&quot;自定义的 panic 信息&quot;) 输出： 1232019/09/10 20:25:27 http: panic serving [::1]:61547: 自定义的 panic 信息goroutine 8 [running]:... 一种是无意抛出的，写程序马虎造成，比如， 123var slice = [] int &#123;1, 2, 3, 4, 5&#125;slice[6] = 6 输出： 1232019/09/10 15:27:05 http: panic serving [::1]:61616: runtime error: index out of rangegoroutine 6 [running]:... 想象一下，如果在线上环境出现了 panic，命令行输出的，因为咱们无法捕获就无法定位问题呀，想想都可怕，那么问题来了，怎么捕获异常？ 怎么捕获异常？当程序发生 panic 后，在 defer(延迟函数) 内部可以调用 recover 进行捕获。 不多说，直接上代码： 12345defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) &#125;&#125;() 在运行一下 “无意抛出的 panic ”，输出： 1runtime error: index out of range OK，错误捕获到了，这时我们可以进行做文章了。 做啥文章，大家应该都知道了吧： 获取运行时的调用栈（debug.Stack()） 获取当时的 Request 数据 组装数据，进行发邮件 那么，Go 怎么发邮件呀，有没有开源包呀？ 当然有，请往下看。 封装发邮件方法使用包：gopkg.in/gomail.v2 直接上代码： 1234567891011121314151617181920212223242526272829func SendMail(mailTo string, subject string, body string) error &#123; if config.ErrorNotifyOpen != 1 &#123; return nil &#125; m := gomail.NewMessage() //设置发件人 m.SetHeader(&quot;From&quot;, config.SystemEmailUser) //设置发送给多个用户 mailArrTo := strings.Split(mailTo, &quot;,&quot;) m.SetHeader(&quot;To&quot;, mailArrTo...) //设置邮件主题 m.SetHeader(&quot;Subject&quot;, subject) //设置邮件正文 m.SetBody(&quot;text/html&quot;, body) d := gomail.NewDialer(config.SystemEmailHost, config.SystemEmailPort, config.SystemEmailUser, config.SystemEmailPass) err := d.DialAndSend(m) if err != nil &#123; fmt.Println(err) &#125; return err&#125; 在这块我加了一个开关，想开想关，您随意。 现在会发送邮件了，再整个邮件模板就完美了。 自定义邮件模板如图： 这就是告警邮件的模板，还不错吧，大家还想记录什么，可以自定义去修改。 封装一个中间件最后，封装一下。 直接上代码： 1234567891011121314151617181920212223242526272829func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; defer func() &#123; if err := recover(); err != nil &#123; DebugStack := &quot;&quot; for _, v := range strings.Split(string(debug.Stack()), &quot;\\n&quot;) &#123; DebugStack += v + &quot;&lt;br&gt;&quot; &#125; subject := fmt.Sprintf(&quot;【重要错误】%s 项目出错了！&quot;, config.AppName) body := strings.ReplaceAll(MailTemplate, &quot;&#123;ErrorMsg&#125;&quot;, fmt.Sprintf(&quot;%s&quot;, err)) body = strings.ReplaceAll(body, &quot;&#123;RequestTime&#125;&quot;, util.GetCurrentDate()) body = strings.ReplaceAll(body, &quot;&#123;RequestURL&#125;&quot;, c.Request.Method + &quot; &quot; + c.Request.Host + c.Request.RequestURI) body = strings.ReplaceAll(body, &quot;&#123;RequestUA&#125;&quot;, c.Request.UserAgent()) body = strings.ReplaceAll(body, &quot;&#123;RequestIP&#125;&quot;, c.ClientIP()) body = strings.ReplaceAll(body, &quot;&#123;DebugStack&#125;&quot;, DebugStack) _ = util.SendMail(config.ErrorNotifyUser, subject, body) utilGin := util.Gin&#123;Ctx: c&#125; utilGin.Response(500, &quot;系统异常，请联系管理员！&quot;, nil) &#125; &#125;() c.Next() &#125;&#125; 当发生 panic 异常时，输出： 12345&#123; &quot;code&quot;: 500, &quot;msg&quot;: &quot;系统异常，请联系管理员！&quot;, &quot;data&quot;: null&#125; 同时，还会收到一封 panic 告警邮件。 便于截图，DebugStack 删减了一些信息。 到这，就结束了。 备注 发邮件的地方，可以调整为异步发送。 文章中仅贴了部分代码，相关代码请查阅 github。 测试发邮件时，一定要配置邮箱信息。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"路由中间件 - 日志记录","slug":"gin-log-1","date":"2019-03-10T11:22:20.000Z","updated":"2022-05-13T09:40:47.454Z","comments":true,"path":"2019/03/10/gin-log-1/","link":"","permalink":"https://timmy6.github.io/2019/03/10/gin-log-1/","excerpt":"","text":"首先同步下项目概况： 上篇文章分享了，规划项目目录和参数验证，其中参数验证使用的是 validator.v8 版本，现已更新到 validator.v9 版本，最新代码查看 github 即可。 这篇文章咱们分享：路由中间件 - 日志记录。 日志是特别重要的一个东西，方便我们对问题进行排查，这篇文章我们实现将日志记录到文本文件中。 这是我规划的，需要记录的参数： 1234567891011121314151617- request 请求数据 - request_time - request_method - request_uri - request_proto - request_ua - request_referer - request_post_data - request_client_ip - response 返回数据 - response_time - response_code - response_msg - response_data - cost_time 花费时间 Gin 框架中自带 Logger 中间件，我们了解下框架中自带的 Logger 中间件是否满足我们的需求？ gin.Logger()我们先使用 gin.Logger() 看看效果。 在 route.go SetupRouter 方法中增加代码： 1engine.Use(gin.Logger()) 运行后多请求几次，日志输出在命令行中： 123[GIN] 2019/08/30 - 21:24:16 | 200 | 178.072µs | ::1 | GET /ping[GIN] 2019/08/30 - 21:24:27 | 200 | 367.997µs | ::1 | POST /product[GIN] 2019/08/30 - 21:24:28 | 200 | 2.521592ms | ::1 | POST /product 先解决第一个问题，怎么将日志输出到文本中？ 在 route.go SetupRouter 方法中增加代码： 123f, _ := os.Create(config.AppAccessLogName)gin.DefaultWriter = io.MultiWriter(f)engine.Use(gin.Logger()) 运行后多请求几次，日志输出在文件中： 123[GIN] 2019/08/30 - 21:36:07 | 200 | 369.023µs | ::1 | GET /ping[GIN] 2019/08/30 - 21:36:08 | 200 | 27.585µs | ::1 | GET /ping[GIN] 2019/08/30 - 21:36:10 | 200 | 14.302µs | ::1 | POST /product 虽然记录到文件成功了，但是记录的参数不是我们想要的样子。 怎么办呢？ 我们需要自定义一个日志中间件，按照我们需要的参数进行记录。 自定义 Logger()middleware&#x2F;logger&#x2F;logger.go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package loggerimport ( &quot;bytes&quot; &quot;encoding/json&quot; &quot;fmt&quot; &quot;github.com/gin-gonic/gin&quot; &quot;go-gin-api/app/config&quot; &quot;go-gin-api/app/util&quot; &quot;log&quot; &quot;os&quot;)type bodyLogWriter struct &#123; gin.ResponseWriter body *bytes.Buffer&#125;func (w bodyLogWriter) Write(b []byte) (int, error) &#123; w.body.Write(b) return w.ResponseWriter.Write(b)&#125;func (w bodyLogWriter) WriteString(s string) (int, error) &#123; w.body.WriteString(s) return w.ResponseWriter.WriteString(s)&#125;func SetUp() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; bodyLogWriter := &amp;bodyLogWriter&#123;body: bytes.NewBufferString(&quot;&quot;), ResponseWriter: c.Writer&#125; c.Writer = bodyLogWriter //开始时间 startTime := util.GetCurrentMilliTime() //处理请求 c.Next() responseBody := bodyLogWriter.body.String() var responseCode int var responseMsg string var responseData interface&#123;&#125; if responseBody != &quot;&quot; &#123; response := util.Response&#123;&#125; err := json.Unmarshal([]byte(responseBody), &amp;response) if err == nil &#123; responseCode = response.Code responseMsg = response.Message responseData = response.Data &#125; &#125; //结束时间 endTime := util.GetCurrentMilliTime() if c.Request.Method == &quot;POST&quot; &#123; c.Request.ParseForm() &#125; //日志格式 accessLogMap := make(map[string]interface&#123;&#125;) accessLogMap[&quot;request_time&quot;] = startTime accessLogMap[&quot;request_method&quot;] = c.Request.Method accessLogMap[&quot;request_uri&quot;] = c.Request.RequestURI accessLogMap[&quot;request_proto&quot;] = c.Request.Proto accessLogMap[&quot;request_ua&quot;] = c.Request.UserAgent() accessLogMap[&quot;request_referer&quot;] = c.Request.Referer() accessLogMap[&quot;request_post_data&quot;] = c.Request.PostForm.Encode() accessLogMap[&quot;request_client_ip&quot;] = c.ClientIP() accessLogMap[&quot;response_time&quot;] = endTime accessLogMap[&quot;response_code&quot;] = responseCode accessLogMap[&quot;response_msg&quot;] = responseMsg accessLogMap[&quot;response_data&quot;] = responseData accessLogMap[&quot;cost_time&quot;] = fmt.Sprintf(&quot;%vms&quot;, endTime - startTime) accessLogJson, _ := util.JsonEncode(accessLogMap) if f, err := os.OpenFile(config.AppAccessLogName, os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0666); err != nil &#123; log.Println(err) &#125; else &#123; f.WriteString(accessLogJson + &quot;\\n&quot;) &#125; &#125;&#125; 运行后多请求几次，日志输出在文件中： 123&#123;&quot;cost_time&quot;:&quot;0ms&quot;,&quot;request_client_ip&quot;:&quot;::1&quot;,&quot;request_method&quot;:&quot;GET&quot;,&quot;request_post_data&quot;:&quot;&quot;,&quot;request_proto&quot;:&quot;HTTP/1.1&quot;,&quot;request_referer&quot;:&quot;&quot;,&quot;request_time&quot;:1567172568233,&quot;request_ua&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36&quot;,&quot;request_uri&quot;:&quot;/ping&quot;,&quot;response_code&quot;:1,&quot;response_data&quot;:null,&quot;response_msg&quot;:&quot;pong&quot;,&quot;response_time&quot;:1567172568233&#125;&#123;&quot;cost_time&quot;:&quot;0ms&quot;,&quot;request_client_ip&quot;:&quot;::1&quot;,&quot;request_method&quot;:&quot;GET&quot;,&quot;request_post_data&quot;:&quot;&quot;,&quot;request_proto&quot;:&quot;HTTP/1.1&quot;,&quot;request_referer&quot;:&quot;&quot;,&quot;request_time&quot;:1567172569158,&quot;request_ua&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36&quot;,&quot;request_uri&quot;:&quot;/ping&quot;,&quot;response_code&quot;:1,&quot;response_data&quot;:null,&quot;response_msg&quot;:&quot;pong&quot;,&quot;response_time&quot;:1567172569158&#125;&#123;&quot;cost_time&quot;:&quot;0ms&quot;,&quot;request_client_ip&quot;:&quot;::1&quot;,&quot;request_method&quot;:&quot;POST&quot;,&quot;request_post_data&quot;:&quot;name=admin&quot;,&quot;request_proto&quot;:&quot;HTTP/1.1&quot;,&quot;request_referer&quot;:&quot;&quot;,&quot;request_time&quot;:1567172629565,&quot;request_ua&quot;:&quot;PostmanRuntime/7.6.0&quot;,&quot;request_uri&quot;:&quot;/product&quot;,&quot;response_code&quot;:-1,&quot;response_data&quot;:null,&quot;response_msg&quot;:&quot;Key: &#x27;ProductAdd.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;NameValid&#x27; tag&quot;,&quot;response_time&quot;:1567172629565&#125; OK，咱们想要的所有参数全都记录了！ 抛出几个问题吧： 1、有没有开源的日志记录工具？ 当然有，其中 logrus 是用的最多的，这个工具功能强大。 2、为什么将日志记录到文本中？ 因为，日志平台可以使用的是 ELK。 使用 Logstash 进行收集文本文件，使用 Elasticsearch 引擎进行搜索分析，最终在 Kibana 平台展示出来。 3、当大量请求过来时，写入文件会不会出问题？ 可能会，这块可以使用异步，咱们可以用下 go 的 chan。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"规划项目目录和参数验证","slug":"gin-modules2","date":"2019-02-25T11:22:20.000Z","updated":"2022-05-13T07:48:43.346Z","comments":true,"path":"2019/02/25/gin-modules2/","link":"","permalink":"https://timmy6.github.io/2019/02/25/gin-modules2/","excerpt":"","text":"概述首先同步下项目概况： 上篇文章分享了，使用 go modules 初始化项目，这篇文章咱们分享： 规划目录结构 模型绑定和验证 自定义验证器 制定 API 返回结构 废话不多说，咱们开始吧。 规划目录结构12345678910111213141516171819202122232425├─ go-gin-api│ ├─ app│ ├─ config //配置文件│ ├─ config.go│ ├─ controller //控制器层│ ├─ param_bind│ ├─ param_verify│ ├─ ...│ ├─ model //数据库ORM│ ├─ proto│ ├─ ...│ ├─ repository //数据库操作层│ ├─ ...│ ├─ route //路由│ ├─ middleware│ ├─ route.go│ ├─ service //业务层│ ├─ ...│ ├─ util //工具包│ ├─ ...│ ├─ vendor //依赖包│ ├─ ...│ ├─ go.mod│ ├─ go.sum│ ├─ main.go //入口文件 上面的目录结构是我自定义的，大家也可以根据自己的习惯去定义。 controller 控制器层主要对提交过来的数据进行验证，然后将验证完成的数据传递给 service 处理。 在 gin 框架中，参数验证有两种： 1、模型绑定和验证。 2、自定义验证器。 其中目录 param_bind，存储的是参数绑定的数据，目录param_verify 存储的是自定义验证器。 接下来，让咱们进行简单实现。 模型绑定和验证比如，有一个创建商品的接口，商品名称不能为空。 配置路由(route.go)： 1234567891011121314ProductRouter := engine.Group(&quot;&quot;)&#123; // 新增产品 ProductRouter.POST(&quot;/product&quot;, product.Add) // 更新产品 ProductRouter.PUT(&quot;/product/:id&quot;, product.Edit) // 删除产品 ProductRouter.DELETE(&quot;/product/:id&quot;, product.Delete) // 获取产品详情 ProductRouter.GET(&quot;/product/:id&quot;, product.Detail)&#125; 参数绑定(param_bind&#x2F;product.go)： 123type ProductAdd struct &#123; Name string `form:&quot;name&quot; json:&quot;name&quot; binding:&quot;required&quot;`&#125; 控制器调用(controller&#x2F;product.go)： 1234if err := c.ShouldBind(&amp;param_bind.ProductAdd&#123;&#125;); err != nil &#123; utilGin.Response(-1, err.Error(), nil) return&#125; 咱们用 Postman 模拟 post 请求时，name 参数不传或传递为空，会出现： Key: ‘ProductAdd.Name’ Error:Field validation for ‘Name’ failed on the ‘required’ tag 这就使用到了参数设置的 binding:&quot;required&quot;。 那么还能使用 binding 哪些参数，有文档吗？ 有。Gin 使用 go-playground&#x2F;validator.v8 进行验证，相关文档： https://godoc.org/gopkg.in/go-playground/validator.v8 接下来，咱们实现一下自定义验证器。 自定义验证器比如，有一个创建商品的接口，商品名称不能为空并且参数名称不能等于 admin。 类似于这种业务需求，无法 binding 现成的方法，需要我们自己写验证方法，才能实现。 自定义验证方法(param_verify&#x2F;product.go) 1234567891011func NameValid ( v *validator.Validate, topStruct reflect.Value, currentStructOrField reflect.Value, field reflect.Value, fieldType reflect.Type, fieldKind reflect.Kind, param string,) bool &#123; if s, ok := field.Interface().(string); ok &#123; if s == &quot;admin&quot; &#123; return false &#125; &#125; return true&#125; 参数绑定(param_bind&#x2F;product.go)： 123type ProductAdd struct &#123; Name string `form:&quot;name&quot; json:&quot;name&quot; binding:&quot;required,NameValid&quot;`&#125; 同时还要绑定验证器: 1234// 绑定验证器if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;NameValid&quot;, param_verify.NameValid)&#125; 咱们用 Postman 模拟 post 请求时，name 参数不传或传递为空，会出现： Key: ‘ProductAdd.Name’ Error:Field validation for ‘Name’ failed on the ‘required’ tag name&#x3D;admin 时： Key: ‘ProductAdd.Name’ Error:Field validation for ‘Name’ failed on the ‘NameValid’ tag OK，上面两个验证都生效了！ 上面的输出都是在控制台，能不能返回一个 Json 结构的数据呀？ 能。接下来咱们制定 API 返回结构。 制定 API 返回结构12345&#123; &quot;code&quot;: 1, &quot;msg&quot;: &quot;&quot;, &quot;data&quot;: null&#125; API 接口的返回的结构基本都是这三个字段。 比如 code&#x3D;1 表示成功，code&#x3D;-1 表示失败。 msg 表示提示信息。 data 表示要返回的数据。 那么，我们怎么在 gin 框架中实现它，其实很简单 基于 c.JSON() 方法进行封装即可，直接看代码。 12345678910111213141516171819202122package utilimport &quot;github.com/gin-gonic/gin&quot;type Gin struct &#123; Ctx *gin.Context&#125;type response struct &#123; Code int `json:&quot;code&quot;` Message string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125;func (g *Gin)Response(code int, msg string, data interface&#123;&#125;) &#123; g.Ctx.JSON(200, response&#123; Code : code, Message : msg, Data : data, &#125;) return&#125; 控制器调用(controller&#x2F;product.go)： 12345utilGin := util.Gin&#123;Ctx:c&#125;if err := c.ShouldBind(&amp;param_bind.ProductAdd&#123;&#125;); err != nil &#123; utilGin.Response(-1, err.Error(), nil) return&#125; 咱们用 Postman 模拟 post 请求时，name 参数不传或传递为空，会出现： 12345&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;Key: &#x27;ProductAdd.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;required&#x27; tag&quot;, &quot;data&quot;: null&#125; name&#x3D;admin 时： 12345&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;Key: &#x27;ProductAdd.Name&#x27; Error:Field validation for &#x27;Name&#x27; failed on the &#x27;NameValid&#x27; tag&quot;, &quot;data&quot;: null&#125; OK，上面两个验证都生效了！ 源码地址https://github.com/xinliangnote/go-gin-api go-gin-api 系列文章 1. 使用 go modules 初始化项目 备注Gin 模型验证 Validator 升级：validator.v8 升级为 validator.v9，已提交到 github !!!","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"使用 go modules 初始化项目","slug":"gin-modules","date":"2019-02-15T13:12:50.000Z","updated":"2022-05-13T07:42:06.370Z","comments":true,"path":"2019/02/15/gin-modules/","link":"","permalink":"https://timmy6.github.io/2019/02/15/gin-modules/","excerpt":"","text":"概述我想实现一个开箱即用的 API 框架的轮子，这个轮子是基于 Gin 基础上开发的。 为什么是开箱即用，它会集成哪些功能？ 以上功能点，都是常用的，后期可能还会增加。 废话不多说，咱们开始吧。 创建一个项目，咱们首先要考虑一个依赖包的管理工具。 常见的包管理有，dep、go vendor、glide、go modules 等。 最开始，使用过 dep，当时被朋友 diss 了，推荐我使用 go modules 。 现在来说一下 go modules ，这个是随着 Go 1.11 的发布和我们见面的，这是官方提倡的新的包管理。 说一个环境变量：GO111MODULE，默认值为 auto 。 当项目中有 go.mod 时，使用 go modules 管理，反之使用 旧的 GOPATH 和 vendor机制。 如果就想使用 go modules ，可以将 GO111MODULE 设置为 on 。 直接上手吧。 初始化咱们在 GOPATH 之外的地方，新建一个空文件夹 go-gin-api 。 1cd go-gin-api &amp;&amp; go mod init go-gin-api 输出： go: creating new go.mod: module go-gin-api 这时目录中多一个 go.mod 文件，内容如下： 123module go-gin-apigo 1.12 到这，go mod 初始化就完成，接下来添加依赖包 - gin。 添加依赖包在目录中创建一个 main.go 的文件，放上如下代码： 12345678910111213package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.GET(&quot;/ping&quot;, func(c *gin.Context) &#123; c.JSON(200, gin.H&#123; &quot;message&quot;: &quot;pong&quot;, &#125;) &#125;) r.Run() // listen and serve on 0.0.0.0:8080&#125; 这代码没什么特别的，就是官方的入门Demo。 接下来，开始下载依赖包。 1go mod tidy 执行完成后，看一下 go.mod 文件： 12345module go-gin-apigo 1.12require github.com/gin-gonic/gin v1.4.0 这时，看到新增一个 gin v1.4.0 的包。 还生成了一个 go.sum 的文件，这个文件可以暂时先不管。 这时发现了 2 个问题。 1、目录中没发现 gin 包，包下载到哪了？ 下载到了 GOPATH&#x2F;pkg&#x2F;mod 目录中。 2、GoLand 编辑器中关于 Gin 的引用变红了？ 在这里编辑器需要设置一下，如图： 点击 Apply 和 OK 即可。 如果这招不灵，还可以执行： 1go mod vendor 这个命令是将项目依赖的包，放到项目的 vendor 目录中，这肯定就可以了。 go mod 命令go mod tidy 拉取缺少的模块，移除不用的模块。 我常用这个命令。 go mod vendor 将依赖复制到vendor下。 我常用这个命令。 go mod download 下载依赖包。 go mod verify 检验依赖。 go mod graph 打印模块依赖图。 其他命令，可以执行 go mod ，查看即可。 小结这篇文章，分享了 go modules 的使用。 使用 go modules 从零搭建一个项目。 GoLand 编辑器使用 go modules。 今天就到这了，下一篇文章开始搭建 API 项目了，写参数验证。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"gRPC 工具","slug":"grpc-tools","date":"2019-02-10T14:22:50.000Z","updated":"2022-05-13T07:37:45.866Z","comments":true,"path":"2019/02/10/grpc-tools/","link":"","permalink":"https://timmy6.github.io/2019/02/10/grpc-tools/","excerpt":"","text":"概述当我们在写 HTTP 接口的时候，使用的是 Postman 进行接口调试，那么在写 gRPC 接口的时候，有没有类似于 Postman 的调试工具呢？ 这是有的。 咱们一起看下 grpcui，源码地址： https://github.com/fullstorydev/grpcui 看下官方描述： grpcui is a command-line tool that lets you interact with gRPC servers via a browser. It’s sort of like Postman, but for gRPC APIs instead of REST. 写一个 gRPC API端口：9901 .proto 文件： 123456789101112131415161718192021syntax = &quot;proto3&quot;; // 指定 proto 版本package listen; // 指定包名// 定义服务service Listen &#123; // 定义方法 rpc ListenData(Request) returns (Response) &#123;&#125;&#125;// Request 请求结构message Request &#123; string name = 1;&#125;// Response 响应结构message Response &#123; string message = 1;&#125; 很简单，这个大家一看就知道了。 Service name 为 listen.Listen Method name 为 ListenData 再看下 ListenData 方法： 123func (l *ListenController) ListenData(ctx context.Context, in *listen.Request) (*listen.Response, error) &#123; return &amp;listen.Response&#123;Message : fmt.Sprintf(&quot;[%s]&quot;, in.Name)&#125;, nil&#125; 这表示，将 Name 直接返回。 启动服务1cd listen &amp;&amp; go run main.go 服务启动成功后，等待使用。 grpcui 使用安装根据官方 README.md 文档安装即可。 12go get github.com/fullstorydev/grpcuigo install github.com/fullstorydev/grpcui/cmd/grpcui 这时，在 $GOPATH/bin 目录下，生成一个 grpcui 可执行文件。 执行个命令，验证下： 1grpcui -help 输出： 1234Usage: grpcui [flags] [address] ...... 表示安装成功了。 运行123grpcui -plaintext 127.0.0.1:9901Failed to compute set of methods to expose: server does not support the reflection API 这种情况下，加个反射就可以了，在 listen 的 main.go 新增如下代码即可： 1reflection.Register(s) 在运行一次试试： 12grpcui -plaintext 127.0.0.1:9901gRPC Web UI available at http://127.0.0.1:63027/ 在浏览器中访问：http://127.0.0.1:63027/ 到这，我们看到 Service name、Method name 都出来了，传输参数直接在页面上进行操作即可。 当发起 Request “Tom”，也能获得 Response “Tom”。 当然，如果这个服务下面有多个 Service name，多个 Method name 也都会显示出来的，去试试吧。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"https://timmy6.github.io/tags/gRPC/"}]},{"title":"gRPC Hello World","slug":"grpc-hello","date":"2019-01-25T13:22:50.000Z","updated":"2022-05-13T07:26:13.715Z","comments":true,"path":"2019/01/25/grpc-hello/","link":"","permalink":"https://timmy6.github.io/2019/01/25/grpc-hello/","excerpt":"","text":"概述开始 gRPC 了，这篇文章学习使用 gRPC，输出一个 Hello World。 用 Go 实现 gRPC 的服务端。 用 Go 实现 gRPC 的客户端。 gRPC 支持 4 类服务方法，咱们这次实现 单项 RPC 和 服务端流式 RPC。 四类服务方法单项 RPC 服务端发送一个请求给服务端，从服务端获取一个应答，就像一次普通的函数调用。 1rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 服务端流式 RPC 客户端发送一个请求给服务端，可获取一个数据流用来读取一系列消息。客户端从返回的数据流里一直读取直到没有更多消息为止。 1rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 客户端流式 RPC 客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。 1rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 双向流式 RPC 两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是相互独立的，所以客户端和服务端能按其希望的任意顺序读写，例如：服务端可以在写应答前等待所有的客户端消息，或者它可以先读一个消息再写一个消息，或者是读写相结合的其他方式。每个数据流里消息的顺序会被保持。 1rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; 安装安装 protobuf 编译器 1brew install protobuf 验证： 123protoc --version//输出：libprotoc 3.7.1 安装 Go protobuf 插件 123go get -u github.com/golang/protobuf/protogo get -u github.com/golang/protobuf/protoc-gen-go 安装 grpc-go 1go get -u google.golang.org/grpc 写个 Hello World 服务 编写服务端 .proto 文件 生成服务端 .pb.go 文件并同步给客户端 编写服务端提供接口的代码 编写客户端调用接口的代码 目录结构 123456789101112131415├─ hello -- 代码根目录│ ├─ go_client│ ├── main.go│ ├── proto│ ├── hello│ ├── hello.pb.go│ ├─ go_server│ ├── main.go│ ├── controller│ ├── hello_controller│ ├── hello_server.go│ ├── proto│ ├── hello│ ├── hello.pb.go│ ├── hello.proto 这样创建目录是为了 go_client 和 go_server 后期可以拆成两个项目。 编写服务端 hello.proto 文件 123456789101112131415161718192021222324syntax = &quot;proto3&quot;; // 指定 proto 版本package hello; // 指定包名// 定义 Hello 服务service Hello &#123; // 定义 SayHello 方法 rpc SayHello(HelloRequest) returns (HelloResponse) &#123;&#125; // 定义 LotsOfReplies 方法 rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125;&#125;// HelloRequest 请求结构message HelloRequest &#123; string name = 1;&#125;// HelloResponse 响应结构message HelloResponse &#123; string message = 1;&#125; 了解更多 Protobuf 语法，请查看： https://developers.google.com/protocol-buffers/ 生成服务端 .pb.go 1protoc -I . --go_out=plugins=grpc:. ./hello.proto 同时将生成的 hello.pb.go 复制到客户端一份。 查看更多命令参数，执行 protoc，查看 OPTION 。 编写服务端提供接口的代码 123456789101112131415161718192021// hello_server.gopackage hello_controllerimport ( &quot;fmt&quot; &quot;golang.org/x/net/context&quot; &quot;hello/go_server/proto/hello&quot;)type HelloController struct&#123;&#125;func (h *HelloController) SayHello(ctx context.Context, in *hello.HelloRequest) (*hello.HelloResponse, error) &#123; return &amp;hello.HelloResponse&#123;Message : fmt.Sprintf(&quot;%s&quot;, in.Name)&#125;, nil&#125;func (h *HelloController) LotsOfReplies(in *hello.HelloRequest, stream hello.Hello_LotsOfRepliesServer) error &#123; for i := 0; i &lt; 10; i++ &#123; stream.Send(&amp;hello.HelloResponse&#123;Message : fmt.Sprintf(&quot;%s %s %d&quot;, in.Name, &quot;Reply&quot;, i)&#125;) &#125; return nil&#125; 1234567891011121314151617181920212223242526272829303132// main.gopackage mainimport ( &quot;log&quot; &quot;net&quot; &quot;hello/go_server/proto/hello&quot; &quot;hello/go_server/controller/hello_controller&quot; &quot;google.golang.org/grpc&quot;)const ( Address = &quot;0.0.0.0:9090&quot;)func main() &#123; listen, err := net.Listen(&quot;tcp&quot;, Address) if err != nil &#123; log.Fatalf(&quot;Failed to listen: %v&quot;, err) &#125; s := grpc.NewServer() // 服务注册 hello.RegisterHelloServer(s, &amp;hello_controller.HelloController&#123;&#125;) log.Println(&quot;Listen on &quot; + Address) if err := s.Serve(listen); err != nil &#123; log.Fatalf(&quot;Failed to serve: %v&quot;, err) &#125;&#125; 运行： 123go run main.go2019/07/28 17:51:20 Listen on 0.0.0.0:9090 编写客户端请求接口的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package mainimport ( &quot;hello/go_client/proto/hello&quot; &quot;io&quot; &quot;log&quot; &quot;golang.org/x/net/context&quot; &quot;google.golang.org/grpc&quot;)const ( // gRPC 服务地址 Address = &quot;0.0.0.0:9090&quot;)func main() &#123; conn, err := grpc.Dial(Address, grpc.WithInsecure()) if err != nil &#123; log.Fatalln(err) &#125; defer conn.Close() // 初始化客户端 c := hello.NewHelloClient(conn) // 调用 SayHello 方法 res, err := c.SayHello(context.Background(), &amp;hello.HelloRequest&#123;Name: &quot;Hello World&quot;&#125;) if err != nil &#123; log.Fatalln(err) &#125; log.Println(res.Message) // 调用 LotsOfReplies 方法 stream, err := c.LotsOfReplies(context.Background(),&amp;hello.HelloRequest&#123;Name: &quot;Hello World&quot;&#125;) if err != nil &#123; log.Fatalln(err) &#125; for &#123; res, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Printf(&quot;stream.Recv: %v&quot;, err) &#125; log.Printf(&quot;%s&quot;, res.Message) &#125;&#125; 运行： 12345678910111213go run main.go2019/07/28 17:58:13 Hello World2019/07/28 17:58:13 Hello World Reply 02019/07/28 17:58:13 Hello World Reply 12019/07/28 17:58:13 Hello World Reply 22019/07/28 17:58:13 Hello World Reply 32019/07/28 17:58:13 Hello World Reply 42019/07/28 17:58:13 Hello World Reply 52019/07/28 17:58:13 Hello World Reply 62019/07/28 17:58:13 Hello World Reply 72019/07/28 17:58:13 Hello World Reply 82019/07/28 17:58:13 Hello World Reply 9","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"https://timmy6.github.io/tags/gRPC/"}]},{"title":"统一定义API错误码","slug":"error-code","date":"2019-01-15T13:22:50.000Z","updated":"2022-05-13T07:22:22.732Z","comments":true,"path":"2019/01/15/error-code/","link":"","permalink":"https://timmy6.github.io/2019/01/15/error-code/","excerpt":"","text":"改之前在使用 gin 开发接口的时候，返回接口数据是这样写的。 123456789101112type response struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125;// always return http.StatusOKc.JSON(http.StatusOK, response&#123; Code: 20101, Msg: &quot;用户手机号不合法&quot;, Data: nil,&#125;) 这种写法 code、msg 都是在哪需要返回在哪定义，没有进行统一管理。 改之后12345// 比如，返回“用户手机号不合法”错误c.JSON(http.StatusOK, errno.ErrUserPhone.WithID(c.GetString(&quot;trace-id&quot;)))// 正确返回c.JSON(http.StatusOK, errno.OK.WithData(data).WithID(c.GetString(&quot;trace-id&quot;))) errno.ErrUserPhone、errno.OK 表示自定义的错误码，下面会看到定义的地方。 .WithID() 设置当前请求的唯一ID，也可以理解为链路ID，忽略也可以。 .WithData() 设置成功时返回的数据。 下面分享下编写的 errno 包源码，非常简单，希望大家不要介意。 errno 包源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// errno/errno.gopackage errnoimport ( &quot;encoding/json&quot;)var _ Error = (*err)(nil)type Error interface &#123; // i 为了避免被其他包实现 i() // WithData 设置成功时返回的数据 WithData(data interface&#123;&#125;) Error // WithID 设置当前请求的唯一ID WithID(id string) Error // ToString 返回 JSON 格式的错误详情 ToString() string&#125;type err struct &#123; Code int `json:&quot;code&quot;` // 业务编码 Msg string `json:&quot;msg&quot;` // 错误描述 Data interface&#123;&#125; `json:&quot;data&quot;` // 成功时返回的数据 ID string `json:&quot;id,omitempty&quot;` // 当前请求的唯一ID，便于问题定位，忽略也可以&#125;func NewError(code int, msg string) Error &#123; return &amp;err&#123; Code: code, Msg: msg, Data: nil, &#125;&#125;func (e *err) i() &#123;&#125;func (e *err) WithData(data interface&#123;&#125;) Error &#123; e.Data = data return e&#125;func (e *err) WithID(id string) Error &#123; e.ID = id return e&#125;// ToString 返回 JSON 格式的错误详情func (e *err) ToString() string &#123; err := &amp;struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;` ID string `json:&quot;id,omitempty&quot;` &#125;&#123; Code: e.Code, Msg: e.Msg, Data: e.Data, ID: e.ID, &#125; raw, _ := json.Marshal(err) return string(raw)&#125; 12345678910111213141516171819// errno/code.gopackage errnovar ( // OK OK = NewError(0, &quot;OK&quot;) // 服务级错误码 ErrServer = NewError(10001, &quot;服务异常，请联系管理员&quot;) ErrParam = NewError(10002, &quot;参数有误&quot;) ErrSignParam = NewError(10003, &quot;签名参数有误&quot;) // 模块级错误码 - 用户模块 ErrUserPhone = NewError(20101, &quot;用户手机号不合法&quot;) ErrUserCaptcha = NewError(20102, &quot;用户验证码有误&quot;) // ...) 错误码规则 错误码需在 code.go 文件中定义。 错误码需为 &gt; 0 的数，反之表示正确。 错误码为 5 位数 1 01 01 服务级错误码 模块级错误码 具体错误码 服务级别错误码：1 位数进行表示，比如 1 为系统级错误；2 为普通错误，通常是由用户非法操作引起。 模块级错误码：2 位数进行表示，比如 01 为用户模块；02 为订单模块。 具体错误码：2 位数进行表示，比如 01 为手机号不合法；02 为验证码输入错误。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"自定义错误处理","slug":"custom-err","date":"2019-01-10T13:22:50.000Z","updated":"2022-05-13T07:16:06.972Z","comments":true,"path":"2019/01/10/custom-err/","link":"","permalink":"https://timmy6.github.io/2019/01/10/custom-err/","excerpt":"","text":"概述开始今天的文章，为什么要自定义错误处理？默认的错误处理方式是什么？ 那好，咱们就先说下默认的错误处理。 默认的错误处理是 errors.New(&quot;错误信息&quot;)，这个信息通过 error 类型的返回值进行返回。 举个简单的例子： 12345678func hello(name string) (str string, err error) &#123; if name == &quot;&quot; &#123; err = errors.New(&quot;name 不能为空&quot;) return &#125; str = fmt.Sprintf(&quot;hello: %s&quot;, name) return&#125; 当调用这个方法时： 123456var name = &quot;&quot;str, err := hello(name)if err != nil &#123; fmt.Println(err.Error()) return&#125; 这就是默认的错误处理，下面还会用这个例子进行说。 这个默认的错误处理，只是得到了一个错误信息的字符串。 然而… 我还想得到发生错误时的 时间、文件名、方法名、行号 等信息。 我还想得到错误时进行告警，比如 短信告警、邮件告警、微信告警 等。 我还想调用的时候，不那么复杂，就和默认错误处理类似，比如： 12alarm.WeChat(&quot;错误信息&quot;)return 这样，我们就得到了我们想要的信息（时间、文件名、方法名、行号），并通过 微信 的方式进行告警通知我们。 同理，alarm.Email(&quot;错误信息&quot;)、alarm.Sms(&quot;错误信息&quot;) 我们得到的信息是一样的，只是告警方式不同而已。 还要保证，我们业务逻辑中，获取错误的时候，只获取错误信息即可。 上面这些想出来的，就是今天要实现的，自定义错误处理，我们就实现之前，先说下 Go 的错误处理。 错误处理12345678910111213141516171819202122232425262728package mainimport ( &quot;errors&quot; &quot;fmt&quot;)func hello(name string) (str string, err error) &#123; if name == &quot;&quot; &#123; err = errors.New(&quot;name 不能为空&quot;) return &#125; str = fmt.Sprintf(&quot;hello: %s&quot;, name) return&#125;func main() &#123; var name = &quot;&quot; fmt.Println(&quot;param:&quot;, name) str, err := hello(name) if err != nil &#123; fmt.Println(err.Error()) return &#125; fmt.Println(str)&#125; 输出： 12param: Tomhello: Tom 当 name &#x3D; “” 时，输出： 12param:name 不能为空 建议每个函数都要有错误处理，error 应该为最后一个返回值。 咱们一起看下官方 errors.go 1234567891011121314151617181920// Copyright 2011 The Go Authors. All rights reserved.// Use of this source code is governed by a BSD-style// license that can be found in the LICENSE file.// Package errors implements functions to manipulate errors.package errors// New returns an error that formats as the given text.func New(text string) error &#123; return &amp;errorString&#123;text&#125;&#125;// errorString is a trivial implementation of error.type errorString struct &#123; s string&#125;func (e *errorString) Error() string &#123; return e.s&#125; 上面的代码，并不复杂，参照上面的，咱们进行写一个自定义错误处理。 自定义错误处理咱们定义一个 alarm.go，用于处理告警。 废话不多说，直接看代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package alarmimport ( &quot;encoding/json&quot; &quot;fmt&quot; &quot;ginDemo/common/function&quot; &quot;path/filepath&quot; &quot;runtime&quot; &quot;strings&quot;)type errorString struct &#123; s string&#125;type errorInfo struct &#123; Time string `json:&quot;time&quot;` Alarm string `json:&quot;alarm&quot;` Message string `json:&quot;message&quot;` Filename string `json:&quot;filename&quot;` Line int `json:&quot;line&quot;` Funcname string `json:&quot;funcname&quot;`&#125;func (e *errorString) Error() string &#123; return e.s&#125;func New (text string) error &#123; alarm(&quot;INFO&quot;, text) return &amp;errorString&#123;text&#125;&#125;// 发邮件func Email (text string) error &#123; alarm(&quot;EMAIL&quot;, text) return &amp;errorString&#123;text&#125;&#125;// 发短信func Sms (text string) error &#123; alarm(&quot;SMS&quot;, text) return &amp;errorString&#123;text&#125;&#125;// 发微信func WeChat (text string) error &#123; alarm(&quot;WX&quot;, text) return &amp;errorString&#123;text&#125;&#125;// 告警方法func alarm(level string, str string) &#123; // 当前时间 currentTime := function.GetTimeStr() // 定义 文件名、行号、方法名 fileName, line, functionName := &quot;?&quot;, 0 , &quot;?&quot; pc, fileName, line, ok := runtime.Caller(2) if ok &#123; functionName = runtime.FuncForPC(pc).Name() functionName = filepath.Ext(functionName) functionName = strings.TrimPrefix(functionName, &quot;.&quot;) &#125; var msg = errorInfo &#123; Time : currentTime, Alarm : level, Message : str, Filename : fileName, Line : line, Funcname : functionName, &#125; jsons, errs := json.Marshal(msg) if errs != nil &#123; fmt.Println(&quot;json marshal error:&quot;, errs) &#125; errorJsonInfo := string(jsons) fmt.Println(errorJsonInfo) if level == &quot;EMAIL&quot; &#123; // 执行发邮件 &#125; else if level == &quot;SMS&quot; &#123; // 执行发短信 &#125; else if level == &quot;WX&quot; &#123; // 执行发微信 &#125; else if level == &quot;INFO&quot; &#123; // 执行记日志 &#125;&#125; 看下如何调用： 1234567891011121314151617181920212223242526272829303132333435363738package v1import ( &quot;fmt&quot; &quot;ginDemo/common/alarm&quot; &quot;ginDemo/entity&quot; &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)func AddProduct(c *gin.Context) &#123; // 获取 Get 参数 name := c.Query(&quot;name&quot;) var res = entity.Result&#123;&#125; str, err := hello(name) if err != nil &#123; res.SetCode(entity.CODE_ERROR) res.SetMessage(err.Error()) c.JSON(http.StatusOK, res) c.Abort() return &#125; res.SetCode(entity.CODE_SUCCESS) res.SetMessage(str) c.JSON(http.StatusOK, res)&#125;func hello(name string) (str string, err error) &#123; if name == &quot;&quot; &#123; err = alarm.WeChat(&quot;name 不能为空&quot;) return &#125; str = fmt.Sprintf(&quot;hello: %s&quot;, name) return&#125; 访问：http://localhost:8080/v1/product/add?name=a 12345&#123; &quot;code&quot;: 1, &quot;msg&quot;: &quot;hello: a&quot;, &quot;data&quot;: null&#125; 未抛出错误，不会输出信息。 访问：http://localhost:8080/v1/product/add 12345&#123; &quot;code&quot;: -1, &quot;msg&quot;: &quot;name 不能为空&quot;, &quot;data&quot;: null&#125; 抛出了错误，输出信息如下： 1&#123;&quot;time&quot;:&quot;2019-07-23 22:19:17&quot;,&quot;alarm&quot;:&quot;WX&quot;,&quot;message&quot;:&quot;name 不能为空&quot;,&quot;filename&quot;:&quot;绝对路径/ginDemo/router/v1/product.go&quot;,&quot;line&quot;:33,&quot;funcname&quot;:&quot;hello&quot;&#125; 这只是个例子，大家可以在一些复杂的业务逻辑判断场景中使用自定义错误处理”。 到这里，报错时我们收到了 时间、错误信息、文件名、行号、方法名 了。 调用起来，也比较简单。 虽然标记了告警方式，还是没有进行告警通知呀。 我想说，在这里存储数据到队列中，再执行异步任务具体去消耗，这块就不实现了，大家可以去完善。 读取 文件名、方法名、行号 使用的是 runtime.Caller()。 我们还知道，Go 有 panic 和 recover，它们是干什么的呢，接下来咱们就说说。 panic 和 recover当程序不能继续运行的时候，才应该使用 panic 抛出错误。 当程序发生 panic 后，在 defer(延迟函数) 内部可以调用 recover 进行控制，不过有个前提条件，只有在相同的 Go 协程中才可以。 panic 分两个，一种是有意抛出的，一种是无意的写程序马虎造成的，咱们一个个说。 有意抛出的 panic： 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Println(&quot;-- 1 --&quot;) defer func() &#123; if r := recover(); r != nil &#123; fmt.Printf(&quot;panic: %s\\n&quot;, r) &#125; fmt.Println(&quot;-- 2 --&quot;) &#125;() panic(&quot;i am panic&quot;)&#125; 输出： 123-- 1 --panic: i am panic-- 2 -- 无意抛出的 panic： 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Println(&quot;-- 1 --&quot;) defer func() &#123; if r := recover(); r != nil &#123; fmt.Printf(&quot;panic: %s\\n&quot;, r) &#125; fmt.Println(&quot;-- 2 --&quot;) &#125;() var slice = [] int &#123;1, 2, 3, 4, 5&#125; slice[6] = 6&#125; 输出： 123-- 1 --panic: runtime error: index out of range-- 2 -- 上面的两个我们都通过 recover 捕获到了，那我们如何在 Gin 框架中使用呢？如果收到 panic 时，也想进行告警怎么实现呢？ 既然想实现告警，先在 ararm.go 中定义一个 Panic() 方法，当项目发生 panic 异常时，调用这个方法，这样就实现告警了。 12345// Panic 异常func Panic (text string) error &#123; alarm(&quot;PANIC&quot;, text) return &amp;errorString&#123;text&#125;&#125; 那我们怎么捕获到呢？ 使用中间件进行捕获，写一个 recover 中间件。 123456789101112131415161718package recoverimport ( &quot;fmt&quot; &quot;ginDemo/common/alarm&quot; &quot;github.com/gin-gonic/gin&quot;)func Recover() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; defer func() &#123; if r := recover(); r != nil &#123; alarm.Panic(fmt.Sprintf(&quot;%s&quot;, r)) &#125; &#125;() c.Next() &#125;&#125; 路由调用中间件： 123r.Use(logger.LoggerToFile(), recover.Recover())//Use 可以传递多个中间件。 验证下吧，咱们先抛出两个异常，看看能否捕获到？ 还是修改 product.go 这个文件吧。 有意抛出 panic： 1234567891011121314151617181920212223242526272829303132333435363738package v1import ( &quot;fmt&quot; &quot;ginDemo/entity&quot; &quot;github.com/gin-gonic/gin&quot; &quot;net/http&quot;)func AddProduct(c *gin.Context) &#123; // 获取 Get 参数 name := c.Query(&quot;name&quot;) var res = entity.Result&#123;&#125; str, err := hello(name) if err != nil &#123; res.SetCode(entity.CODE_ERROR) res.SetMessage(err.Error()) c.JSON(http.StatusOK, res) c.Abort() return &#125; res.SetCode(entity.CODE_SUCCESS) res.SetMessage(str) c.JSON(http.StatusOK, res)&#125;func hello(name string) (str string, err error) &#123; if name == &quot;&quot; &#123; // 有意抛出 panic panic(&quot;i am panic&quot;) return &#125; str = fmt.Sprintf(&quot;hello: %s&quot;, name) return&#125; 访问：http://localhost:8080/v1/product/add 界面是空白的。 抛出了异常，输出信息如下： 1&#123;&quot;time&quot;:&quot;2019-07-23 22:42:37&quot;,&quot;alarm&quot;:&quot;PANIC&quot;,&quot;message&quot;:&quot;i am panic&quot;,&quot;filename&quot;:&quot;绝对路径/ginDemo/middleware/recover/recover.go&quot;,&quot;line&quot;:13,&quot;funcname&quot;:&quot;1&quot;&#125; 很显然，定位的文件名、方法名、行号不是我们想要的。 需要调整 runtime.Caller(2)，这个代码在 alarm.go 的 alarm 方法中。 将 2 调整成 4 ，看下输出信息： 1&#123;&quot;time&quot;:&quot;2019-07-23 22:45:24&quot;,&quot;alarm&quot;:&quot;PANIC&quot;,&quot;message&quot;:&quot;i am panic&quot;,&quot;filename&quot;:&quot;绝对路径/ginDemo/router/v1/product.go&quot;,&quot;line&quot;:33,&quot;funcname&quot;:&quot;hello&quot;&#125; 这就对了。 无意抛出 panic： 123456789101112// 上面代码不变func hello(name string) (str string, err error) &#123; if name == &quot;&quot; &#123; // 无意抛出 panic var slice = [] int &#123;1, 2, 3, 4, 5&#125; slice[6] = 6 return &#125; str = fmt.Sprintf(&quot;hello: %s&quot;, name) return&#125; 访问：http://localhost:8080/v1/product/add 界面是空白的。 抛出了异常，输出信息如下： 1&#123;&quot;time&quot;:&quot;2019-07-23 22:50:06&quot;,&quot;alarm&quot;:&quot;PANIC&quot;,&quot;message&quot;:&quot;runtime error: index out of range&quot;,&quot;filename&quot;:&quot;绝对路径/runtime/panic.go&quot;,&quot;line&quot;:44,&quot;funcname&quot;:&quot;panicindex&quot;&#125; 很显然，定位的文件名、方法名、行号也不是我们想要的。 将 4 调整成 5 ，看下输出信息： 1&#123;&quot;time&quot;:&quot;2019-07-23 22:55:27&quot;,&quot;alarm&quot;:&quot;PANIC&quot;,&quot;message&quot;:&quot;runtime error: index out of range&quot;,&quot;filename&quot;:&quot;绝对路径/ginDemo/router/v1/product.go&quot;,&quot;line&quot;:34,&quot;funcname&quot;:&quot;hello&quot;&#125; 这就对了。 奇怪了，这是为什么？ 在这里，有必要说下 runtime.Caller(skip) 了。 skip 指的调用的深度。 为 0 时，打印当前调用文件及行数。 为 1 时，打印上级调用的文件及行数。 依次类推… 在这块，调用的时候需要注意下，我现在还没有好的解决方案。 我是将 skip（调用深度），当一个参数传递进去。 比如： 1234567891011// 发微信func WeChat (text string) error &#123; alarm(&quot;WX&quot;, text, 2) return &amp;errorString&#123;text&#125;&#125;// Panic 异常func Panic (text string) error &#123; alarm(&quot;PANIC&quot;, text, 5) return &amp;errorString&#123;text&#125;&#125; 具体的代码就不贴了。 但是，有意抛出 Panic 和 无意抛出 Panic 的调用深度又不同，怎么办？ 1、尽量将有意抛出的 Panic 改成抛出错误的方式。 2、想其他办法搞定它。 就到这吧。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"}]},{"title":"gin日志记录","slug":"gin-log","date":"2019-01-05T13:22:50.000Z","updated":"2022-05-11T09:47:16.798Z","comments":true,"path":"2019/01/05/gin-log/","link":"","permalink":"https://timmy6.github.io/2019/01/05/gin-log/","excerpt":"","text":"概述上篇文章分享了 Gin 框架的路由配置，这篇文章分享日志记录。 查了很多资料，Go 的日志记录用的最多的还是 github.com/sirupsen/logrus。 Logrus is a structured logger for Go (golang), completely API compatible with the standard library logger. Gin 框架的日志默认只会在控制台输出，咱们利用 Logrus 封装一个中间件，将日志记录到文件中。 这篇文章就是学习和使用 Logrus 。 日志格式比如，我们约定日志格式为 Text，包含字段如下： 请求时间、日志级别、状态码、执行时间、请求IP、请求方式、请求路由。 接下来，咱们利用 Logrus 实现它。 Logrus 使用用 dep 方式进行安装。 在 Gopkg.toml 文件新增： 123[[constraint]] name = &quot;github.com/sirupsen/logrus&quot; version = &quot;1.4.2&quot; 在项目中导入： 1import &quot;github.com/sirupsen/logrus&quot; 在项目命令行执行： 1dep ensure 这时，在 vendor/github.com/ 目录中就会看到 sirupsen 目录。 准备上手用了，上手之前咱们先规划一下，将这个功能设置成一个中间件，比如：logger.go。 日志可以记录到 File 中，定义一个 LoggerToFile 方法。 日志可以记录到 MongoDB 中，定义一个 LoggerToMongo 方法。 日志可以记录到 ES 中，定义一个 LoggerToES 方法。 日志可以记录到 MQ 中，定义一个 LoggerToMQ 方法。 … 这次咱们先实现记录到文件， 实现 LoggerToFile 方法，其他的可以根据自己的需求进行实现。 这个 logger 中间件，创建好了，可以任意在其他项目中进行迁移使用。 废话不多说，直接看代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package middlewareimport ( &quot;fmt&quot; &quot;ginDemo/config&quot; &quot;github.com/gin-gonic/gin&quot; &quot;github.com/sirupsen/logrus&quot; &quot;os&quot; &quot;path&quot; &quot;time&quot;)// 日志记录到文件func LoggerToFile() gin.HandlerFunc &#123; logFilePath := config.Log_FILE_PATH logFileName := config.LOG_FILE_NAME //日志文件 fileName := path.Join(logFilePath, logFileName) //写入文件 src, err := os.OpenFile(fileName, os.O_APPEND|os.O_WRONLY, os.ModeAppend) if err != nil &#123; fmt.Println(&quot;err&quot;, err) &#125; //实例化 logger := logrus.New() //设置输出 logger.Out = src //设置日志级别 logger.SetLevel(logrus.DebugLevel) //设置日志格式 logger.SetFormatter(&amp;logrus.TextFormatter&#123;&#125;) return func(c *gin.Context) &#123; // 开始时间 startTime := time.Now() // 处理请求 c.Next() // 结束时间 endTime := time.Now() // 执行时间 latencyTime := endTime.Sub(startTime) // 请求方式 reqMethod := c.Request.Method // 请求路由 reqUri := c.Request.RequestURI // 状态码 statusCode := c.Writer.Status() // 请求IP clientIP := c.ClientIP() // 日志格式 logger.Infof(&quot;| %3d | %13v | %15s | %s | %s |&quot;, statusCode, latencyTime, clientIP, reqMethod, reqUri, ) &#125;&#125;// 日志记录到 MongoDBfunc LoggerToMongo() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125;// 日志记录到 ESfunc LoggerToES() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125;// 日志记录到 MQfunc LoggerToMQ() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125; 日志中间件写好了，怎么调用呢？ 只需在 main.go 中新增： 12engine := gin.Default() //在这行后新增engine.Use(middleware.LoggerToFile()) 运行一下，看看日志： 12time=&quot;2019-07-17T22:10:45+08:00&quot; level=info msg=&quot;| 200 | 27.698µs | ::1 | GET | /v1/product/add?name=a&amp;price=10 |&quot;time=&quot;2019-07-17T22:10:46+08:00&quot; level=info msg=&quot;| 200 | 27.239µs | ::1 | GET | /v1/product/add?name=a&amp;price=10 |&quot; 这个 time=&quot;2019-07-17T22:10:45+08:00&quot; ，这个时间格式不是咱们想要的，怎么办？ 时间需要格式化一下，修改 logger.SetFormatter 1234//设置日志格式logger.SetFormatter(&amp;logrus.TextFormatter&#123; TimestampFormat:&quot;2006-01-02 15:04:05&quot;,&#125;) 执行以下，再看日志： 12time=&quot;2019-07-17 22:15:57&quot; level=info msg=&quot;| 200 | 185.027µs | ::1 | GET | /v1/product/add?name=a&amp;price=10 |&quot;time=&quot;2019-07-17 22:15:58&quot; level=info msg=&quot;| 200 | 56.989µs | ::1 | GET | /v1/product/add?name=a&amp;price=10 |&quot; 时间变得正常了。 我不喜欢文本格式，喜欢 JSON 格式，怎么办？ 1234//设置日志格式logger.SetFormatter(&amp;logrus.JSONFormatter&#123; TimestampFormat:&quot;2006-01-02 15:04:05&quot;,&#125;) 执行以下，再看日志： 12&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;| 200 | 24.78µs | ::1 | GET | /v1/product/add?name=a\\u0026price=10 |&quot;,&quot;time&quot;:&quot;2019-07-17 22:23:55&quot;&#125;&#123;&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;| 200 | 26.946µs | ::1 | GET | /v1/product/add?name=a\\u0026price=10 |&quot;,&quot;time&quot;:&quot;2019-07-17 22:23:56&quot;&#125; msg 信息太多，不方便看，怎么办？ 12345678// 日志格式logger.WithFields(logrus.Fields&#123; &quot;status_code&quot; : statusCode, &quot;latency_time&quot; : latencyTime, &quot;client_ip&quot; : clientIP, &quot;req_method&quot; : reqMethod, &quot;req_uri&quot; : reqUri,&#125;).Info() 执行以下，再看日志： 12&#123;&quot;client_ip&quot;:&quot;::1&quot;,&quot;latency_time&quot;:26681,&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;&quot;,&quot;req_method&quot;:&quot;GET&quot;,&quot;req_uri&quot;:&quot;/v1/product/add?name=a\\u0026price=10&quot;,&quot;status_code&quot;:200,&quot;time&quot;:&quot;2019-07-17 22:37:54&quot;&#125;&#123;&quot;client_ip&quot;:&quot;::1&quot;,&quot;latency_time&quot;:24315,&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;&quot;,&quot;req_method&quot;:&quot;GET&quot;,&quot;req_uri&quot;:&quot;/v1/product/add?name=a\\u0026price=10&quot;,&quot;status_code&quot;:200,&quot;time&quot;:&quot;2019-07-17 22:37:55&quot;&#125; 说明一下：time、msg、level 这些参数是 logrus 自动加上的。 logrus 支持输出文件名和行号吗？ 不支持，作者的回复是太耗性能。 不过网上也有人通过 Hook 的方式实现了，选择在生产环境使用的时候，记得做性能测试。 logrus 支持日志分割吗？ 不支持，但有办法实现它。 1、可以利用 Linux logrotate，统一由运维进行处理。 2、可以利用 file-rotatelogs 实现。 需要导入包： github.com/lestrrat-go/file-rotatelogs github.com/rifflock/lfshook 奉上完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package middlewareimport ( &quot;fmt&quot; &quot;ginDemo/config&quot; &quot;github.com/gin-gonic/gin&quot; rotatelogs &quot;github.com/lestrrat-go/file-rotatelogs&quot; &quot;github.com/rifflock/lfshook&quot; &quot;github.com/sirupsen/logrus&quot; &quot;os&quot; &quot;path&quot; &quot;time&quot;)// 日志记录到文件func LoggerToFile() gin.HandlerFunc &#123; logFilePath := config.Log_FILE_PATH logFileName := config.LOG_FILE_NAME // 日志文件 fileName := path.Join(logFilePath, logFileName) // 写入文件 src, err := os.OpenFile(fileName, os.O_APPEND|os.O_WRONLY, os.ModeAppend) if err != nil &#123; fmt.Println(&quot;err&quot;, err) &#125; // 实例化 logger := logrus.New() // 设置输出 logger.Out = src // 设置日志级别 logger.SetLevel(logrus.DebugLevel) // 设置 rotatelogs logWriter, err := rotatelogs.New( // 分割后的文件名称 fileName + &quot;.%Y%m%d.log&quot;, // 生成软链，指向最新日志文件 rotatelogs.WithLinkName(fileName), // 设置最大保存时间(7天) rotatelogs.WithMaxAge(7*24*time.Hour), // 设置日志切割时间间隔(1天) rotatelogs.WithRotationTime(24*time.Hour), ) writeMap := lfshook.WriterMap&#123; logrus.InfoLevel: logWriter, logrus.FatalLevel: logWriter, logrus.DebugLevel: logWriter, logrus.WarnLevel: logWriter, logrus.ErrorLevel: logWriter, logrus.PanicLevel: logWriter, &#125; lfHook := lfshook.NewHook(writeMap, &amp;logrus.JSONFormatter&#123; TimestampFormat:&quot;2006-01-02 15:04:05&quot;, &#125;) // 新增 Hook logger.AddHook(lfHook) return func(c *gin.Context) &#123; // 开始时间 startTime := time.Now() // 处理请求 c.Next() // 结束时间 endTime := time.Now() // 执行时间 latencyTime := endTime.Sub(startTime) // 请求方式 reqMethod := c.Request.Method // 请求路由 reqUri := c.Request.RequestURI // 状态码 statusCode := c.Writer.Status() // 请求IP clientIP := c.ClientIP() // 日志格式 logger.WithFields(logrus.Fields&#123; &quot;status_code&quot; : statusCode, &quot;latency_time&quot; : latencyTime, &quot;client_ip&quot; : clientIP, &quot;req_method&quot; : reqMethod, &quot;req_uri&quot; : reqUri, &#125;).Info() &#125;&#125;// 日志记录到 MongoDBfunc LoggerToMongo() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125;// 日志记录到 ESfunc LoggerToES() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125;// 日志记录到 MQfunc LoggerToMQ() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; &#125;&#125; 这时会新生成一个文件 system.log.20190717.log，日志内容与上面的格式一致。 最后，logrus 可扩展的 Hook 很多，大家可以去网上查找。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"路由配置","slug":"gin-router","date":"2018-12-20T12:22:50.000Z","updated":"2022-05-11T09:47:11.000Z","comments":true,"path":"2018/12/20/gin-router/","link":"","permalink":"https://timmy6.github.io/2018/12/20/gin-router/","excerpt":"","text":"概述这篇文章分享 Gin 的路由配置，主要包含的功能点如下： 实现了，路由分组 v1版本、v2版本。 实现了，生成签名和验证验证。 实现了，在配置文件中读取配置。 路由配置比如我们的接口地址是这样的： /v1/product/add /v1/member/add /v2/product/add /v2/member/add 假设需求是这样的，接口支持多种请求方式，v1 不需签名验证，v2 需要签名验证，路由文件应该这样写： 123456789101112131415161718192021222324252627282930313233343536373839404142package routerimport ( &quot;ginDemo/common&quot; &quot;ginDemo/controller/v1&quot; &quot;ginDemo/controller/v2&quot; &quot;github.com/gin-gonic/gin&quot; &quot;net/url&quot; &quot;strconv&quot;)func InitRouter(r *gin.Engine) &#123; r.GET(&quot;/sn&quot;, SignDemo) // v1 版本 GroupV1 := r.Group(&quot;/v1&quot;) &#123; GroupV1.Any(&quot;/product/add&quot;, v1.AddProduct) GroupV1.Any(&quot;/member/add&quot;, v1.AddMember) &#125; // v2 版本 GroupV2 := r.Group(&quot;/v2&quot;, common.VerifySign) &#123; GroupV2.Any(&quot;/product/add&quot;, v2.AddProduct) GroupV2.Any(&quot;/member/add&quot;, v2.AddMember) &#125;&#125;func SignDemo(c *gin.Context) &#123; ts := strconv.FormatInt(common.GetTimeUnix(), 10) res := map[string]interface&#123;&#125;&#123;&#125; params := url.Values&#123; &quot;name&quot; : []string&#123;&quot;a&quot;&#125;, &quot;price&quot; : []string&#123;&quot;10&quot;&#125;, &quot;ts&quot; : []string&#123;ts&#125;, &#125; res[&quot;sn&quot;] = common.CreateSign(params) res[&quot;ts&quot;] = ts common.RetJson(&quot;200&quot;, &quot;&quot;, res, c)&#125; .Any 表示支持多种请求方式。 controller/v1 表示 v1 版本的文件。 controller/v2 表示 v2 版本的文件。 SignDemo 表示生成签名的Demo。 接下来，给出一些代码片段： 验证签名方法： 1234567891011121314151617181920212223242526272829303132333435// 验证签名func VerifySign(c *gin.Context) &#123; var method = c.Request.Method var ts int64 var sn string var req url.Values if method == &quot;GET&quot; &#123; req = c.Request.URL.Query() sn = c.Query(&quot;sn&quot;) ts, _ = strconv.ParseInt(c.Query(&quot;ts&quot;), 10, 64) &#125; else if method == &quot;POST&quot; &#123; req = c.Request.PostForm sn = c.PostForm(&quot;sn&quot;) ts, _ = strconv.ParseInt(c.PostForm(&quot;ts&quot;), 10, 64) &#125; else &#123; RetJson(&quot;500&quot;, &quot;Illegal requests&quot;, &quot;&quot;, c) return &#125; exp, _ := strconv.ParseInt(config.API_EXPIRY, 10, 64) // 验证过期时间 if ts &gt; GetTimeUnix() || GetTimeUnix() - ts &gt;= exp &#123; RetJson(&quot;500&quot;, &quot;Ts Error&quot;, &quot;&quot;, c) return &#125; // 验证签名 if sn == &quot;&quot; || sn != CreateSign(req) &#123; RetJson(&quot;500&quot;, &quot;Sn Error&quot;, &quot;&quot;, c) return &#125;&#125; 生成签名的方法： 123456789101112131415161718192021// 生成签名func CreateSign(params url.Values) string &#123; var key []string var str = &quot;&quot; for k := range params &#123; if k != &quot;sn&quot; &#123; key = append(key, k) &#125; &#125; sort.Strings(key) for i := 0; i &lt; len(key); i++ &#123; if i == 0 &#123; str = fmt.Sprintf(&quot;%v=%v&quot;, key[i], params.Get(key[i])) &#125; else &#123; str = str + fmt.Sprintf(&quot;&amp;%v=%v&quot;, key[i], params.Get(key[i])) &#125; &#125; // 自定义签名算法 sign := MD5(MD5(str) + MD5(config.APP_NAME + config.APP_SECRET)) return sign&#125; 获取参数的方法： 12345678910111213// 获取 Get 参数name := c.Query(&quot;name&quot;)price := c.DefaultQuery(&quot;price&quot;, &quot;100&quot;)// 获取 Post 参数name := c.PostForm(&quot;name&quot;)price := c.DefaultPostForm(&quot;price&quot;, &quot;100&quot;)// 获取 Get 所有参数ReqGet = c.Request.URL.Query()//获取 Post 所有参数ReqPost = c.Request.PostForm v1 业务代码： 123456789101112131415package v1import &quot;github.com/gin-gonic/gin&quot;func AddProduct(c *gin.Context) &#123; // 获取 Get 参数 name := c.Query(&quot;name&quot;) price := c.DefaultQuery(&quot;price&quot;, &quot;100&quot;) c.JSON(200, gin.H&#123; &quot;v1&quot; : &quot;AddProduct&quot;, &quot;name&quot; : name, &quot;price&quot; : price, &#125;)&#125; v2 业务代码： 123456789101112131415161718package v2import ( &quot;github.com/gin-gonic/gin&quot;)func AddProduct(c *gin.Context) &#123; // 获取 Get 参数 name := c.Query(&quot;name&quot;) price := c.DefaultQuery(&quot;price&quot;, &quot;100&quot;) c.JSON(200, gin.H&#123; &quot;v1&quot; : &quot;AddProduct&quot;, &quot;name&quot; : name, &quot;price&quot; : price, &#125;)&#125; 接下来，直接看效果吧。 访问 v1 接口： 访问后，直接返回数据，不走签名验证。 访问 v2 接口： 进入了这段验证： 12345// 验证过期时间if ts &gt; GetTimeUnix() || GetTimeUnix() - ts &gt;= exp &#123; RetJson(&quot;500&quot;, &quot;Ts Error&quot;, &quot;&quot;, c) return&#125; 修改为合法的时间戳后： 进入了这段验证： 12345// 验证签名if sn == &quot;&quot; || sn != CreateSign(req) &#123; RetJson(&quot;500&quot;, &quot;Sn Error&quot;, &quot;&quot;, c) return&#125; 修改为合法的签名后： 至此，简单的路由配置已经实现了。 对了，还有一个点没说，就是如何读取配置文件中的配置，我是这样做的： 12345678package configconst ( PORT = &quot;:8080&quot; APP_NAME = &quot;ginDemo&quot; APP_SECRET = &quot;6YJSuc50uJ18zj45&quot; API_EXPIRY = &quot;120&quot;) 引入 config 包，直接 config.xx 即可。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"使用 sync.WaitGroup 来实现并发操作","slug":"sync-WaitGroup","date":"2018-12-15T12:22:50.000Z","updated":"2022-05-11T09:47:04.981Z","comments":true,"path":"2018/12/15/sync-WaitGroup/","link":"","permalink":"https://timmy6.github.io/2018/12/15/sync-WaitGroup/","excerpt":"","text":"前言如果你有一个任务可以分解成多个子任务进行处理，同时每个子任务没有先后执行顺序的限制，等到全部子任务执行完毕后，再进行下一步处理。这时每个子任务的执行可以并发处理，这种情景下适合使用 sync.WaitGroup。 虽然 sync.WaitGroup 使用起来比较简单，但是一不留神很有可能踩到坑里。 sync.WaitGroup 正确使用比如，有一个任务需要执行 3 个子任务，那么可以这样写： 12345678910111213141516171819202122232425262728func main() &#123; var wg sync.WaitGroup wg.Add(3) go handlerTask1(&amp;wg) go handlerTask2(&amp;wg) go handlerTask3(&amp;wg) wg.Wait() fmt.Println(&quot;全部任务执行完毕.&quot;)&#125;func handlerTask1(wg *sync.WaitGroup) &#123; defer wg.Done() fmt.Println(&quot;执行任务 1&quot;)&#125;func handlerTask2(wg *sync.WaitGroup) &#123; defer wg.Done() fmt.Println(&quot;执行任务 2&quot;)&#125;func handlerTask3(wg *sync.WaitGroup) &#123; defer wg.Done() fmt.Println(&quot;执行任务 3&quot;)&#125; 执行输出： 1234执行任务 3执行任务 1执行任务 2全部任务执行完毕. sync.WaitGroup 闭坑指南0112345// 正确go handlerTask1(&amp;wg)// 错误go handlerTask1(wg) 执行子任务时，使用的 sync.WaitGroup 一定要是 wg 的引用类型！ 02注意不要将 wg.Add() 放在 go handlerTask1(&amp;wg) 中！ 例如： 1234567891011121314// 错误var wg sync.WaitGroupgo handlerTask1(&amp;wg)wg.Wait()...func handlerTask1(wg *sync.WaitGroup) &#123; wg.Add(1) defer wg.Done() fmt.Println(&quot;执行任务 1&quot;)&#125; 注意 wg.Add() 一定要在 wg.Wait() 执行前执行！ 03注意 wg.Add() 和 wg.Done() 的计数器保持一致！其实 wg.Done() 就是执行的 wg.Add(-1) 。 小结sync.WaitGroup 使用起来比较简单，一定要注意不要踩到坑里。 其实 sync.WaitGroup 使用场景比较局限，仅适用于等待全部子任务执行完毕后，再进行下一步处理，如果需求是当第一个子任务执行失败时，通知其他子任务停止运行，这时 sync.WaitGroup 是无法满足的，需要使用到通知机制（channel）。 以上，希望对你能够有所帮助。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"使用sync.Map来解决map的并发操作问题","slug":"sync-map","date":"2018-12-12T12:22:50.000Z","updated":"2022-05-11T09:46:56.245Z","comments":true,"path":"2018/12/12/sync-map/","link":"","permalink":"https://timmy6.github.io/2018/12/12/sync-map/","excerpt":"","text":"前言在 Golang 中 map 不是并发安全的，自 1.9 才引入了 sync.Map ，sync.Map 的引入确实解决了 map 的并发安全问题，不过 sync.Map 却没有实现 len() 函数，如果想要计算 sync.Map 的长度，稍微有点麻烦，需要使用 Range 函数。 map 并发操作出现问题1234567891011121314151617func main() &#123; demo := make(map[int]int) go func() &#123; for j := 0; j &lt; 1000; j++ &#123; demo[j] = j &#125; &#125;() go func() &#123; for j := 0; j &lt; 1000; j++ &#123; fmt.Println(demo[j]) &#125; &#125;() time.Sleep(time.Second * 1)&#125; 执行输出： 1fatal error: concurrent map read and map write sync.Map 解决并发操作问题1234567891011121314151617func main() &#123; demo := sync.Map&#123;&#125; go func() &#123; for j := 0; j &lt; 1000; j++ &#123; demo.Store(j, j) &#125; &#125;() go func() &#123; for j := 0; j &lt; 1000; j++ &#123; fmt.Println(demo.Load(j)) &#125; &#125;() time.Sleep(time.Second * 1)&#125; 执行输出： 123456&lt;nil&gt; false1 true...999 true 计算 map 长度123456789func main() &#123; demo := make(map[int]int) for j := 0; j &lt; 1000; j++ &#123; demo[j] = j &#125; fmt.Println(&quot;len of demo:&quot;, len(demo))&#125; 执行输出： 1len of demo: 1000 计算 sync.Map 长度123456789101112131415func main() &#123; demo := sync.Map&#123;&#125; for j := 0; j &lt; 1000; j++ &#123; demo.Store(j, j) &#125; lens := 0 demo.Range(func(key, value interface&#123;&#125;) bool &#123; lens++ return true &#125;) fmt.Println(&quot;len of demo:&quot;, lens)&#125; 执行输出： 1len of demo: 1000 小结 Load 加载 key 数据 Store 更新或新增 key 数据 Delete 删除 key 数据 Range 遍历数据 LoadOrStore 如果存在 key 数据则返回，反之则设置 LoadAndDelete 如果存在 key 数据则删除 以上，希望对你能够有所帮助。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"基于逃逸分析来提升程序性能","slug":"escape","date":"2018-12-10T11:17:50.000Z","updated":"2022-05-11T09:46:49.518Z","comments":true,"path":"2018/12/10/escape/","link":"","permalink":"https://timmy6.github.io/2018/12/10/escape/","excerpt":"","text":"前言为什么需要了解逃逸分析？ 因为我们想要提升程序性能，通过逃逸分析我们能够知道变量是分配到堆上还是栈上，如果分配到栈上，内存的分配和释放都是由编译器进行管理，分配和释放的速度非常快，如果分配到堆上，堆不像栈那样可以自动清理，它会引起频繁地进行垃圾回收（GC），而垃圾回收会占用比较大的系统开销。 什么是逃逸分析？ 在编译程序优化理论中，逃逸分析是一种确定指针动态范围的方法，简单来说就是分析在程序的哪些地方可以访问到该指针。 简单的说，它是在对变量放到堆上还是栈上进行分析，该分析在编译阶段完成。如果一个变量超过了函数调用的生命周期，也就是这个变量在函数外部存在引用，编译器会把这个变量分配到堆上，这时我们就说这个变量发生逃逸了。 如何确定是否逃逸？1go run -gcflags &#x27;-m -l&#x27; main.go 可能出现逃逸的场景011234567891011package maintype Student struct &#123; Name interface&#123;&#125;&#125;func main() &#123; stu := new(Student) stu.Name = &quot;tom&quot;&#125; 分析结果： 1234go run -gcflags &#x27;-m -l&#x27; 01.go# command-line-arguments./01.go:8:12: new(Student) does not escape./01.go:9:11: &quot;tom&quot; escapes to heap interface&#123;&#125; 赋值，会发生逃逸，优化方案是将类型设置为固定类型，例如：string 1234567891011package maintype Student struct &#123; Name string&#125;func main() &#123; stu := new(Student) stu.Name = &quot;tom&quot;&#125; 分析结果： 123go run -gcflags &#x27;-m -l&#x27; 01.go# command-line-arguments./01.go:8:12: new(Student) does not escape 0212345678910111213141516package maintype Student struct &#123; Name string&#125;func GetStudent() *Student &#123; stu := new(Student) stu.Name = &quot;tom&quot; return stu&#125;func main() &#123; GetStudent()&#125; 分析结果： 123go run -gcflags &#x27;-m -l&#x27; 02.go# command-line-arguments./02.go:8:12: new(Student) escapes to heap 返回指针类型，会发生逃逸，优化方案视情况而定。 函数传递指针和传值哪个效率高吗？我们知道传递指针可以减少底层值的拷贝，可以提高效率，但是如果拷贝的数据量小，由于指针传递会产生逃逸，可能会使用堆，也可能会增加 GC 的负担，所以传递指针不一定是高效的。 不要盲目使用变量指针作为参数，虽然减少了复制，但变量逃逸的开销可能更大。 03123456789package mainfunc main() &#123; nums := make([]int, 10000, 10000) for i := range nums &#123; nums[i] = i &#125;&#125; 分析结果： 123go run -gcflags &#x27;-m -l&#x27; 03.go# command-line-arguments./03.go:4:14: make([]int, 10000, 10000) escapes to heap 栈空间不足，会发生逃逸，优化方案尽量设置容量，如果容量实在过大那就没办法了。 小结 逃逸分析是编译器在静态编译时完成的。 逃逸分析后可以确定哪些变量可以分配在栈上，栈的性能好。 以上，希望对你能够有所帮助。 推荐阅读 Go - 使用 sync.Pool 来减少 GC 压力 Go - 使用 options 设计模式 Go - json.Unmarshal 遇到的小坑 Go - 两个在开发中需注意的小点 Go - time.RFC3339 时间格式化","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"不要使用 + 和 fmt.Sprintf 操作字符串","slug":"string-append","date":"2018-12-05T10:17:50.000Z","updated":"2022-05-11T09:46:44.447Z","comments":true,"path":"2018/12/05/string-append/","link":"","permalink":"https://timmy6.github.io/2018/12/05/string-append/","excerpt":"","text":"不要使用 + 和 fmt.Sprintf 操作字符串不要使用 + 和 fmt.Sprintf 操作字符串，虽然很方便，但是真的很慢！ 我们要使用 bytes.NewBufferString 进行处理。 基准测试如下： +123456789101112131415161718func BenchmarkStringOperation1(b *testing.B) &#123; b.ResetTimer() str := &quot;&quot; for i := 0; i &lt; b.N; i++ &#123; str += &quot;golang&quot; &#125;&#125;// 输出goos: darwingoarch: amd64pkg: demo/stringoperationcpu: Intel(R) Core(TM) i7-8700B CPU @ 3.20GHzBenchmarkStringOperation1BenchmarkStringOperation1-12 353318 114135 ns/opPASSProcess finished with the exit code 0 fmt.Sprintf123456789101112131415161718func BenchmarkStringOperation2(b *testing.B) &#123; b.ResetTimer() str := &quot;&quot; for i := 0; i &lt; b.N; i++ &#123; str = fmt.Sprintf(&quot;%s%s&quot;, str, &quot;golang&quot;) &#125;&#125;// 输出goos: darwingoarch: amd64pkg: demo/stringoperationcpu: Intel(R) Core(TM) i7-8700B CPU @ 3.20GHzBenchmarkStringOperation2BenchmarkStringOperation2-12 280140 214098 ns/opPASSProcess finished with the exit code 0 bytes.NewBufferString123456789101112131415161718func BenchmarkStringOperation3(b *testing.B) &#123; b.ResetTimer() strBuf := bytes.NewBufferString(&quot;&quot;) for i := 0; i &lt; b.N; i++ &#123; strBuf.WriteString(&quot;golang&quot;) &#125;&#125;// 输出goos: darwingoarch: amd64pkg: demo/stringoperationcpu: Intel(R) Core(TM) i7-8700B CPU @ 3.20GHzBenchmarkStringOperation3BenchmarkStringOperation3-12 161292136 8.582 ns/opPASSProcess finished with the exit code 0 对于固定字段的键值对，不要使用 map[string]interface{}对于固定字段的键值对，不要使用 map[string]interface&#123;&#125;! 我们要使用临时 Struct。 基准测试如下： map[string]interface{}12345678910111213141516171819func BenchmarkStructOperation1(b *testing.B) &#123; b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; var demo = map[string]interface&#123;&#125;&#123;&#125; demo[&quot;Name&quot;] = &quot;Tom&quot; demo[&quot;Age&quot;] = 30 &#125;&#125;// 输出goos: darwingoarch: amd64pkg: demo/structoperationcpu: Intel(R) Core(TM) i7-8700B CPU @ 3.20GHzBenchmarkStructOperation1BenchmarkStructOperation1-12 43300134 27.97 ns/opPASSProcess finished with the exit code 0 临时 Struct12345678910111213141516171819202122func BenchmarkStructOperation2(b *testing.B) &#123; b.ResetTimer() for i := 0; i &lt; b.N; i++ &#123; var demo struct &#123; Name string Age int &#125; demo.Name = &quot;Tom&quot; demo.Age = 30 &#125;&#125;// 输出oos: darwingoarch: amd64pkg: demo/structoperationcpu: Intel(R) Core(TM) i7-8700B CPU @ 3.20GHzBenchmarkStructOperation2BenchmarkStructOperation2-12 1000000000 0.2388 ns/opPASSProcess finished with the exit code 0 小结你有类似这样的注意点吗，欢迎留言~ 下面推荐阅读的这几篇文章也是关于开发中需要知道的小技术点，更多技术细节和代码讨论，可以加入到我的星球。 推荐阅读 函数的不定参数你是这样用吗？ 优雅地处理错误真是一门学问啊！ 如何设计 API 接口，实现统一格式返回？","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"json.Unmarshal遇到的小坑","slug":"json-unmarshal","date":"2018-11-25T10:17:50.000Z","updated":"2022-05-11T09:46:39.159Z","comments":true,"path":"2018/11/25/json-unmarshal/","link":"","permalink":"https://timmy6.github.io/2018/11/25/json-unmarshal/","excerpt":"","text":"1.问题现象描述使用 json.Unmarshal()，反序列化时，出现了科学计数法，参考代码如下： 12345678910jsonStr := `&#123;&quot;number&quot;:1234567&#125;`result := make(map[string]interface&#123;&#125;)err := json.Unmarshal([]byte(jsonStr), &amp;result)if err != nil &#123; fmt.Println(err)&#125;fmt.Println(result)// 输出// map[number:1.234567e+06] 这个问题不是必现，只有当数字的位数大于 6 位时，才会变成了科学计数法。 2.问题影响描述当数据结构未知，使用 map[string]interface&#123;&#125; 来接收反序列化结果时，如果数字的位数大于 6 位，都会变成科学计数法，用到的地方都会受到影响。 3.引起问题的原因从 encoding/json 可以找到答案，看一下这段注释： 123456789// To unmarshal JSON into an interface value,// Unmarshal stores one of these in the interface value://// bool, for JSON booleans// float64, for JSON numbers// string, for JSON strings// []interface&#123;&#125;, for JSON arrays// map[string]interface&#123;&#125;, for JSON objects// nil for JSON null 是因为当 JSON 中存在一个比较大的数字时，它会被解析成 float64 类型，就有可能会出现科学计数法的形式。 4.问题的解决方案方案一 强制类型转换，参考代码如下： 12345678910jsonStr := `&#123;&quot;number&quot;:1234567&#125;`result := make(map[string]interface&#123;&#125;)err := json.Unmarshal([]byte(jsonStr), &amp;result)if err != nil &#123; fmt.Println(err)&#125;fmt.Println(int(result[&quot;number&quot;].(float64)))// 输出// 1234567 方案二 尽量避免使用 interface，对 json 字符串结构定义结构体，快捷方法可使用在线工具：https://mholt.github.io/json-to-go/。 1234567891011121314type Num struct &#123; Number int `json:&quot;number&quot;`&#125;jsonStr := `&#123;&quot;number&quot;:1234567&#125;`var result Numerr := json.Unmarshal([]byte(jsonStr), &amp;result)if err != nil &#123; fmt.Println(err)&#125;fmt.Println(result)// 输出// &#123;1234567&#125; 方案三 使用 UseNumber() 方法。 123456789101112jsonStr := `&#123;&quot;number&quot;:1234567&#125;`result := make(map[string]interface&#123;&#125;)d := json.NewDecoder(bytes.NewReader([]byte(jsonStr)))d.UseNumber()err := d.Decode(&amp;result)if err != nil &#123; fmt.Println(err)&#125;fmt.Println(result)// 输出// map[number:1234567] 这时一定要注意 result[&quot;number&quot;] 的数据类型！ 1234fmt.Println(fmt.Sprintf(&quot;type: %v&quot;, reflect.TypeOf(result[&quot;number&quot;])))// 输出// type: json.Number 通过代码可以看出 json.Number 其实就是字符串类型： 12// A Number represents a JSON number literal.type Number string 如果转换其他类型，参考如下代码： 12345678910111213// 转成 int64numInt, _ := result[&quot;number&quot;].(json.Number).Int64()fmt.Println(fmt.Sprintf(&quot;value: %v, type: %v&quot;, numInt, reflect.TypeOf(numInt)))// 输出// value: 1234567, type: int64// 转成 stringnumStr := result[&quot;number&quot;].(json.Number).String()fmt.Println(fmt.Sprintf(&quot;value: %v, type: %v&quot;, numStr, reflect.TypeOf(numStr)))// 输出// value: 1234567, type: string","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"defer 函数","slug":"defer","date":"2018-11-15T11:17:50.000Z","updated":"2022-05-11T09:46:33.357Z","comments":true,"path":"2018/11/15/defer/","link":"","permalink":"https://timmy6.github.io/2018/11/15/defer/","excerpt":"","text":"概述defer 函数大家肯定都用过，它在声明时不会立刻去执行，而是在函数 return 后去执行的。 它的主要应用场景有异常处理、记录日志、清理数据、释放资源 等等。 这篇文章不是分享 defer 的应用场景，而是分享使用 defer 需要注意的点。 咱们先从一道题开始，一起来感受下 … 1234567891011121314func calc(index string, a, b int) int &#123; ret := a + b fmt.Println(index, a, b, ret) return ret&#125;func main() &#123; x := 1 y := 2 defer calc(&quot;A&quot;, x, calc(&quot;B&quot;, x, y)) x = 3 defer calc(&quot;C&quot;, x, calc(&quot;D&quot;, x, y)) y = 4&#125; 输出什么？ … 接下来，先容我分享几个小例子，再进行作答。 执行顺序12345678func main() &#123; defer fmt.Println(&quot;1&quot;) defer fmt.Println(&quot;2&quot;) defer fmt.Println(&quot;3&quot;) fmt.Println(&quot;main&quot;)&#125; 输出： 1234main321 结论：defer 函数定义的顺序 与 实际执的行顺序是相反的，也就是最先声明的最后才执行。 闭包1234567891011func main() &#123; var a = 1 var b = 2 defer fmt.Println(a + b) a = 2 fmt.Println(&quot;main&quot;)&#125; 输出： 12main3 稍微修改一下，再看看： 123456789101112func main() &#123; var a = 1 var b = 2 defer func() &#123; fmt.Println(a + b) &#125;() a = 2 fmt.Println(&quot;main&quot;)&#125; 输出： 12main4 结论：闭包获取变量相当于引用传递，而非值传递。 稍微再修改一下，再看看： 123456789101112func main() &#123; var a = 1 var b = 2 defer func(a int, b int) &#123; fmt.Println(a + b) &#125;(a, b) a = 2 fmt.Println(&quot;main&quot;)&#125; 输出： 12main3 结论：传参是值复制。 还可以理解为：defer 调用的函数，参数的值在 defer 定义时就确定了，看下代码 defer fmt.Println(a + b)，在这时，参数的值已经确定了。 而 defer 函数内部所使用的变量的值需要在这个函数运行时才确定，看下代码 defer func() &#123; fmt.Println(a + b) &#125;()，a 和 b 的值在函数运行时，才能确定。 Return一1234567func t1() int &#123; a := 1 defer func() &#123; a++ &#125;() return a&#125; 输出：1 二123456func t2() (a int) &#123; defer func() &#123; a++ &#125;() return 1&#125; 输出：2 三1234567func t3() (b int) &#123; a := 1 defer func() &#123; a++ &#125;() return 1&#125; 输出：1 四123456func t4() (a int) &#123; defer func(a int) &#123; a++ &#125;(a) return 1&#125; 输出：1 结论：return 不是原子操作。 os.Exit12345func main() &#123; defer fmt.Println(&quot;1&quot;) fmt.Println(&quot;main&quot;) os.Exit(0)&#125; 输出：main 结论：当os.Exit()方法退出程序时，defer不会被执行。 不同协程12345678910111213141516171819func main() &#123; GoA() time.Sleep(1 * time.Second) fmt.Println(&quot;main&quot;)&#125;func GoA() &#123; defer (func()&#123; if err := recover(); err != nil &#123; fmt.Println(&quot;panic:&quot; + fmt.Sprintf(&quot;%s&quot;, err)) &#125; &#125;)() go GoB()&#125;func GoB() &#123; panic(&quot;error&quot;)&#125; GoB() panic 捕获不到。 结论：defer 只对当前协程有效。 这个问题怎么解？咱们下回再说。 接下来，咱们分析下文章开头的问题吧。 答案解析先列出答案： 1234B 1 2 3D 3 2 5C 3 5 8A 1 3 4 其实上面那道题，可以拆解为： 12345678910111213141516func calc(index string, a, b int) int &#123; ret := a + b fmt.Println(index, a, b, ret) return ret&#125;func main() &#123; x := 1 y := 2 tmp1 := calc(&quot;B&quot;, x, y) defer calc(&quot;A&quot;, x, tmp1) x = 3 tmp2 := calc(&quot;D&quot;, x, y) defer calc(&quot;C&quot;, x, tmp2) y = 4&#125; 所以顺序就是：B D C A。 执行到 tmp1 时，输出：B 1 2 3。 执行到 tmp2 时，输出：D 3 2 5。 根据 defer 执行顺序原则，先声明的后执行，所以下一个该执行 C 了。 又因为传参是值赋值，所以在 A 的时候，无法用到 x = 3 和 y = 4，在 C 的时候，无法用到 y = 4。 执行到 C 时，输出：C 3 5 8 执行到 A 时，输出：A 1 3 4 到这，基本上 defer 就清楚了，大家可以根据自己的理解去记忆。 go-gin-api 系列文章 7. 路由中间件 - 签名验证 6. 路由中间件 - Jaeger 链路追踪（实战篇） 5. 路由中间件 - Jaeger 链路追踪（理论篇） 4. 路由中间件 - 捕获异常 3. 路由中间件 - 日志记录 2. 规划项目目录和参数验证 1. 使用 go modules 初始化项目","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"chan通道","slug":"chan","date":"2018-11-05T11:17:50.000Z","updated":"2022-05-11T09:46:27.420Z","comments":true,"path":"2018/11/05/chan/","link":"","permalink":"https://timmy6.github.io/2018/11/05/chan/","excerpt":"","text":"概述chan 可以理解为队列，遵循先进先出的规则。 在说 chan 之前，咱们先说一下 go 关键字。 在 go 关键字后面加一个函数，就可以创建一个线程，函数可以为已经写好的函数，也可以是匿名函数。 举个例子： 123456789func main() &#123; fmt.Println(&quot;main start&quot;) go func() &#123; fmt.Println(&quot;goroutine&quot;) &#125;() fmt.Println(&quot;main end&quot;)&#125; 输出： 12main startmain end 为什么没有输出 goroutine ？ 首先，我们清楚 Go 语言的线程是并发机制，不是并行机制。 那么，什么是并发，什么是并行？ 并发是不同的代码块交替执行，也就是交替可以做不同的事情。 并行是不同的代码块同时执行，也就是同时可以做不同的事情。 举个生活化场景的例子： 你正在家看书，忽然电话来了，然后你接电话，通话完成后继续看书，这就是并发，看书和接电话交替做。 如果电话来了，你一边看书一遍接电话，这就是并行，看书和接电话一起做。 说回上面的例子，为什么没有输出 goroutine ？ main 函数是一个主线程，是因为主线程执行太快了，子线程还没来得及执行，所以看不到输出。 现在让主线程休眠 1 秒钟，再试试。 1234567891011func main() &#123; fmt.Println(&quot;main start&quot;) go func() &#123; fmt.Println(&quot;goroutine&quot;) &#125;() time.Sleep(1 * time.Second) fmt.Println(&quot;main end&quot;)&#125; 输出： 123main startgoroutinemain end 这就对了。 接下来，看看如何使用 chan 。 声明 chan1234567891011// 声明不带缓冲的通道ch1 := make(chan string)// 声明带10个缓冲的通道ch2 := make(chan string, 10)// 声明只读通道ch3 := make(&lt;-chan string)// 声明只写通道ch4 := make(chan&lt;- string) 注意： 不带缓冲的通道，进和出都会阻塞。 带缓冲的通道，进一次长度 +1，出一次长度 -1，如果长度等于缓冲长度时，再进就会阻塞。 写入 chan123ch1 := make(chan string, 10)ch1 &lt;- &quot;a&quot; 读取 chan123val, ok := &lt;- ch1// 或val := &lt;- ch1 关闭 chan1close(chan) 注意： close 以后不能再写入，写入会出现 panic 重复 close 会出现 panic 只读的 chan 不能 close close 以后还可以读取数据 示例12345678910func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string) ch &lt;- &quot;a&quot; // 入 chan go func() &#123; val := &lt;- ch // 出 chan fmt.Println(val) &#125;() fmt.Println(&quot;main end&quot;)&#125; 输出： 12main startfatal error: all goroutines are asleep - deadlock! What ? 这是为啥，刚开始就出师不利呀？ 因为，定义的是一个无缓冲的 chan，赋值后就陷入了阻塞。 怎么解决它？ 声明一个有缓冲的 chan。 12345678910func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string, 1) ch &lt;- &quot;a&quot; // 入 chan go func() &#123; val := &lt;- ch // 出 chan fmt.Println(val) &#125;() fmt.Println(&quot;main end&quot;)&#125; 输出： 12main startmain end 为啥没有输出 a , 和前面一样，主线程执行太快了，加个休眠 1 秒钟，再试试。 1234567891011func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string, 1) ch &lt;- &quot;a&quot; // 入 chan go func() &#123; val := &lt;- ch // 出 chan fmt.Println(val) &#125;() time.Sleep(1 * time.Second) fmt.Println(&quot;main end&quot;)&#125; 输出： 123main startamain end 这就对了。 再看一个例子： 12345678910111213func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string) go func() &#123; ch &lt;- &quot;a&quot; // 入 chan &#125;() go func() &#123; val := &lt;- ch // 出 chan fmt.Println(val) &#125;() time.Sleep(1 * time.Second) fmt.Println(&quot;main end&quot;)&#125; 输出： 123main startamain end 再看一个例子： 1234567891011121314151617func producer(ch chan string) &#123; fmt.Println(&quot;producer start&quot;) ch &lt;- &quot;a&quot; ch &lt;- &quot;b&quot; ch &lt;- &quot;c&quot; ch &lt;- &quot;d&quot; fmt.Println(&quot;producer end&quot;)&#125;func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string, 3) go producer(ch) time.Sleep(1 * time.Second) fmt.Println(&quot;main end&quot;)&#125; 输出： 123main startproducer startmain end 带缓冲的通道，如果长度等于缓冲长度时，再进就会阻塞。 再看一个例子： 12345678910111213141516171819202122232425func producer(ch chan string) &#123; fmt.Println(&quot;producer start&quot;) ch &lt;- &quot;a&quot; ch &lt;- &quot;b&quot; ch &lt;- &quot;c&quot; ch &lt;- &quot;d&quot; fmt.Println(&quot;producer end&quot;)&#125;func customer(ch chan string) &#123; for &#123; msg := &lt;- ch fmt.Println(msg) &#125;&#125;func main() &#123; fmt.Println(&quot;main start&quot;) ch := make(chan string, 3) go producer(ch) go customer(ch) time.Sleep(1 * time.Second) fmt.Println(&quot;main end&quot;)&#125; 输出： 12345678main startproducer startproducer endabcdmain end 就到这吧。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"老项目迁移 go module 大型灾难记录","slug":"gomod","date":"2018-10-26T08:17:50.000Z","updated":"2022-05-11T09:46:21.557Z","comments":true,"path":"2018/10/26/gomod/","link":"","permalink":"https://timmy6.github.io/2018/10/26/gomod/","excerpt":"最近在改造一个比较早期的一个项目，其中就涉及到用将原来 Vendor 管理依赖换成 Go Modules 来管理。 然而过程真是一波三折，在这里总结一下此次 Go Modules 改造中遇到的问题，以及解决方法。","text":"最近在改造一个比较早期的一个项目，其中就涉及到用将原来 Vendor 管理依赖换成 Go Modules 来管理。 然而过程真是一波三折，在这里总结一下此次 Go Modules 改造中遇到的问题，以及解决方法。 背景 go version： 12$ go versiongo version go1.16.5 darwin/amd64 简化的 demo 如下, 很 “简单” 我们只要把 hello world 输出即可。 123456789101112131415161718192021222324252627package mainimport ( &quot;github.com/coreos/etcd/pkg/transport&quot; &quot;github.com/google/certificate-transparency-go/tls&quot; &quot;github.com/qiniu/api.v7/auth/qbox&quot; &quot;go.etcd.io/etcd/clientv3&quot; &quot;google.golang.org/grpc&quot; &quot;qiniupkg.com/x/log.v7&quot;)func main() &#123; _ = transport.TLSInfo&#123;&#125; _ = clientv3.WatchResponse&#123;&#125; _, _ = clientv3.New(clientv3.Config&#123;&#125;) _ = qbox.NewMac(&quot;&quot;, &quot;&quot;) _ = tls.DigitallySigned&#123;&#125; _ = grpc.ClientConn&#123;&#125; log.Info(&quot;hello world&quot;)&#125; 实战直接初始化，并 tidy 一下。 123456789101112131415161718192021222324$ go mod init demo-go/gomodgo: creating new go.mod: module demo-go/gomodgo: to add module requirements and sums: go mod tidy $ go mod tidygo: finding module for ...demo-go/gomod imports qiniupkg.com/x/log.v7: module qiniupkg.com/x@latest found (v1.11.5), but does not contain package qiniupkg.com/x/log.v7demo-go/gomod imports github.com/qiniu/api.v7/auth/qbox imports github.com/qiniu/x/bytes.v7/seekable: module github.com/qiniu/x@latest found (v1.11.5), but does not contain package github.com/qiniu/x/bytes.v7/seekabledemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context: package github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context provided by github.com/coreos/etcd at latest version v2.3.8+incompatible but not at required version v3.3.10+incompatibledemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/Godeps/_workspace/src/google.golang.org/grpc: package github.com/coreos/etcd/Godeps/_workspace/src/google.golang.org/grpc provided by github.com/coreos/etcd at latest version v2.3.8+incompatible but not at required version v3.3.10+incompatibledemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/Godeps/_workspace/src/google.golang.org/grpc/credentials: package github.com/coreos/etcd/Godeps/_workspace/src/google.golang.org/grpc/credentials provided by github.com/coreos/etcd at latest version v2.3.8+incompatible but not at required version v3.3.10+incompatibledemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/storage/storagepb: package github.com/coreos/etcd/storage/storagepb provided by github.com/coreos/etcd at latest version v2.3.8+incompatible but not at required version v3.3.10+incompatible 好家伙，报错了。我们先看到前两行 qiniupkg.com/x@latest 中没有 qiniupkg.com/x/log.v7； github.com/qiniu/x@latest 中没有 github.com/qiniu/x/bytes.v7/seekable； 这看起来应该是一个问题， qiniupkg.com/x 和github.com/qiniu/x 应该是同一个包，不同镜像。于是我到 Github 看一下 @lastet 版本的代码，确实没有bytes.v7 包了。人肉查找，最后在 v1.7.8 版本，我们找到了 bytes.v7 包。 于是，我们可以指定一下版本。 12go mod edit -replace qiniupkg.com/x=qiniupkg.com/x@v1.7.8go mod edit -replace github.com/qiniu/x=github.com/qiniu/x@v1.7.8 继续往下看，接下来的几个问题是一类的，都是etcd导致的。 意思是 go.etcd.io/etcd/clientv3 导入了 github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context, 同时 github.com/coreos/etcd@v2.3.8 中 提供了 github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context 。 但是，我们这里需要 github.com/coreos/etcd@v3.3.10, 而该版本并不提供 github.com/coreos/etcd/Godeps/_workspace/src/golang.org/x/net/context 。 我们直接更新 etcd 到的 v3.3.10 试试。 1go mod edit -replace go.etcd.io/etcd=go.etcd.io/etcd@v3.3.20+incompatible 我们再 go mod tidy 下。 123456789$ go mod tidygo: demo-go/gomod imports go.etcd.io/etcd/clientv3 tested by go.etcd.io/etcd/clientv3.test imports github.com/coreos/etcd/auth imports github.com/coreos/etcd/mvcc/backend imports github.com/coreos/bbolt: github.com/coreos/bbolt@v1.3.6: parsing go.mod: module declares its path as: go.etcd.io/bbolt but was required as: github.com/coreos/bbolt 这个错误和鸟窝这篇 Etcd使用go module的灾难一致，go.etcd.io/bbolt 和 github.com/coreos/bbolt 包名不一致，我们替换一下。 1go mod edit -replace github.com/coreos/bbolt@v1.3.6=go.etcd.io/bbolt@v1.3.6 继续，go mod tidy 一下。 1234567891011121314151617181920$ go mod tidy...demo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/clientv3/balancer: module github.com/coreos/etcd@latest found (v2.3.8+incompatible), but does not contain package github.com/coreos/etcd/clientv3/balancerdemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/clientv3/balancer/picker: module github.com/coreos/etcd@latest found (v2.3.8+incompatible), but does not contain package github.com/coreos/etcd/clientv3/balancer/pickerdemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/clientv3/balancer/resolver/endpoint: module github.com/coreos/etcd@latest found (v2.3.8+incompatible), but does not contain package github.com/coreos/etcd/clientv3/balancer/resolver/endpointdemo-go/gomod imports go.etcd.io/etcd/clientv3 imports github.com/coreos/etcd/clientv3/credentials: module github.com/coreos/etcd@latest found (v2.3.8+incompatible), but does not contain package github.com/coreos/etcd/clientv3/credentialsdemo-go/gomod imports go.etcd.io/etcd/clientv3 tested by go.etcd.io/etcd/clientv3.test imports github.com/coreos/etcd/integration imports github.com/coreos/etcd/proxy/grpcproxy imports google.golang.org/grpc/naming: module google.golang.org/grpc@latest found (v1.39.0), but does not contain package google.golang.org/grpc/naming 好家伙，又是etcd。 仔细一看，我们导入了github.com/coreos/etcd 和 go.etcd.io/etcd 两个版本etcd, 我们前面只替换了一个。现在我们把另外一个也替换了。 1go mod edit -replace github.com/coreos/etcd=github.com/coreos/etcd@v3.3.20+incompatible 再go mod tidy下，这个错误没有了，但还有个grpc的错误，继续找原因。原来是 google.golang.org/grpc v1.39.0 版本没有 google.golang.org/grpc/naming 包。 上 Github 仓库， 找了一下历史版本，v1.29.1上是有这个包的，我们继续替换。 1go mod edit -replace google.golang.org/grpc=google.golang.org/grpc@v1.29.1 这下，终于，go mod tidy通过了，可以开心的输出hello world 了。 然而， 1234567$ go run main.go# github.com/coreos/etcd/clientv3/balancer/resolver/endpoint../../../go/pkg/mod/github.com/coreos/etcd@v3.3.20+incompatible/clientv3/balancer/resolver/endpoint/endpoint.go:114:78: undefined: resolver.BuildOption../../../go/pkg/mod/github.com/coreos/etcd@v3.3.20+incompatible/clientv3/balancer/resolver/endpoint/endpoint.go:182:31: undefined: resolver.ResolveNowOption# github.com/coreos/etcd/clientv3/balancer/picker../../../go/pkg/mod/github.com/coreos/etcd@v3.3.20+incompatible/clientv3/balancer/picker/err.go:37:44: undefined: balancer.PickOptions../../../go/pkg/mod/github.com/coreos/etcd@v3.3.20+incompatible/clientv3/balancer/picker/roundrobin_balanced.go:55:54: undefined: balancer.PickOptions 意不意外，惊不惊喜！! 原来etcd包依赖了grpc的resolver包，但我导入的v1.29.1版本的grpc是没有这个包的。到 grpc仓库 挨个版本看了一下，确实只有v1.26.0版本才声明了type BuildOption 。于是，我们再次使用替换大法。 1go mod edit -replace google.golang.org/grpc=google.golang.org/grpc@v1.26.0 再次tidy, 运行！ 终于，看到了久违的hello world! 12$ go run main.go2021/07/20 12:27:09.642431 [INFO] /Users/razeen/wspace/github/demo-go/gomod/main.go:26: hello world 总结项目规范现在我们回过头看下这个 demo 项目，其实很有问题。 123456&quot;github.com/coreos/etcd/pkg/transport&quot;&quot;github.com/google/certificate-transparency-go/tls&quot;&quot;github.com/qiniu/api.v7/auth/qbox&quot;&quot;go.etcd.io/etcd/clientv3&quot;&quot;google.golang.org/grpc&quot;&quot;qiniupkg.com/x/log.v7&quot; etcd 和 qiniupkg的包完全可以统一，只导入一种！而且，后来我们发现log.v7这包也是意外导入的…. 这也是在改造我们一些老的项目时遇到的问题，以前用vendor go get 没有注意到这些问题，这是需要提前规范的。 看懂 go.mod我们来简单看一下，经历各种坎坷后，得出的go.mod 文件。 12345678910111213141516171819202122232425262728293031module demo-go/gomodgo 1.16replace qiniupkg.com/x =&gt; qiniupkg.com/x v1.7.8replace github.com/qiniu/x =&gt; github.com/qiniu/x v1.7.8replace go.etcd.io/etcd =&gt; go.etcd.io/etcd v3.3.20+incompatiblereplace github.com/coreos/bbolt v1.3.6 =&gt; go.etcd.io/bbolt v1.3.6replace github.com/coreos/etcd =&gt; github.com/coreos/etcd v3.3.20+incompatiblereplace google.golang.org/grpc =&gt; google.golang.org/grpc v1.26.0require ( github.com/coreos/bbolt v1.3.6 // indirect github.com/coreos/etcd v3.3.10+incompatible github.com/dgrijalva/jwt-go v3.2.0+incompatible // indirect github.com/google/certificate-transparency-go v1.1.1 github.com/grpc-ecosystem/go-grpc-prometheus v1.2.0 // indirect github.com/qiniu/api.v7 v7.2.5+incompatible github.com/qiniu/x v0.0.0-00010101000000-000000000000 // indirect github.com/soheilhy/cmux v0.1.5 // indirect github.com/xiang90/probing v0.0.0-20190116061207-43a291ad63a2 // indirect go.etcd.io/etcd v0.0.0-20200513171258-e048e166ab9c google.golang.org/grpc v1.29.1 qiniupkg.com/x v0.0.0-00010101000000-000000000000 sigs.k8s.io/yaml v1.2.0 // indirect) 我们先看一个常见的这几个指令， module 定义主模块的路径； go 编写该mod文件时的go版本； require 声明给定模块依赖项的最低要求版本; replace 手动指定的依赖模块 (可以替换全部的版本、指定的版本、本地的版本等等 )； 还有就是 v3.3.20+incompatible 后面的 +incompatible , 这是指兼容的版本，指依赖库的版本是v2 或以上，但go.mod和 依赖库路径 没有按照官方指定的方式命名，会加上这个。 v0.0.0-00010101000000-000000000000 这是一个伪版本，在和 不兼容 module 或 标记的版本不可用的时候，回打上这个伪版本。 // indirect 这指明这些不是我们直接引用的依赖。 除此之外，以下指令也可了解一下。 1234567891011121314# 查看当前模块以及所有的依赖模块go list -m all# 查看某个模块的以及打标签的版本go list -m -versions go.etcd.io/etcd# 升级特定的包go get xx@version 升级特定的包# 了解为什么需要模块go mod why -m all # 为什么需要指定（google.golang.org/grpc）的模块go mod why -m google.golang.org/grpc 更多可以细读官方文档，感谢阅读。 参考 Using Go Modules Minimal Version Selection 跳出Go module的泥潭 Etcd使用go module的灾难 浅谈Go Modules原理","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"Golang中的RESTful API最佳实践","slug":"restful","date":"2018-10-22T08:17:50.000Z","updated":"2022-05-11T09:46:15.199Z","comments":true,"path":"2018/10/22/restful/","link":"","permalink":"https://timmy6.github.io/2018/10/22/restful/","excerpt":"RESRful API已经流行很多年了，我也一直在使用它。最佳实践也看过不少，但当一个项目完成，再次回顾&#x2F;梳理项目时，会发现很多API和规范还是多少有些出入。在这篇文章中，我们结合Go Web再次梳理一下RESTful API的相关最佳实践。","text":"RESRful API已经流行很多年了，我也一直在使用它。最佳实践也看过不少，但当一个项目完成，再次回顾&#x2F;梳理项目时，会发现很多API和规范还是多少有些出入。在这篇文章中，我们结合Go Web再次梳理一下RESTful API的相关最佳实践。 关于RESTful API关于什么是RESTful API，不再累述。推荐几个相关链接。 理解RESTful架构 REST API Tutorial 1.使用JSON不管是接收还是返回数据都推荐使用JSON。 通常返回数据的格式有JSON和XML，但XML过于冗长，可读性差，而且各种语言的解析上也不如JSON，使用JSON的好处，显而易见。 而接收数据，我们这里也推荐使用JSON，对于后端开发而言，入参直接与模型绑定，省去冗长的参数解析能简化不少代码，而且JSON能更简单的传递一些更复杂的结构等。 正如示例代码中的这一段，我们以gin框架为例。 12345678910111213141516// HandleLogin docfunc HandleLogin(c *gin.Context) &#123; param := &amp;LoginParams&#123;&#125; if err := c.BindJSON(param); err != nil &#123; c.JSON(http.StatusBadRequest, &amp;Resp&#123;Error: &quot;parameters error&quot;&#125;) return &#125; // 做一些校验 // ... session := sessions.Default(c) session.Set(sessionsKey, param.UserID) session.Save() c.JSON(http.StatusOK, &amp;Resp&#123;Data: &quot;login succeed&quot;&#125;)&#125; 通过c.BindJSON,轻松的将入参于模型LoginParams绑定；通过c.JSON轻松的将数据JSON序列化返回。 但所有接口都必须用JSON么？那也未必。比如文件上传，这时我们使用FormData比把文件base64之类的放到JSON里面更高效。 2.路径中不包含动词我们的HTTP请求方法中已经有GET,POST等这些动作了，完全没有必要再路径中加上动词。 我们常用HTTP请求方法包括GET,POST,PUT和DELETE, 这也对应了我们经常需要做的数据库操作。GET查找&#x2F;获取资源，POST新增资源，PUT修改资源，DELETE删除资源。 如下，这些路径中没有任何动词，简洁明了。 12345678// 获取文章列表v1.GET(&quot;/articles&quot;, HandleGetArticles)// 发布文章v1.POST(&quot;/articles&quot;, HandlePostArticles)// 修改文章v1.PUT(&quot;/articles&quot;, HandleUpdateArticles)// 删除文章v1.DELETE(&quot;/articles/:id&quot;, HandleDeleteArticles) 3.路径中对应资源用复数就像我们上面这段代码，articles对于的是我们的文章资源，背后就是一张数据库表articles, 所以操作这个资源的应该都用复数形式。 4.次要资源可分层展示一个博客系统中，最主要的应该是文章了，而评论应该是其子资源，我们可以评论嵌套在它的父资源后面，如： 12345678// 获取评论列表v1.GET(&quot;/articles/:articles_id/comments&quot;, HandleGetComments)// 添加评论v1.POST(&quot;/articles/:articles_id/comments&quot;, HandleAddComments)// 修改评论v1.PUT(&quot;/articles/:articles_id/comments/:id&quot;, HandleUpdateComments)// 删除评论v1.DELETE(&quot;/articles/:articles_id/comments/:id&quot;, HandleDeleteComments) 那么，我们需要获取所有文章的评论怎么办？可以这么写： 1v1.GET(&quot;/articles/-/comments&quot;, HandleGetComments) 但这也不是决对的，资源虽然有层级关系，但这种层级关系不宜太深，个人感觉两层最多了，如果超过，可以直接拿出来放在一级。 5.分页、排序、过滤获取列表时，会使用到分页、排序过滤。一般： 123?page=1&amp;page_size=10 # 指定页面page与分页大小page_size?sort=-create_at,+author # 按照创建时间create_at降序，作者author升序排序?title=helloworld # 按字段title搜索 6.统一数据格式不管是路径的格式，还是参数的格式，还是返回值的格式建议统一形式。 一般常用的格式有蛇形,大驼峰和小驼峰，个人比较喜欢蛇形。Anyway, 不管哪种，只要统一即可。 除了参数的命名统一外，返回的数据格式，最好统一，方便前端对接。 如下，我们定义Resp为通用返回数据结构，Data中存放返回的数据，如果出错，将错误信息放在Error中。 123456789101112131415// Resp doctype Resp struct &#123; Data interface&#123;&#125; `json:&quot;data&quot;` Error string `json:&quot;error&quot;`&#125;// 登陆成功返回 c.JSON(http.StatusOK, &amp;Resp&#123;Data: &quot;login succeed&quot;&#125;)// 查询列表 c.JSON(http.StatusOK, &amp;Resp&#123;Data: map[string]interface&#123;&#125;&#123; &quot;result&quot;: tempStorage, &quot;total&quot;: len(tempStorage), &#125;&#125;)// 参数错误 c.JSON(http.StatusBadRequest, &amp;Resp&#123;Error: &quot;parameters error&quot;&#125;) 7.善用HTTP状态码HTTP状态码有很多，我们没有必要也不可能全部用上，常用如下： 200 StatusOK - 只有成功请求都返回200。 400 StatusBadRequest - 当出现参数不对，用户参数校验不通过时，给出该状态，并返回Error 401 StatusUnauthorized - 没有登陆&#x2F;经过认证 403 Forbidden - 服务端拒绝授权(如密码错误)，不允许访问 404 Not Found - 路径不存在 500 Internal Server Error - 所请求的服务器遇到意外的情况并阻止其执行请求 502 Bad Gateway - 网关或代理从上游接收到了无效的响应 503 Service Unavailable - 服务器尚未处于可以接受请求的状态 其中502,503，我们写程序时并不会明确去抛出。所以我们平常用6个状态码已经能很好的展示服务端状态了。 同时，我们将状态与返回值对应起来，200状态下，返回Data数据；其他状态返回Error。 8.API版本化正如Demo中所示，我们将路由分组到了/api/v1路径下面，版本化API。如果后续的服务端升级，但可能仍有很大部分客户端请求未升级，依然请求老版本的API，那么我们只需要增加/api/v2，然后在该路径下为已升级的客户端提供服务。这样，我们就做到了API的版本控制，可以平滑的从一个版本切换到另外一个版本。 123456v1 := r.Group(&quot;/api/v1&quot;)&#123; v1.POST(&quot;/login&quot;, HandleLogin) v1.GET(&quot;/articles&quot;, HandleGetArticles) v1.GET(&quot;/articles/:id/comments&quot;, HandleGetComments) // .... 9. 统一 ‘&#x2F;‘ 开头所以路由中，路径都以’&#x2F;‘开头，虽然框架会为我们做这件事，但还是建议统一加上。 10. 增加&#x2F;更新操作 返回资源对于POST,PUT操作，建议操作后，返回更新后的资源。 11. 使用HTTPS对于暴露出去的接口&#x2F;OpenAPI，一定使用HTTPS。一般时候，我们可以直接在服务前面架设一个WebServer，在WebServer内部署证书即可。当然，如果是直接由后端暴露出的接口，有必要直接在后端开启HTTPS！ 12. 规范的API文档对于我们这种前后端分离的架构，API文档是很重要。在Go中，我们很容易的能用swag结合代码注释自动生成API文档。 总结API写的好不好，重要的还是看是否遵循WEB标准和保持一致性，最终目的也是让这些API更清晰，易懂，安全，希望这些建议对你有所帮助。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"gin文件上传与下载","slug":"gin-file","date":"2018-10-12T08:17:50.000Z","updated":"2022-05-11T09:46:09.526Z","comments":true,"path":"2018/10/12/gin-file/","link":"","permalink":"https://timmy6.github.io/2018/10/12/gin-file/","excerpt":"","text":"Gin是用Go编写的web框架。性能还不错，而且使用比较简单，还支持RESTful API。 日常的使用中我们可能要处理一些文件的上传与下载，我这里简单总结一下。 单文件上传我们使用multipart/form-data格式上传文件，利用c.Request.FormFile解析文件。 123456789101112131415161718// HandleUploadFile 上传单个文件func HandleUploadFile(c *gin.Context) &#123; file, header, err := c.Request.FormFile(&quot;file&quot;) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;msg&quot;: &quot;文件上传失败&quot;&#125;) return &#125; content, err := ioutil.ReadAll(file) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;msg&quot;: &quot;文件读取失败&quot;&#125;) return &#125; fmt.Println(header.Filename) fmt.Println(string(content)) c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;上传成功&quot;&#125;)&#125; 我们上传文件可以看到。 我们已经看到文件上传成功，已经文件名字与内容。 多文件上传多文件的上传利用c.Request.MultipartForm解析。 12345678910111213141516171819202122232425262728293031// HandleUploadMutiFile 上传多个文件func HandleUploadMutiFile(c *gin.Context) &#123; // 限制放入内存的文件大小 err := c.Request.ParseMultipartForm(4 &lt;&lt; 20) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;msg&quot;: &quot;文件太大&quot;&#125;) return &#125; formdata := c.Request.MultipartForm files := formdata.File[&quot;file&quot;] for _, v := range files &#123; file, err := v.Open() if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;msg&quot;: &quot;文件读取失败&quot;&#125;) return &#125; defer file.Close() content, err := ioutil.ReadAll(file) if err != nil &#123; c.JSON(http.StatusBadRequest, gin.H&#123;&quot;msg&quot;: &quot;文件读取失败&quot;&#125;) return &#125; fmt.Println(v.Filename) fmt.Println(string(content)) &#125; c.JSON(http.StatusOK, gin.H&#123;&quot;msg&quot;: &quot;上传成功&quot;&#125;)&#125; 多个文件，遍历文件内容即可读取。 利用c.Request.ParseMultipartForm()可设置上传文件的大小，这里限制了4MB。 c.Request.ParseMultipartForm()并不能限制上传文件的大小，只是限制了上传的文件读取到内存部分的大小，如果超过了就存入了系统的临时文件中。如果需要限制文件大小，需要使用github.com/gin-contrib/size中间件，如demo中使用r.Use(limits.RequestSizeLimiter(4 &lt;&lt; 20))限制最大4Mb。 我们看到 两个文件已经上传成功。 文件下载文件的下载主要是注意设置文件名，文件类型等。 123456789101112// HandleDownloadFile 下载文件func HandleDownloadFile(c *gin.Context) &#123; content := c.Query(&quot;content&quot;) content = &quot;hello world, 我是一个文件，&quot; + content c.Writer.WriteHeader(http.StatusOK) c.Header(&quot;Content-Disposition&quot;, &quot;attachment; filename=hello.txt&quot;) c.Header(&quot;Content-Type&quot;, &quot;application/text/plain&quot;) c.Header(&quot;Accept-Length&quot;, fmt.Sprintf(&quot;%d&quot;, len(content))) c.Writer.Write([]byte(content))&#125; 通过 Content-Disposition设置文件名字； Content-Type设置文件类型，可以到这里查阅； Accept-Length这个设置文件长度； c.Writer.Write写出文件。 成功下载可以看到：","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"gRPC在Go中的使用（三）gRPC实现TLS加密通信与流通信","slug":"grpc3","date":"2018-10-02T08:17:50.000Z","updated":"2022-05-11T09:46:03.455Z","comments":true,"path":"2018/10/02/grpc3/","link":"","permalink":"https://timmy6.github.io/2018/10/02/grpc3/","excerpt":"在前面的两篇博客中，我们已经知道了如何利用gRPC建立简单RPC通信。但这样简单的实现有时候满足不了我们的业务需求。在一些场景中我们需要防止数据被劫持，或是一些场景中我们希望客户端与服务器不是简单的一问一答，而是建立起一个流式的RPC通信，那么该怎么做到呢？","text":"在前面的两篇博客中，我们已经知道了如何利用gRPC建立简单RPC通信。但这样简单的实现有时候满足不了我们的业务需求。在一些场景中我们需要防止数据被劫持，或是一些场景中我们希望客户端与服务器不是简单的一问一答，而是建立起一个流式的RPC通信，那么该怎么做到呢？ TLS加密通信TLS加密无非就是认证客户端与服务器，如果对SSL&#x2F;TLS加密通信有所了解的童鞋都知道我们首先需要两张证书。 所以作为准备工作，我们首先要申请两张测试证书。一张客户端证书，一张服务器证书。 生成测试证书利用MySSL测试证书生成工具我们可以很简单的生成两张证书，如下所示： 如图，填入域名生成一张服务器证书，然后将私钥，证书链，根证书都下载下来，保存到文件。 同样，生成一张客户端证书并保存。 客户端与服务器TLS认证在gRPC通信中，我们完成服务器认证与客户端认证主要使用的是grpc下的credentials库。下面通过实例来看看怎么使用。 代码实例 服务端实现 1234567891011121314151617181920212223242526272829303132333435363738func main() &#123; lis, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; panic(err) &#125; // 加载证书和密钥 （同时能验证证书与私钥是否匹配） cert, err := tls.LoadX509KeyPair(&quot;certs/test_server.pem&quot;, &quot;certs/test_server.key&quot;) if err != nil &#123; panic(err) &#125; // 将根证书加入证书池 // 测试证书的根如果不加入可信池，那么测试证书将视为不可惜，无法通过验证。 certPool := x509.NewCertPool() rootBuf, err := ioutil.ReadFile(&quot;certs/root.pem&quot;) if err != nil &#123; panic(err) &#125; if !certPool.AppendCertsFromPEM(rootBuf) &#123; panic(&quot;fail to append test ca&quot;) &#125; tlsConf := &amp;tls.Config&#123; ClientAuth: tls.RequireAndVerifyClientCert, Certificates: []tls.Certificate&#123;cert&#125;, ClientCAs: certPool, &#125; serverOpt := grpc.Creds(credentials.NewTLS(tlsConf)) grpcServer := grpc.NewServer(serverOpt) pb.RegisterHelloWorldServiceServer(grpcServer, &amp;SayHelloServer&#123;&#125;) log.Println(&quot;Server Start...&quot;) grpcServer.Serve(lis)&#125; 客户端实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func main() &#123; cert, err := tls.LoadX509KeyPair(&quot;certs/test_client.pem&quot;, &quot;certs/test_client.key&quot;) if err != nil &#123; panic(err) &#125; // 将根证书加入证书池 certPool := x509.NewCertPool() bs, err := ioutil.ReadFile(&quot;certs/root.pem&quot;) if err != nil &#123; panic(err) &#125; if !certPool.AppendCertsFromPEM(bs) &#123; panic(&quot;fail to append test ca&quot;) &#125; // 新建凭证 // ServerName 需要与服务器证书内的通用名称一致 transportCreds := credentials.NewTLS(&amp;tls.Config&#123; ServerName: &quot;server.razeen.me&quot;, Certificates: []tls.Certificate&#123;cert&#125;, RootCAs: certPool, &#125;) dialOpt := grpc.WithTransportCredentials(transportCreds) conn, err := grpc.Dial(&quot;localhost:8080&quot;, dialOpt) if err != nil &#123; log.Fatalf(&quot;Dial failed:%v&quot;, err) &#125; defer conn.Close() client := pb.NewHelloWorldServiceClient(conn) resp1, err := client.SayHelloWorld(context.Background(), &amp;pb.HelloWorldRequest&#123; Greeting: &quot;Hello Server 1 !!&quot;, Infos: map[string]string&#123;&quot;hello&quot;: &quot;world&quot;&#125;, &#125;) if err != nil &#123; log.Printf(&quot;%v&quot;, err) &#125; log.Printf(&quot;Resp1:%+v&quot;, resp1) resp2, err := client.SayHelloWorld(context.Background(), &amp;pb.HelloWorldRequest&#123; Greeting: &quot;Hello Server 2 !!&quot;, &#125;) if err != nil &#123; log.Printf(&quot;%v&quot;, err) &#125; log.Printf(&quot;Resp2:%+v&quot;, resp2)&#125; 从代码中，我们不难看出，主要是创建一个通信凭证(TransportCredentials)。利用credentials库的NewTLS方法从tls加载一个通信凭证用于通信。而在其中需要注意的是： 如果你使用的是自签发的证书，注意将根加入证书池。如果你使用的是可信CA签发的证书大部分不用添加，因为系统的可信CA库已经有了。如果没有成功添加, 在通信时会出现以下错误： rpc error: code &#x3D; Unavailable desc &#x3D; all SubConns are in TransientFailure, latest connection error: connection error: desc &#x3D; “transport: authentication handshake failed: x509: certificate signed by unknown authority” 或 rpc error: code &#x3D; Unavailable desc &#x3D; all SubConns are in TransientFailure, latest connection error: connection error: desc &#x3D; “transport: authentication handshake failed: remote error: tls: bad certificate” 客户端凭证内 ServerName 需要与服务器证书内的通用名称一致，如果不一致会出现如下错误： rpc error: code &#x3D; Unavailable desc &#x3D; all SubConns are in TransientFailure, latest connection error: connection error: desc &#x3D; “transport: authentication handshake failed: x509: certificate is valid for server.razeen.me, not xxxxx” 之后，我们就可安心的通信了，在私钥不泄漏的情况下，基本不再担心数据劫持问题了。 这里我想多说一句：我们经常在提交代码时会直接 git add . ，这是个不好的习惯，有时后我们会将一些不必要的文件提交上去，特别是一些证书、私钥、密码之类的文件。 流式的RPC通信流式PRC通信可以分为: 服务器端流式 RPC; 客户端发送请求到服务器，拿到一个流去读取返回的消息序列。 客户端读取返回的流，直到里面没有任何消息。如： 1rpc ListHello(HelloWorldRequest) returns (stream HelloWorldResponse) &#123;&#125; 客户端流式 RPC; 客户端写入一个消息序列并将其发送到服务器，同样也是使用流。一旦客户端完成写入消息，它等待服务器完成读取返回它的响应。如： 1rpc SayMoreHello(stream HelloWorldRequest) returns (HelloWorldResponse) &#123;&#125; 双向流式 RPC; 双方使用读写流去发送一个消息序列。两个流独立操作，因此客户端和服务器可以以任意喜欢的顺序读写。如： 1rpc SayHelloChat(stream HelloWorldRequest) returns (stream HelloWorldRequest) &#123;&#125; 从上面的定义不难看出，用stream可以定义一个流式消息。下面我们就通过实例来演示一下流式通信的使用方法。 首先，我们将上面三个rpc server加入.proto , 并且生成新的.pb.go代码。 在生成的代码hello_world.pb.go中，我们可以看到客户端接口如下： 123456type HelloWorldServiceClient interface &#123; SayHelloWorld(ctx context.Context, in *HelloWorldRequest, opts ...grpc.CallOption) (*HelloWorldResponse, error) ListHello(ctx context.Context, in *HelloWorldRequest, opts ...grpc.CallOption) (HelloWorldService_ListHelloClient, error) SayMoreHello(ctx context.Context, opts ...grpc.CallOption) (HelloWorldService_SayMoreHelloClient, error) SayHelloChat(ctx context.Context, opts ...grpc.CallOption) (HelloWorldService_SayHelloChatClient, error)&#125; 服务端接口如下: 1234567// HelloWorldServiceServer is the server API for HelloWorldService service.type HelloWorldServiceServer interface &#123; SayHelloWorld(context.Context, *HelloWorldRequest) (*HelloWorldResponse, error) ListHello(*HelloWorldRequest, HelloWorldService_ListHelloServer) error SayMoreHello(HelloWorldService_SayMoreHelloServer) error SayHelloChat(HelloWorldService_SayHelloChatServer) error&#125; 在客户段的接口中，生成了HelloWorldService_XXXXClient接口类型。 在服务端的接口中，生成了HelloWorldService_XXXXServer接口类型。 我们再查看这些接口的定义，发现这这几个接口都是实现了以下几个方法中的数个： 1234Send(*HelloWorldRequest) errorRecv() (*HelloWorldRequest, error)CloseAndRecv() (*HelloWorldResponse, error)grpc.ClientStream 看其名字，我们不难知道，流式RPC的使用，或者说流的收发也就离不开这几个方法了。下面我们通过几个实例来验证一下。 在服务端，我们实现这三个接口。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// 服务器端流式 RPC, 接收一次客户端请求，返回一个流func (s *SayHelloServer) ListHello(in *pb.HelloWorldRequest, stream pb.HelloWorldService_ListHelloServer) error &#123; log.Printf(&quot;Client Say: %v&quot;, in.Greeting) // 我们返回多条数据 stream.Send(&amp;pb.HelloWorldResponse&#123;Reply: &quot;ListHello Reply &quot; + in.Greeting + &quot; 1&quot;&#125;) time.Sleep(1 * time.Second) stream.Send(&amp;pb.HelloWorldResponse&#123;Reply: &quot;ListHello Reply &quot; + in.Greeting + &quot; 2&quot;&#125;) time.Sleep(1 * time.Second) stream.Send(&amp;pb.HelloWorldResponse&#123;Reply: &quot;ListHello Reply &quot; + in.Greeting + &quot; 3&quot;&#125;) time.Sleep(1 * time.Second) return nil&#125;// 客户端流式 RPC， 客户端流式请求，服务器可返回一次func (s *SayHelloServer) SayMoreHello(stream pb.HelloWorldService_SayMoreHelloServer) error &#123; // 接受客户端请求 for &#123; req, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return err &#125; log.Printf(&quot;SayMoreHello Client Say: %v&quot;, req.Greeting) &#125; // 流读取完成后，返回 return stream.SendAndClose(&amp;pb.HelloWorldResponse&#123;Reply: &quot;SayMoreHello Recv Muti Greeting&quot;&#125;)&#125;// 双向流式 RPCfunc (s *SayHelloServer) SayHelloChat(stream pb.HelloWorldService_SayHelloChatServer) error &#123; // 开一个协程去处理客户端数据 go func() &#123; for &#123; req, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; return &#125; log.Printf(&quot;SayHelloChat Client Say: %v&quot;, req.Greeting) &#125; &#125;() // 向客户端写入多条数据 stream.Send(&amp;pb.HelloWorldRequest&#123;Greeting: &quot;SayHelloChat Server Say Hello 1&quot;&#125;) time.Sleep(1 * time.Second) stream.Send(&amp;pb.HelloWorldRequest&#123;Greeting: &quot;SayHelloChat Server Say Hello 2&quot;&#125;) time.Sleep(1 * time.Second) stream.Send(&amp;pb.HelloWorldRequest&#123;Greeting: &quot;SayHelloChat Server Say Hello 3&quot;&#125;) time.Sleep(1 * time.Second) return nil&#125; 之后我们就可以在客户端分别请求这几个rpc服务。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182 // 服务器端流式 RPC; // 我们向服务器SayHello recvListHello, err := client.ListHello(context.Background(), &amp;pb.HelloWorldRequest&#123;Greeting: &quot;Hello Server List Hello&quot;&#125;) if err != nil &#123; log.Fatalf(&quot;ListHello err: %v&quot;, err) &#125; // 服务器以流式返回 // 直到 err==io.EOF时，表示接收完毕。 for &#123; resp, err := recvListHello.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Fatal(err) &#125; log.Printf(&quot;ListHello Server Resp: %v&quot;, resp.Reply) &#125;// Client Out:// 2018/08/06 01:27:55 ListHello Server Resp: ListHello Reply Hello Server List Hello 1// 2018/08/06 01:27:56 ListHello Server Resp: ListHello Reply Hello Server List Hello 2// 2018/08/06 01:27:57 ListHello Server Resp: ListHello Reply Hello Server List Hello 3// Server Out:// 2018/08/06 01:27:55 Client Say: Hello Server List Hello // 客户端流式 RPC; sayMoreClient, err := client.SayMoreHello(context.Background()) if err != nil &#123; log.Fatal(err) &#125; for i := 0; i &lt; 3; i++ &#123; sayMoreClient.Send(&amp;pb.HelloWorldRequest&#123;Greeting: fmt.Sprintf(&quot;SayMoreHello Hello Server %d&quot;, i)&#125;) &#125; sayMoreResp, err := sayMoreClient.CloseAndRecv() if err != nil &#123; log.Fatal(err) &#125; log.Printf(&quot;SayMoreHello Server Resp: %v&quot;, sayMoreResp.Reply)// Client Out:// 2018/08/06 01:31:11 SayMoreHello Server Resp: SayMoreHello Recv Muti Greeting// Server Out:// 2018/08/06 01:31:11 SayMoreHello Client Say: SayMoreHello Hello Server 0// 2018/08/06 01:31:11 SayMoreHello Client Say: SayMoreHello Hello Server 1// 2018/08/06 01:31:11 SayMoreHello Client Say: SayMoreHello Hello Server 2 // 双向流式 RPC; sayHelloChat, err := client.SayHelloChat(context.Background()) if err != nil &#123; log.Fatal(err) &#125; go func() &#123; for i := 0; i &lt; 3; i++ &#123; sayHelloChat.Send(&amp;pb.HelloWorldRequest&#123;Greeting: fmt.Sprintf(&quot;SayHelloChat Hello Server %d&quot;, i)&#125;) &#125; &#125;() for &#123; resp, err := sayHelloChat.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Fatal(err) &#125; log.Printf(&quot;SayHelloChat Server Say: %v&quot;, resp.Greeting) &#125;// Client Out:// 2018/08/06 01:31:11 SayHelloChat Server Say: SayHelloChat Server Say Hello 1// 2018/08/06 01:31:12 SayHelloChat Server Say: SayHelloChat Server Say Hello 2// 2018/08/06 01:31:13 SayHelloChat Server Say: SayHelloChat Server Say Hello 3// Server Out:// 2018/08/06 01:31:11 SayHelloChat Client Say: SayHelloChat Hello Server 0// 2018/08/06 01:31:11 SayHelloChat Client Say: SayHelloChat Hello Server 1// 2018/08/06 01:31:11 SayHelloChat Client Say: SayHelloChat Hello Server 2 看了实例，是不是觉得很简单～。三种方式大同小异，只要掌握了怎么去收发流，怎么判断流的结束，基本就可以了。 好了，gRPC在Go中的使用三篇文章到这里也就结束了，如果博客中有错误或者你还有想知道的，记得留言哦。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"gRPC在Go中的使用（二）gRPC实现简单通讯","slug":"grpc2","date":"2018-09-25T07:27:50.000Z","updated":"2022-05-11T09:45:57.735Z","comments":true,"path":"2018/09/25/grpc2/","link":"","permalink":"https://timmy6.github.io/2018/09/25/grpc2/","excerpt":"Desc:gRPC实现简单通讯,Google 开源 RPC 框架 gRPC 初探 在上一篇中，我们用protobuf定义了两个消息HelloWorldRequest与HelloWorldResponse以及一个HelloWorldService服务。同时，我们还生成了相应的go代码.pb.go。 那么客户端与服务端怎么去通过这些接口去完成通讯呢？下面我们一起实现一个简单的gRPC通讯。","text":"Desc:gRPC实现简单通讯,Google 开源 RPC 框架 gRPC 初探 在上一篇中，我们用protobuf定义了两个消息HelloWorldRequest与HelloWorldResponse以及一个HelloWorldService服务。同时，我们还生成了相应的go代码.pb.go。 那么客户端与服务端怎么去通过这些接口去完成通讯呢？下面我们一起实现一个简单的gRPC通讯。 在RPC通讯中，客户端使用存根(SayHelloWorld)发送请求到服务器并且等待响应返回，整个过程就像我们平常函数调用一样。 123service HelloWorldService &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse)&#123;&#125;&#125; 那么接下来，我们先创建一个服务端。 创建服务端在生成的hello_world.pb.go中，已经为我们生成了服务端的接口： 1234// HelloWorldServiceServer is the server API for HelloWorldService service.type HelloWorldServiceServer interface &#123; SayHelloWorld(context.Context, *HelloWorldRequest) (*HelloWorldResponse, error)&#125; 在服务端我们首先要做的就是实现这个接口。 12345678910111213141516171819202122type SayHelloServer struct&#123;&#125;func (s *SayHelloServer) SayHelloWorld(ctx context.Context, in *pb.HelloWorldRequest) (res *pb.HelloWorldResponse, err error) &#123; log.Printf(&quot;Client Greeting:%s&quot;, in.Greeting) log.Printf(&quot;Client Info:%v&quot;, in.Infos) var an *any.Any if in.Infos[&quot;hello&quot;] == &quot;world&quot; &#123; an, err = ptypes.MarshalAny(&amp;pb.HelloWorld&#123;Msg: &quot;Good Request&quot;&#125;) &#125; else &#123; an, err = ptypes.MarshalAny(&amp;pb.Error&#123;Msg: []string&#123;&quot;Bad Request&quot;, &quot;Wrong Info Msg&quot;&#125;&#125;) &#125; if err != nil &#123; return &#125; return &amp;pb.HelloWorldResponse&#123; Reply: &quot;Hello World !!&quot;, Details: []*any.Any&#123;an&#125;, &#125;, nil&#125; 简单如上面的几行，实现了这个接口我们只需要创建一个结构SayHelloServer,同时实现HelloWorldServiceServer的所有方法即可。 这里为了演示效果我打印了一些数据，同时利用any.Any在不同的情况下返回不同的类型数据。 当然，只是现实了接口还不够，我们还需要启动一个服务，这样客户端才能使用该服务。启动服务很简单，就像我们平常启用一个Server一样。 1234567891011121314func main() &#123; // 我们首先须监听一个tcp端口 lis, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;) if err != nil &#123; panic(err) &#125; // 新建一个grpc服务器 grpcServer := grpc.NewServer() // 向grpc服务器注册SayHelloServer pb.RegisterHelloWorldServiceServer(grpcServer, &amp;SayHelloServer&#123;&#125;) // 启动服务 grpcServer.Serve(lis)&#125; 从上面的代码，我们可以看到，简单的4步即可启动一个服务。 监听一个服务端口，供客户端调用； 创建一个grpc服务器，当然这里可以设置授权认证,这个在下一篇中我们将详细介绍； 注册服务，其实是调用生存的.pb.go中的RegisterHelloWorldServiceServer方法，将我们这里实现的SayHelloServer加入到该服务中。 启动服务，等待客户端连接。 我们 go run server.go,无任何报错，这样一个简单的grpc服务的服务端就准备就绪了。接下来我们看看客户端。 创建客户端例如： 1234567891011121314151617181920212223242526func main() &#123; // 创建一个 gRPC channel 和服务器交互 conn, err := grpc.Dial(&quot;localhost:8080&quot;, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(&quot;Dial failed:%v&quot;, err) &#125; defer conn.Close() // 创建客户端 client := pb.NewHelloWorldServiceClient(conn) // 直接调用 resp1, err := client.SayHelloWorld(context.Background(), &amp;pb.HelloWorldRequest&#123; Greeting: &quot;Hello Server 1 !!&quot;, Infos: map[string]string&#123;&quot;hello&quot;: &quot;world&quot;&#125;, &#125;) log.Printf(&quot;Resp1:%+v&quot;, resp1) resp2, err := client.SayHelloWorld(context.Background(), &amp;pb.HelloWorldRequest&#123; Greeting: &quot;Hello Server 2 !!&quot;, &#125;) log.Printf(&quot;Resp2:%+v&quot;, resp2)&#125; 客户端的实现比服务端更简洁，三步即可。 创建一个 gRPC channel 和服务器交互。这里也是可以设置授权认证的； 创建一个客户端去执行RPC。用到的也是.pb.go内的NewHelloWorldServiceClient方法； 像函数调用一样去调用RPC服务。 我直接RUN起来，如下，我们可以看到客户端发送到服务的消息以及服务端对不同消息的不同回复。 那么到这里，我们简单的实现了一个gRPC通讯。但很多时候，我们可能希望客户端与服务器能更安全的通信，或者客户端与服务器不再是一种固定的结构的传输，需要流式的去处理一些问题等等。针对这些问题，在下一篇博客中，我将结合实例详细说明。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"gRPC在Go中的使用（一）Protocol Buffers语法与相关使用","slug":"grpc1","date":"2018-09-20T06:07:50.000Z","updated":"2022-05-11T09:45:51.566Z","comments":true,"path":"2018/09/20/grpc1/","link":"","permalink":"https://timmy6.github.io/2018/09/20/grpc1/","excerpt":"Desc:protobuf语法介绍，怎么写proto文件，grpc的使用入门 在gRPC官网用了一句话来介绍:“一个高性能、开源的通用RPC框架”，同时介绍了其四大特点： 定义简单 支持多种编程语言多种平台 快速启动和缩放 双向流媒体和集成身份验证","text":"Desc:protobuf语法介绍，怎么写proto文件，grpc的使用入门 在gRPC官网用了一句话来介绍:“一个高性能、开源的通用RPC框架”，同时介绍了其四大特点： 定义简单 支持多种编程语言多种平台 快速启动和缩放 双向流媒体和集成身份验证 在gRPC在go中使用系列中，关于其简介与性能我就不多介绍，相信在社区也有很多关于这些的讨论。这里我主要从三个层次来总结我以往在Go中使用gRPC的一些经验，主要分为： Protocol Buffers语法与相关使用 gRPC实现简单通讯 gRPC服务认证与双向流通讯 *注:下面Protocol Buffers简写protobuf. 这篇我们先介绍protobuf的相关语法、怎么书写.proto文件以及go代码生成。 简介要熟练的使用GRPC，protobuf的熟练使用必不可少。 gRPC使用protobuf来定义服务。protobuf是由Google开发的一种数据序列化协议，可以把它想象成是XML或JSON格式，但更小，更快更简洁。而且一次定义，可生成多种语言的代码。 定义首先我们需要编写一些.proto文件，定义我们在程序中需要处理的结构化数据。我们直接从一个实例开始讲起，下面是一个proto文件： 123456789101112131415161718192021syntax = &quot;proto3&quot;;option go_package = &quot;github.com/razeencheng/demo-go/grpc/demo1/helloworld&quot;;package helloworld;import &quot;github.com/golang/protobuf/ptypes/any/any.proto&quot;;message HelloWorldRequest &#123; string greeting = 1; map&lt;string, string&gt; infos = 2;&#125;message HelloWorldResponse &#123; string reply = 1; repeated google.protobuf.Any details = 2;&#125;service HelloWorldService &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse)&#123;&#125;&#125; 版本文件的开头syntax=&quot;proto3&quot;也就指明版本，主要有proto2与proto3,他们在语法上有一定的差异，我这里主要使用的是后者。 包名第二行，指定生成go文件的包名，可选项，默认使用第三行包名。 第三行，包名。 导包第四行，类似你写go一样，protobuf也可以导入其他的包。 消息定义后面message开头的两个结构就是我们需要传递的消息类型。所有的消息类型都是以message开始，然后定义类型名称。结构内字段的定义为字段规则 字段类型 字段名=字段编号 字段规则主要有 singular和repeated。如其中greeting和reply的字段规则为singular,允许该消息中出现0个或1个该字段(但不能超过一个)，而像details字段允许重复任意次数。其实对应到go里面也就是基本类型和切片类型。 字段类型，下表是proto内类型与go类型的对应表。 .proto Type Notes Go Type double float64 float float32 int32 使用可变长度编码。 无效编码负数 - 如果您的字段可能具有负值， 请改用sint32。 int32 int64 使用可变长度编码。 无效编码负数 - 如果您的字段可能具有负值，请改用sint64。 int64 uint32 使用可变长度编码。 uint32 uint64 使用可变长度编码。 uint64 sint32 使用可变长度编码。 带符号的int值。 这些比常规的int32更有效地编码负数。 int32 sint64 使用可变长度编码。 带符号的int值。 这些比常规的int64更有效地编码负数。 int64 fixed32 总是四个字节。 如果值通常大于228，则比uint32效率更高。 uint32 fixed64 总是八个字节。 如果值通常大于256，则会比uint64更高效。 uint64 sfixed32 总是四个字节。 int32 sfixed64 总是八个字节。 int64 bool bool string 字符串必须始终包含UTF-8编码或7位ASCII文本。 string bytes 可能包含任何字节序列。 []byte 看到这里你也许会疑惑，go里面的切片，map，接口等类型我怎么定义呢？别急，下面一一替你解答。 1.map类型，HelloWorldRequest的infos就是一个map类型，它的结构为map&lt;key_type, value_type&gt; map_field = N 但是在使用的时候你需要注意map类型不能repetead。 2.切片类型，我们直接定义其规则为repeated就可以了。就像HelloWorldResponse中的details字段一样，它就是一个切片类型。那么你会问了它是什么类型的切片？这就看下面了~ 3.接口类型在proto中没有直接实现，但在google&#x2F;protobuf&#x2F;any.proto中定义了一个google.protobuf.Any类型，然后结合protobuf&#x2F;go也算是曲线救国了~ 字段编号 最后的1，2代表的是每个字段在该消息中的唯一标签，在与消息二进制格式中标识这些字段，而且当你的消息在使用的时候该值不能改变。1到15都是用一个字节编码的，通常用于标签那些频繁发生修改的字段。16到2047用两个字节编码，最大的是2^29-1(536,870,911)，其中19000-19999为预留的，你也不可使用。 服务定义如果你要使用RPC(远程过程调用)系统的消息类型，那就需要定义RPC服务接口，protobuf编译器将会根据所选择的不同语言生成服务接口代码及存根。就如： 123service HelloWorldService &#123; rpc SayHelloWorld(HelloWorldRequest) returns (HelloWorldResponse)&#123;&#125;&#125; protobuf编译器将产生一个抽象接口HelloWorldService以及一个相应的存根实现。存根将所有的调用指向RpcChannel(SayHelloWorld)，它是一个抽象接口，必须在RPC系统中对该接口进行实现。具体如何使用，将在下一篇博客中详细介绍。 生成Go代码安装protoc首先要安装protoc,可直接到这里下载二进制安装到 $PATH里面，也可以直接下载源码编译。除此之外，你还需要安装go的proto插件protoc-gen-go。 12345// mac terminalgo get -u github.com/golang/protobuf/&#123;proto,protoc-gen-go&#125;// win powershellgo get -u github.com/golang/protobuf/protogo get -u github.com/golang/protobuf/protoc-gen-go 生成go代码接下来，使用protoc命令即可生成。 1234### mac terminalprotoc -I $&#123;GOPATH&#125;/src --go_out=plugins=grpc:$&#123;GOPATH&#125;/src $&#123;GOPATH&#125;/src/github.com/razeencheng/demo-go/grpc/demo1/helloworld/hello_world.proto### win powershellprotoc -I $env:GOPATH\\src --go_out=plugins=grpc:$env:GOPATH\\src $env:GOPATH\\src\\github.com\\razeencheng\\demo-go\\grpc\\demo1\\helloworld\\hello_world.proto 如上所示 -I指定搜索proto文件的目录,--go_out=plugins=grpc:指定生成go代码的文件夹，后面就是需要生成的proto文件路径。 注意： 如果你使用到了其他包的结构，-I需要将该资源包括在内。 例如我导入了github.com/golang/protobuf/ptypes/any/any.proto 我首先需要 go get -u github.com/golang/protobuf获取该包，然后在使用时资源路径(-I)直接为GOPATH\\src。 最后生成的hello-world.pb.go文件。内容大概如下图所示 图中我们可以看到两个message对应生成了两个结构体，同时会生成一些序列化的方法等。 而定义的service则是生成了对应的client与server接口，那么这到底有什么用？怎么去用呢？将为你详细讲解~ 看到这，我们简单的了解一下protobuf语法，如果你想了解更多，点这里看官方文档。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"怎么写Go基准测试（性能测试)","slug":"benchmark","date":"2018-09-15T03:07:50.000Z","updated":"2022-05-11T09:45:41.231Z","comments":true,"path":"2018/09/15/benchmark/","link":"","permalink":"https://timmy6.github.io/2018/09/15/benchmark/","excerpt":"或许你经常会思考这样的问题，我用不同的方法实现了同样的效果，哪个会更快？哪个内存消耗更小？这时候你一个简单的基准测试就能解决你的疑惑。","text":"或许你经常会思考这样的问题，我用不同的方法实现了同样的效果，哪个会更快？哪个内存消耗更小？这时候你一个简单的基准测试就能解决你的疑惑。 Go向来是以工具丰富而著称的，在学习Go的过程中，你会发现无论是写一个单元测试，还是做一些竞争检测都能很快的上手，而且用的很痛快。当然，接下来要说的基准测试也一样。 基准测试工具就在Go的测试包中，下面就用一个例子来介绍。 举个栗子由于一些场景需要，我需要将[]byte输出16进制字符。 有时候我会这么写: 1fmt.Sprintf(&quot;%x&quot;, b) 但有时候我会这么写： 1hex.EncodeToString(b) 但到底哪种写法更好呢？今天我就来比较一下。 直接写了个main.go 1234567func EncodeA(b []byte) string &#123; return fmt.Sprintf(&quot;%x&quot;, b)&#125;func EncodeB(b []byte) string &#123; return hex.EncodeToString(b)&#125; 再写个测试main_test.go 12345678910111213var buf = []byte(&quot;skdjadialsdgasadasdhsakdjsahlskdjagloqweiqwo&quot;)func BenchmarkEncodeA(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; EncodeA(buf) &#125;&#125;func BenchmarkEncodeB(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; EncodeB(buf) &#125;&#125; 就这么简单，我们的基本测试就写完了。从我的写法中你也许就知道： 和单元测试一样，都写在_test.go文件中； 需要以Benchmark为函数名开头； 和单元测试类似，必须接受一个*testing.B参数； 被测试代码放在一个循环中。 我们直接跑一下。当然我们也是用go test来执行测试，简单的测试只要带上-bench=.就可以了。 12345678$ go test -bench=.goos: darwingoarch: amd64pkg: github.com/razeencheng/demo-go/benchmarkBenchmarkEncodeA-8 5000000 265 ns/opBenchmarkEncodeB-8 10000000 161 ns/opPASSok github.com/razeencheng/demo-go/benchmark 3.397s 前两行是平台信息，第三行包名。第四、五行就是测试的结果了。 BenchmarkEncodeA-8 ,BenchmarkEncodeB-8 基准测试函数名-GOMAXPROCS 5000000,10000000 被测试的函数执行次数，也就是EncodeA()被执行了5000000次，EncodeB()被执行了10000000次，也就是b.N的值了。 265 ns/op,161 ns/op表示每次调用被测试函数花费的时间。 从花费的时间上来看，我们知道EncodeB()要快一点。 更多你以为就这么简单的结束了么？NONONO。 -bench 可接收一个有效的正则表达式来执行符合条件的测试函数。当你的函数很多时，可以用它来过滤. 1234567$ go test -bench=BenchmarkEncodeAgoos: darwingoarch: amd64pkg: github.com/razeencheng/demo-go/benchmarkBenchmarkEncodeA-8 5000000 256 ns/opPASSok github.com/razeencheng/demo-go/benchmark 1.575s -benchmem可以查看内存分配 12345678$ go test -bench=. -benchmemgoos: darwingoarch: amd64pkg: github.com/razeencheng/demo-go/benchmarkBenchmarkEncodeA-8 5000000 261 ns/op 128 B/op 2 allocs/opBenchmarkEncodeB-8 10000000 162 ns/op 192 B/op 2 allocs/opPASSok github.com/razeencheng/demo-go/benchmark 3.408s 其中B/op 表示每次执行会分配多少内存，allocs/op表示每次执行会发生多少次内存分配。 -benchtime指定每个测试执行的时间。默认1s,当你的函数比较耗时你可以设置更长一点。因为b.N是与这个时间有关的。 当你的运行时间没达到-benchtime制定的时间前，b.N将以1，2，5，10，20，50…增加，然后重新运行测试代码。 12345678$ go test -bench=. -benchmem -benchtime=5sgoos: darwingoarch: amd64pkg: github.com/razeencheng/demo-go/benchmarkBenchmarkEncodeA-8 30000000 254 ns/op 128 B/op 2 allocs/opBenchmarkEncodeB-8 50000000 160 ns/op 192 B/op 2 allocs/opPASSok github.com/razeencheng/demo-go/benchmark 16.113s -count指定每个测试执行的次数。 123456789101112$ go test -bench=. -benchmem -count=3goos: darwingoarch: amd64pkg: github.com/razeencheng/demo-go/benchmarkBenchmarkEncodeA-8 5000000 256 ns/op 128 B/op 2 allocs/opBenchmarkEncodeA-8 5000000 255 ns/op 128 B/op 2 allocs/opBenchmarkEncodeA-8 5000000 253 ns/op 128 B/op 2 allocs/opBenchmarkEncodeB-8 10000000 163 ns/op 192 B/op 2 allocs/opBenchmarkEncodeB-8 10000000 160 ns/op 192 B/op 2 allocs/opBenchmarkEncodeB-8 10000000 160 ns/op 192 B/op 2 allocs/opPASSok github.com/razeencheng/demo-go/benchmark 9.984s 我常用的也就这些了。 但对于testing.B来说，它拥有了testing.T的全部接口，所以Fail,Skip,Error这些都可以用，而且还增加了 SetBytes( i uint64) 统计内存消耗。 SetParallelism(p int) 制定并行数目。 StartTimer / StopTimer / ResertTimer 操作计时器。 你可以按需使用。 注意b.N为一个自增字段，谨慎用它做函数参数。","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"变量声明","slug":"var_dec","date":"2018-09-12T03:07:50.000Z","updated":"2022-05-11T10:35:36.885Z","comments":true,"path":"2018/09/12/var_dec/","link":"","permalink":"https://timmy6.github.io/2018/09/12/var_dec/","excerpt":"","text":"概述在声明变量之前，咱们先了解下变量的数据类型，这篇文章主要涉及 字符串、布尔、数字，其他类型后面开篇再说。 数据类型字符串string 只能用一对双引号（””）或反引号（&#96;&#96;）括起来定义，不能用单引号（’’）定义！ 布尔bool 只有 true 和 false，默认为 false。 数字整型 int8 uint8 int16 uint16 int32 uint32 int64 uint64 int uint，具体长度取决于 CPU 位数。 浮点型 float32 float64 常量声明常量，在程序编译阶段就确定下来的值，而程序在运行时无法改变该值。 单个常量声明 第一种：const 变量名称 数据类型 &#x3D; 变量值 如果不赋值，使用的是该数据类型的默认值。 第二种：const 变量名称 &#x3D; 变量值 根据变量值，自行判断数据类型。 多个常量声明 第一种：const 变量名称,变量名称 … ,数据类型 &#x3D; 变量值,变量值 … 第二种：const 变量名称,变量名称 … &#x3D; 变量值,变量值 … 测试代码 1234567891011121314151617181920//demo_1.gopackage mainimport ( &quot;fmt&quot;)func main() &#123; const name string = &quot;Tom&quot; fmt.Println(name) const age = 30 fmt.Println(age) const name_1, name_2 string = &quot;Tom&quot;, &quot;Jay&quot; fmt.Println(name_1, name_2) const name_3, age_1 = &quot;Tom&quot;, 30 fmt.Println(name_3, age_1)&#125; 运行结果： 变量声明单个变量声明 第一种：var 变量名称 数据类型 &#x3D; 变量值 如果不赋值，使用的是该数据类型的默认值。 第二种：var 变量名称 &#x3D; 变量值 根据变量值，自行判断数据类型。 第三种：变量名称 :&#x3D; 变量值 省略了 var 和数据类型，变量名称一定要是未声明过的。 多个变量声明 第一种：var 变量名称,变量名称 … ,数据类型 &#x3D; 变量值,变量值 … 第二种：var 变量名称,变量名称 … &#x3D; 变量值,变量值 … 第三种：变量名称,变量名称 … :&#x3D; 变量值,变量值 … 测试代码 12345678910111213141516171819202122//demo_2.gopackage mainimport ( &quot;fmt&quot;)func main() &#123; var age_1 uint8 = 31 var age_2 = 32 age_3 := 33 fmt.Println(age_1, age_2, age_3) var age_4, age_5, age_6 int = 31, 32, 33 fmt.Println(age_4, age_5, age_6) var name_1, age_7 = &quot;Tom&quot;, 30 fmt.Println(name_1, age_7) name_2, is_boy, height := &quot;Jay&quot;, true, 180.66 fmt.Println(name_2, is_boy, height)&#125; 运行结果： 输出方法fmt.Print：输出到控制台（仅只是输出） fmt.Println：输出到控制台并换行 fmt.Printf：仅输出格式化的字符串和字符串变量（整型和整型变量不可以） fmt.Sprintf：格式化并返回一个字符串，不输出。 测试代码 1234567891011121314//demo_3.gopackage mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Print(&quot;输出到控制台不换行&quot;) fmt.Println(&quot;---&quot;) fmt.Println(&quot;输出到控制台并换行&quot;) fmt.Printf(&quot;name=%s,age=%d\\n&quot;, &quot;Tom&quot;, 30) fmt.Printf(&quot;name=%s,age=%d,height=%v\\n&quot;, &quot;Tom&quot;, 30, fmt.Sprintf(&quot;%.2f&quot;, 180.567))&#125; 运行结果：","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"你好，Go语言","slug":"hello-wrold","date":"2018-09-11T03:07:50.000Z","updated":"2022-05-11T09:47:23.542Z","comments":true,"path":"2018/09/11/hello-wrold/","link":"","permalink":"https://timmy6.github.io/2018/09/11/hello-wrold/","excerpt":"","text":"你好，Go语言 Go 是一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。 因工作需要，准备入坑，先从环境安装开始，输出一个 Hello World。 环境安装目标 安装完成并运行 Hello World 成功！ 本机系统：macOS High Sierra 10.13.4 Go 版本：1.12 方式一： 通过 brew 安装 1brew install go 根据提示进行安装吧，我使用的 方式二 进行安装的。 方式二： 通过安装包安装 地址：https://dl.google.com/go/go1.12.darwin-amd64.pkg 下载之后直接点击安装，一步步继续即可。 配置环境变量 123456vi ~/.bashrc//新增export GOROOT=/usr/local/goexport GOPATH=/Users/username/go/code //代码目录，自定义即可export PATH=$PATH:$GOPATH/bin 及时生效，请执行命令：source ~&#x2F;.bashrc 如果命令行使用的是zsh，请修改 .zshrc 文件。 123456vi ~/.zshrc//新增export GOROOT=/usr/local/goexport GOPATH=/Users/username/go/code //自定义代码目录export PATH=$PATH:$GOPATH/bin 及时生效，请执行命令：source ~&#x2F;.zshrc 验证是否安装成功，命令行下执行： 目录结构bin 存放编译后可执行的文件。 pkg 存放编译后的应用包。 src 存放应用源代码。 例如： 123456├─ code -- 代码根目录│ ├─ bin│ ├─ pkg│ ├─ src│ ├── hello│ ├── hello.go Hello World 代码 1234567891011//在 hello 目录下创建 hello.gopackage mainimport ( &quot;fmt&quot;)func main() &#123; fmt.Println(&quot;Hello World!&quot;)&#125; 命令行执行： 命令查看完整的命令： go build hello 在src目录或hello目录下执行 go build hello，只在对应当前目录下生成文件。 go install hello 在src目录或hello目录下执行 go install hello，会把编译好的结果移动到 $GOPATH&#x2F;bin。 go run hello 在src目录或hello目录下执行 go run hello，不生成任何文件只运行程序。 go fmt hello 在src目录或hello目录下执行 go run hello，格式化代码，将代码修改成标准格式。 其他命令，需要的时候再进行研究吧。 开发工具GoLand GoLand 是 JetBrains 公司推出的 Go 语言集成开发环境，与我们用的 WebStorm、PhpStorm、PyCharm 是一家，同样支持 Windows、Linux、macOS 等操作系统。 下载地址：https://www.jetbrains.com/go/ 软件是付费的，不过想想办法，软件可以永久激活的。 学习网址 Go语言：https://golang.org/ Go语言中文网：https://studygolang.com/ Go语言包管理：https://gopm.io/","categories":[{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://timmy6.github.io/categories/rabbitmq/"},{"name":"微服务","slug":"微服务","permalink":"https://timmy6.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://timmy6.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/categories/redis/"},{"name":"MySql","slug":"MySql","permalink":"https://timmy6.github.io/categories/MySql/"},{"name":"Linux","slug":"Linux","permalink":"https://timmy6.github.io/categories/Linux/"},{"name":"Go开发","slug":"Go开发","permalink":"https://timmy6.github.io/categories/Go%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"数据库优化","slug":"数据库优化","permalink":"https://timmy6.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"},{"name":"常用命令","slug":"常用命令","permalink":"https://timmy6.github.io/tags/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"name":"Go基础","slug":"Go基础","permalink":"https://timmy6.github.io/tags/Go%E5%9F%BA%E7%A1%80/"},{"name":"redis","slug":"redis","permalink":"https://timmy6.github.io/tags/redis/"},{"name":"gin框架","slug":"gin框架","permalink":"https://timmy6.github.io/tags/gin%E6%A1%86%E6%9E%B6/"},{"name":"gRPC","slug":"gRPC","permalink":"https://timmy6.github.io/tags/gRPC/"}]}